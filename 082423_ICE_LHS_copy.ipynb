{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nancy-Shi/Complex_Networks/blob/main/082423_ICE_LHS_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA_qQY-h8rAL"
      },
      "source": [
        "## 3-Layer Model with Informtion, Behavior, Disease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvbMl01j8mD4",
        "outputId": "a6128204-4338-4401-9026-8d0948e159e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " No module named 'igraph'. If you need to use hypernetx.algorithms.hypergraph_modularity, please install additional packages by running the following command: pip install .['all']\n"
          ]
        }
      ],
      "source": [
        "#!pip install hypernetx\n",
        "import hypernetx as hnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fan2mZxpB3Up"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import random\n",
        "import math as math\n",
        "from math import log\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUCtz8IJ8VkT"
      },
      "source": [
        "\n",
        "## Part 1: Hypergraph Generation\n",
        "The following steps generate a hyper graph using the XGI/HyperNetX python package,  following power-law degree distribution for predifined number of nodes n, number of hyperedges num_hyper_edges, degree exponent gamma, using a configuration model with data stored in a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3qvT8MAI8VEs"
      },
      "outputs": [],
      "source": [
        "# Step 1: Generate Degree Sequence\n",
        "def generate_degree_sequence(n, gamma, kmin):\n",
        "    # Generate a random set from the power law distribution\n",
        "    u = np.random.uniform(size=n)\n",
        "    degrees = np.ceil((1.0 - u) ** (-1.0 / (gamma - 1.0)))\n",
        "\n",
        "    # Adjust degrees based on the minimum and maximum degree values\n",
        "    kmax = int(np.sqrt(n))\n",
        "    #kmax = int(((gamma-1)/(gamma-2) * n )** (1/gamma))  # max degree\n",
        "    # kmax = int(1.5*n**(1/4)) # max degree allowed is 1.5*n^(1/4)\n",
        "    degrees = degrees[(degrees >= kmin) & (degrees <= kmax)].astype(int)\n",
        "\n",
        "    # Truncate or pad the sequence to match the length specified\n",
        "    if len(degrees) >= n:\n",
        "        degrees = degrees[:n]\n",
        "    else:\n",
        "        degrees = np.concatenate((degrees, np.full(n - len(degrees), kmin)))\n",
        "\n",
        "    return degrees.tolist()\n",
        "\n",
        "# Step 2: Generate Hyper Edge Size Sequence\n",
        "def generate_hyper_edge_sizes(degrees, num_hyper_edges):\n",
        "    total_degrees = sum(degrees)\n",
        "    hyper_edge_sizes = []\n",
        "\n",
        "    # Calculate the average size for each hyper edge\n",
        "    avg_size = total_degrees // num_hyper_edges\n",
        "    remainder = total_degrees % num_hyper_edges\n",
        "\n",
        "    # Define the range for the random distribution\n",
        "    min_size = 2  # Lower bound of the range\n",
        "    max_size = int(np.sqrt(total_degrees))  # Upper bound of the range\n",
        "    #max_size = len(degrees) - num_hyper_edges  # Upper bound of the range\n",
        "\n",
        "    # Generate hyper edge sizes\n",
        "    for _ in range(num_hyper_edges):\n",
        "        size = random.randint(min_size, max_size)\n",
        "        hyper_edge_sizes.append(size)\n",
        "\n",
        "    return hyper_edge_sizes\n",
        "\n",
        "\n",
        "# Step 3: Create Copies of Nodes\n",
        "def create_node_copies(degrees):\n",
        "    node_copies = []\n",
        "    for i, degree in enumerate(degrees):\n",
        "        for _ in range(degree):\n",
        "            node_copies.append(i)\n",
        "    return node_copies\n",
        "\n",
        "# Step 4: Create Copies of Hyper Edges\n",
        "def create_hyper_edge_copies(hyper_edge_sizes):\n",
        "    hyper_edge_copies = []\n",
        "    for i, size in enumerate(hyper_edge_sizes):\n",
        "        for _ in range(size):\n",
        "            hyper_edge_copies.append(i)\n",
        "    return hyper_edge_copies\n",
        "\n",
        "# Step 5: Randomly Pair Copies without Repeated Pairs\n",
        "def randomly_pair_copies(node_copies, hyper_edge_copies):\n",
        "    pairs = []\n",
        "    paired_hyper_edges = {} # Using a dictionary to track paired hyper-edges with nodes\n",
        "\n",
        "    for node_copy in node_copies:\n",
        "        available_hyper_edges = [h for h in hyper_edge_copies if (h, node_copy) not in paired_hyper_edges]\n",
        "\n",
        "        # If no available hyper-edges left, shuffle the paired hyper-edges and reset\n",
        "        if not available_hyper_edges:\n",
        "            paired_hyper_edges = {}\n",
        "            available_hyper_edges = [h for h in hyper_edge_copies if (h, node_copy) not in paired_hyper_edges]\n",
        "\n",
        "        # Randomly choose a hyper-edge that has not been paired yet with the current node\n",
        "        chosen_hyper_edge = random.choice(available_hyper_edges)\n",
        "        pairs.append((node_copy, chosen_hyper_edge))\n",
        "\n",
        "        # Add to paired_hyper_edges\n",
        "        paired_hyper_edges[(chosen_hyper_edge, node_copy)] = True\n",
        "        hyper_edge_copies.remove(chosen_hyper_edge)\n",
        "\n",
        "    return pairs\n",
        "\n",
        "# Step 6: Convert Bipartite Graph to A Hypergraph Dictionary\n",
        "def convert_to_hypergraph(pairs):\n",
        "    hypergraph = {}\n",
        "    for pair in pairs:\n",
        "        node, hyper_edge = pair\n",
        "        if hyper_edge in hypergraph:\n",
        "            hypergraph[hyper_edge].append(node)\n",
        "        else:\n",
        "            hypergraph[hyper_edge] = [node]\n",
        "    return hypergraph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0b6c7yfU8hg8"
      },
      "outputs": [],
      "source": [
        "def build_hypergraph(n, gamma, kmin, num_hyper_edges):\n",
        "    # Step 1: Generate Degree Sequence\n",
        "    degrees = generate_degree_sequence(n, gamma, kmin)\n",
        "    print(\"Degree Sequence: \", degrees)\n",
        "\n",
        "    # Step 2: Generate Hyper Edge Size Sequence\n",
        "    hyper_edge_sizes = generate_hyper_edge_sizes(degrees, num_hyper_edges)\n",
        "    print(\"Hyper Edge Sizes: \", hyper_edge_sizes)\n",
        "\n",
        "    # Step 3: Create Copies of Nodes\n",
        "    node_copies = create_node_copies(degrees)\n",
        "\n",
        "    # Step 4: Create Copies of Hyper Edges\n",
        "    hyper_edge_copies = create_hyper_edge_copies(hyper_edge_sizes)\n",
        "\n",
        "    # Step 5: Randomly Pair Copies\n",
        "    pairs = randomly_pair_copies(node_copies, hyper_edge_copies)\n",
        "\n",
        "    # Step 6: Convert Bipartite Graph to Hypergraph\n",
        "    hyperedge_dict = convert_to_hypergraph(pairs)\n",
        "\n",
        "    # Print the resulting hypergraph\n",
        "    print(\"Hypergraph Dictionary: \", hyperedge_dict)\n",
        "\n",
        "    return degrees, hyperedge_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-tEXGpf819Y",
        "outputId": "3538d0a6-d385-40df-f158-13a2ee36d1b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degree Sequence:  [3, 3, 6, 5, 3, 6, 3, 3, 6, 11, 3, 5, 3, 3, 4, 5, 6, 3, 3, 3, 11, 3, 4, 3, 4, 4, 3, 7, 3, 4, 3, 13, 3, 3, 8, 5, 3, 5, 3, 5, 4, 6, 4, 3, 6, 3, 5, 3, 3, 4, 3, 3, 3, 5, 6, 12, 4, 4, 4, 4, 7, 8, 3, 4, 3, 4, 4, 4, 3, 3, 4, 8, 9, 9, 4, 13, 3, 3, 3, 5, 11, 4, 9, 9, 3, 3, 9, 11, 5, 4, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 4, 5, 5, 4, 7, 3, 3, 4, 4, 3, 3, 3, 5, 3, 7, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [18, 24, 9, 21, 15, 17, 14, 31, 11, 21, 32, 9, 31, 15, 12, 27, 34, 30, 22, 22, 15, 13, 36, 36, 20, 27, 37, 12, 19, 10, 31, 30, 18, 29, 4, 7, 14, 27, 36, 2, 9, 19, 28, 13, 9, 21, 10, 21, 37, 26, 18, 30, 32, 14, 26, 9, 28, 36, 2, 22, 21, 13, 19, 15, 11, 19, 20, 12, 15, 5, 19, 12, 25, 36, 27, 7, 10, 36, 6, 7, 24, 10, 12, 24, 29, 26, 31, 11, 2, 33, 36, 27, 20, 8, 28, 5, 23, 10, 37, 10]\n",
            "Hypergraph Dictionary:  {22: [0, 2, 3, 5, 9, 14, 31, 33, 62, 68, 72, 112, 113, 133, 144, 146, 148, 210, 250, 261, 278, 326, 329, 335, 388, 389], 99: [0, 5, 82, 104, 106, 271, 318, 328, 397], 73: [0, 27, 41, 72, 73, 86, 88, 108, 116, 127, 139, 165, 167, 205, 226, 230, 243, 247, 336, 361, 366], 10: [1, 17, 41, 53, 55, 82, 97, 105, 123, 157, 177, 179, 187, 202, 216, 222, 294, 302, 330, 383, 393], 98: [1, 9, 12, 15, 55, 61, 63, 65, 66, 70, 110, 119, 126, 141, 143, 175, 182, 183, 198, 201, 214, 219, 246, 314, 327], 85: [1, 4, 9, 14, 24, 50, 66, 67, 68, 87, 95, 99, 116, 132, 156, 213, 258, 296, 325], 71: [2, 51, 145, 150, 175, 269, 382, 383], 51: [2, 18, 25, 31, 37, 46, 49, 55, 56, 81, 140, 193, 258, 276, 290, 326, 333, 337, 338, 352, 369, 380, 397], 56: [2, 10, 27, 34, 44, 58, 99, 105, 114, 126, 183, 187, 257, 271, 300, 321, 334, 340], 16: [2, 20, 35, 36, 86, 94, 103, 104, 105, 121, 134, 148, 177, 179, 217, 218, 253, 254, 259, 265, 293, 346, 364, 370, 371, 384], 47: [2, 83, 108, 157, 166, 178, 195, 200, 229, 242, 308, 314, 371, 375, 392], 23: [3, 11, 12, 31, 37, 54, 85, 98, 108, 119, 135, 163, 172, 174, 175, 210, 252, 257, 259, 273, 303, 309, 347], 45: [3, 31, 55, 111, 121, 135, 177, 194, 201, 202, 293, 336], 21: [3, 11, 41, 45, 107, 140, 253, 295, 301, 320, 394], 70: [3, 30, 40, 42, 57, 104, 118, 130, 151, 156, 181, 215, 239], 83: [4, 43, 44, 71, 73, 76, 82, 86, 87, 97, 100, 125, 147, 155, 196, 212, 290, 322, 398], 46: [4, 55, 75, 83, 186, 297, 346, 391], 86: [5, 16, 20, 31, 73, 75, 82, 86, 111, 172, 180, 186, 206, 208, 249, 252, 256, 262, 280, 373, 388], 43: [5, 11, 65, 117, 134, 176, 283, 300, 304, 312], 29: [5, 58, 80, 93, 106, 116, 229, 231], 74: [5, 26, 45, 53, 66, 72, 79, 81, 113, 124, 128, 139, 155, 170, 174, 216, 262, 266, 302, 311, 336, 353], 42: [6, 35, 40, 44, 52, 60, 121, 141, 166, 172, 173, 185, 190, 241, 255, 328, 343, 344, 345, 350, 383, 387], 67: [6, 57, 90, 225, 276, 390, 397], 31: [6, 8, 16, 34, 88, 91, 129, 215, 247, 264, 281, 304, 306, 317, 324, 328, 329, 352, 365, 386], 65: [7, 27, 37, 52, 71, 73, 85, 109, 153, 179, 305, 307, 347, 358], 13: [7, 31, 32, 69, 81, 129, 181, 196, 217, 280, 305, 354], 32: [7, 54, 60, 101, 108, 138, 251, 268, 348, 360, 373, 382], 1: [8, 9, 23, 38, 62, 148, 159, 163, 170, 182, 185, 206, 227, 229, 243, 275, 342, 345, 349, 372], 77: [8, 20, 21, 22, 51, 54, 56, 57, 67, 72, 75, 80, 105, 137, 140, 147, 165, 180, 188, 234, 246, 260, 279, 286, 305, 353, 385, 392], 92: [8, 22, 38, 41, 78, 79, 81, 134, 143, 158, 199, 217, 258, 272, 289, 320, 356, 399], 50: [8, 16, 30, 61, 162, 203, 250, 267, 288, 311, 331], 57: [8, 19, 25, 28, 60, 61, 83, 96, 142, 149, 157, 189, 190, 201, 225, 251, 256, 283, 303, 321, 342, 381, 384], 52: [9, 14, 31, 39, 55, 59, 64, 79, 80, 105, 145, 150, 182, 193, 208, 219, 230, 302], 15: [9, 44, 100, 114, 117, 136, 142, 162, 192, 247, 264, 298, 299, 306, 313, 339, 355, 363, 367, 381, 396], 58: [9], 48: [9, 20, 46, 63, 74, 124, 159, 160, 252, 264, 274, 293, 296, 313, 317, 323, 339, 351, 362, 368, 378, 379, 399], 87: [9, 34, 45, 69, 71, 77, 86, 236], 54: [9, 20, 34, 46, 76, 92, 124, 147, 173, 255, 261, 266, 280, 358, 378, 399], 12: [9, 18, 61, 64, 80, 107, 109, 128, 130, 181, 184, 220, 232, 287, 310, 374, 385, 393], 5: [10, 87, 91, 126, 168, 189, 271, 274, 294, 301, 330, 344], 59: [10, 29, 42, 58, 72, 74, 86, 88, 145, 183, 207, 223, 248, 267, 344, 359], 84: [11, 27, 29, 31, 39, 59, 78, 80, 86, 89, 93, 98, 103, 115, 131, 209, 238, 278, 298, 337, 343, 369], 53: [11, 26, 40, 61, 120, 165, 173, 195, 235, 306, 359], 30: [12, 27, 52, 53, 65, 73, 83, 86, 93, 131, 189, 208, 211, 260, 263, 265, 268, 269, 295, 309, 318, 319, 333, 361], 4: [13, 89, 153, 204, 241, 281, 286, 357, 394], 25: [13, 25, 71, 77, 88, 96, 101, 112, 162, 185, 191, 204, 232, 239, 315, 327, 368], 33: [13, 20, 22, 32, 33, 56, 71, 87, 122, 130, 154, 197, 200, 270, 276, 279, 285, 288, 289, 314, 322, 324, 332, 355, 389], 91: [14, 21, 35, 63, 72, 83, 86, 97, 116, 158, 169, 199, 207, 253, 256, 270, 274, 316, 322], 28: [15, 34, 89, 167, 180, 198, 202, 250, 308, 326, 332, 354, 362, 375, 386], 44: [15, 70, 102, 233, 249, 269], 49: [15, 50, 57, 75, 103, 122, 149, 164, 236, 244, 245, 260, 370, 373, 377], 95: [15, 104, 120, 365], 63: [16, 87, 154, 214, 231, 233, 249, 289, 299, 343, 362], 89: [16, 26, 36, 48, 54, 76, 79, 87, 89, 91, 106, 118, 192, 219, 226, 232, 284, 291, 316, 357, 361, 390, 391], 26: [16, 19, 21, 24, 46, 47, 48, 56, 58, 70, 71, 91, 92, 106, 117, 218, 225, 227, 259, 287, 292, 300, 308, 313, 335, 360, 365, 369, 370, 375], 81: [17, 92, 118, 205, 366], 3: [17, 42, 80, 87, 93, 152, 220, 240, 327], 34: [18, 166, 176], 18: [19, 43, 44, 53, 67, 75, 84, 111, 178, 200, 213, 231, 237, 246, 307], 8: [20, 22, 31, 125, 251, 261, 310, 338, 374], 68: [20, 55, 74, 80, 87, 235, 292, 342, 346], 62: [20, 25, 72, 111, 123, 178, 188, 220, 279, 282, 317, 348, 355, 396], 17: [20, 29, 31, 35, 41, 61, 73, 90, 120, 129, 161, 215, 218, 237, 254, 291, 330, 341, 358, 364, 378], 90: [20, 24, 41, 51, 67, 77, 102, 108, 119, 127, 136, 151, 168, 205, 209, 221, 254, 303, 323, 331, 332, 347], 14: [23, 248, 255, 357, 363, 389], 7: [23, 31, 39, 50, 59, 75, 80, 83, 107, 144, 170, 228, 230, 234, 244, 290, 316, 325, 335, 350, 363], 6: [24, 49, 98, 132, 154, 203, 295, 301, 320, 340, 390, 391], 35: [27, 112, 164, 377, 394], 0: [27, 37, 60, 65, 69, 75, 101, 171, 192, 224, 242, 243, 268, 294], 27: [28, 47, 64, 75, 222, 248, 299, 309], 39: [28], 60: [29, 39, 62, 71, 138, 160, 207, 244, 273, 277, 282, 318, 319, 321, 340, 353, 376, 386], 36: [30, 115, 118, 144, 191, 223, 284], 96: [31, 32, 70, 73, 74, 75, 80, 119, 146, 158, 174, 195, 238, 266, 272, 334, 366], 11: [31, 39, 82, 367, 374, 376], 24: [33, 34, 36, 55, 133, 137, 150, 186, 209, 267, 273, 277, 315, 356, 380, 384], 37: [34, 38, 53, 61, 68, 72, 73, 127, 159, 171, 197, 204, 262, 339, 398], 20: [34, 82, 90, 110, 131, 143, 164, 190, 194, 275, 291, 372], 64: [35, 73, 102, 187, 235, 345, 377], 76: [37, 54, 161, 191, 392, 395], 66: [40, 42, 61, 87, 108, 116, 132, 198, 213, 281, 284, 286, 352, 380], 9: [43, 87, 139, 193, 199, 221, 222, 223, 227, 239, 245, 270, 287, 324, 329, 341, 359, 396], 19: [44, 75, 83, 96, 106, 114, 135, 141, 194, 212, 257, 263, 277, 282, 325, 351, 376], 82: [46, 48, 75, 108, 123, 312, 337, 338], 75: [47, 161, 169, 210], 93: [49, 79, 137, 214, 333, 387], 94: [49, 72, 83, 99, 100, 138, 155, 156, 188, 203, 206, 216, 236, 240, 241, 265, 272, 283, 311, 360, 367, 372], 78: [54, 55, 371], 38: [55, 71, 75, 88, 94, 100, 115, 118, 128, 168, 171, 184, 226, 228, 288, 292, 296, 310, 331, 334, 341, 349, 356, 388, 393, 398], 61: [55, 60, 80, 87, 113, 118, 149, 211, 233, 285, 348, 381, 382], 40: [55, 63, 80, 95, 197, 312, 385], 72: [59, 75, 78, 82, 83, 84, 95, 122, 133, 136, 153, 240, 319, 354], 80: [60, 66, 94, 118, 125, 142, 151, 152, 163, 167, 196, 212, 221, 224, 245, 297, 350, 387], 41: [60, 82, 107, 146, 152, 160, 228, 242, 263, 285, 297, 395], 97: [82, 224, 234, 298, 304, 315, 351], 79: [84, 85, 110, 176, 237, 364], 69: [109, 238, 307, 349, 379], 55: [112, 169, 368, 379], 88: [184, 211], 2: [275, 278, 323, 395]}\n"
          ]
        }
      ],
      "source": [
        "# Test 2\n",
        "n2 =400  # Number of nodes\n",
        "gamma2 = 2.5  # Power-law exponent\n",
        "kmin2 = 3  # Minimum degree\n",
        "num_hyper_edges2 = 100  # Desired number of hyper edges\n",
        "\n",
        "degrees2, hyperedge_dict2 = build_hypergraph(n2, gamma2, kmin2, num_hyper_edges2)\n",
        "H2 = hnx.Hypergraph(hyperedge_dict2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bbX083i9Htn"
      },
      "source": [
        "## Part 2: Assign Behavior Status\n",
        "NP represents the state of no protection, while P represents the state of with protection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "elKpYEaU9HE1"
      },
      "outputs": [],
      "source": [
        "def assign_protection(hypergraph, fraction_protected):\n",
        "    # Get the list of nodes from the hypergraph\n",
        "    nodes = list(hypergraph.nodes())\n",
        "\n",
        "    # Calculate the number of nodes to protect\n",
        "    num_nodes_to_protect = int(len(nodes) * fraction_protected)\n",
        "\n",
        "    # Randomly choose nodes to protect\n",
        "    nodes_to_protect = random.sample(nodes, num_nodes_to_protect)\n",
        "\n",
        "    # Initialize the protection status dictionary\n",
        "    protection_status = {}\n",
        "\n",
        "    # Assign protection status to each node\n",
        "    for node in nodes:\n",
        "        if node in nodes_to_protect:\n",
        "            protection_status[node] = \"P\"  # Protected node\n",
        "        else:\n",
        "            protection_status[node] = \"N\"  # Non-protected node\n",
        "\n",
        "    print(protection_status)\n",
        "\n",
        "    return protection_status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxZAdvJR-TXv",
        "outputId": "554c883c-b419-4124-b6c6-ec7b1f05e561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'N', 1: 'N', 2: 'N', 3: 'N', 4: 'N', 5: 'N', 6: 'N', 7: 'P', 8: 'N', 9: 'P', 10: 'N', 11: 'P', 12: 'N', 13: 'N', 14: 'N', 15: 'N', 16: 'N', 17: 'N', 18: 'N', 19: 'N', 20: 'N', 21: 'N', 22: 'N', 23: 'P', 24: 'N', 25: 'N', 26: 'N', 27: 'N', 28: 'N', 29: 'N', 30: 'N', 31: 'P', 32: 'N', 33: 'N', 34: 'N', 35: 'N', 36: 'N', 37: 'N', 38: 'N', 39: 'N', 40: 'N', 41: 'N', 42: 'N', 43: 'N', 44: 'P', 45: 'N', 46: 'N', 47: 'N', 48: 'N', 49: 'N', 50: 'N', 51: 'N', 52: 'N', 53: 'N', 54: 'N', 55: 'N', 56: 'N', 57: 'N', 58: 'N', 59: 'N', 60: 'N', 61: 'N', 62: 'N', 63: 'N', 64: 'N', 65: 'N', 66: 'N', 67: 'N', 68: 'N', 69: 'P', 70: 'N', 71: 'N', 72: 'N', 73: 'P', 74: 'N', 75: 'N', 76: 'N', 77: 'N', 78: 'N', 79: 'P', 80: 'N', 81: 'N', 82: 'N', 83: 'N', 84: 'N', 85: 'N', 86: 'N', 87: 'N', 88: 'N', 89: 'N', 90: 'P', 91: 'N', 92: 'N', 93: 'N', 94: 'P', 95: 'N', 96: 'N', 97: 'N', 98: 'N', 99: 'N', 100: 'N', 101: 'N', 102: 'N', 103: 'N', 104: 'N', 105: 'P', 106: 'N', 107: 'N', 108: 'P', 109: 'N', 110: 'N', 111: 'N', 112: 'N', 113: 'N', 114: 'P', 115: 'N', 116: 'N', 117: 'N', 118: 'N', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'N', 124: 'N', 125: 'N', 126: 'N', 127: 'N', 128: 'N', 129: 'N', 130: 'N', 131: 'N', 132: 'N', 133: 'P', 134: 'N', 135: 'N', 136: 'N', 137: 'N', 138: 'N', 139: 'N', 140: 'N', 141: 'N', 142: 'N', 143: 'N', 144: 'N', 145: 'N', 146: 'N', 147: 'N', 148: 'N', 149: 'N', 150: 'N', 151: 'N', 152: 'P', 153: 'N', 154: 'N', 155: 'N', 156: 'N', 157: 'N', 158: 'N', 159: 'N', 160: 'P', 161: 'N', 162: 'N', 163: 'N', 164: 'N', 165: 'N', 166: 'N', 167: 'N', 168: 'P', 169: 'N', 170: 'N', 171: 'N', 172: 'N', 173: 'N', 174: 'N', 175: 'P', 176: 'N', 177: 'N', 178: 'N', 179: 'N', 180: 'N', 181: 'N', 182: 'N', 183: 'N', 184: 'N', 185: 'N', 186: 'N', 187: 'P', 188: 'N', 189: 'N', 190: 'N', 191: 'N', 192: 'N', 193: 'N', 194: 'P', 195: 'P', 196: 'P', 197: 'N', 198: 'N', 199: 'N', 200: 'P', 201: 'P', 202: 'N', 203: 'N', 204: 'N', 205: 'N', 206: 'N', 207: 'N', 208: 'N', 209: 'N', 210: 'N', 211: 'N', 212: 'N', 213: 'N', 214: 'N', 215: 'N', 216: 'N', 217: 'N', 218: 'N', 219: 'N', 220: 'N', 221: 'N', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'N', 227: 'N', 228: 'N', 229: 'N', 230: 'N', 231: 'N', 232: 'N', 233: 'N', 234: 'N', 235: 'N', 236: 'N', 237: 'N', 238: 'N', 239: 'N', 240: 'N', 241: 'N', 242: 'N', 243: 'N', 244: 'N', 245: 'N', 246: 'N', 247: 'N', 248: 'N', 249: 'P', 250: 'N', 251: 'N', 252: 'N', 253: 'N', 254: 'N', 255: 'N', 256: 'P', 257: 'N', 258: 'N', 259: 'N', 260: 'N', 261: 'N', 262: 'N', 263: 'N', 264: 'N', 265: 'N', 266: 'N', 267: 'N', 268: 'N', 269: 'N', 270: 'N', 271: 'N', 272: 'N', 273: 'P', 274: 'N', 275: 'N', 276: 'N', 277: 'N', 278: 'N', 279: 'N', 280: 'P', 281: 'N', 282: 'N', 283: 'N', 284: 'N', 285: 'P', 286: 'N', 287: 'N', 288: 'N', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'N', 294: 'N', 295: 'N', 296: 'N', 297: 'N', 298: 'N', 299: 'N', 300: 'N', 301: 'N', 302: 'N', 303: 'N', 304: 'N', 305: 'P', 306: 'N', 307: 'N', 308: 'N', 309: 'N', 310: 'N', 311: 'P', 312: 'N', 313: 'N', 314: 'N', 315: 'N', 316: 'N', 317: 'N', 318: 'N', 319: 'N', 320: 'N', 321: 'N', 322: 'P', 323: 'N', 324: 'N', 325: 'N', 326: 'N', 327: 'N', 328: 'N', 329: 'N', 330: 'N', 331: 'N', 332: 'N', 333: 'N', 334: 'N', 335: 'P', 336: 'N', 337: 'N', 338: 'N', 339: 'N', 340: 'N', 341: 'N', 342: 'N', 343: 'P', 344: 'N', 345: 'N', 346: 'N', 347: 'N', 348: 'N', 349: 'N', 350: 'N', 351: 'N', 352: 'N', 353: 'N', 354: 'N', 355: 'N', 356: 'N', 357: 'N', 358: 'N', 359: 'N', 360: 'N', 361: 'N', 362: 'P', 363: 'N', 364: 'N', 365: 'N', 366: 'N', 367: 'N', 368: 'N', 369: 'N', 370: 'N', 371: 'N', 372: 'N', 373: 'N', 374: 'N', 375: 'N', 376: 'N', 377: 'N', 378: 'N', 379: 'N', 380: 'N', 381: 'N', 382: 'N', 383: 'N', 384: 'P', 385: 'N', 386: 'N', 387: 'N', 388: 'N', 389: 'N', 390: 'P', 391: 'P', 392: 'N', 393: 'N', 394: 'N', 395: 'P', 396: 'N', 397: 'N', 398: 'N', 399: 'N'}\n",
            "{0: 'N', 1: 'N', 2: 'N', 3: 'N', 4: 'N', 5: 'N', 6: 'N', 7: 'P', 8: 'N', 9: 'P', 10: 'N', 11: 'P', 12: 'N', 13: 'N', 14: 'N', 15: 'N', 16: 'N', 17: 'N', 18: 'N', 19: 'N', 20: 'N', 21: 'N', 22: 'N', 23: 'P', 24: 'N', 25: 'N', 26: 'N', 27: 'N', 28: 'N', 29: 'N', 30: 'N', 31: 'P', 32: 'N', 33: 'N', 34: 'N', 35: 'N', 36: 'N', 37: 'N', 38: 'N', 39: 'N', 40: 'N', 41: 'N', 42: 'N', 43: 'N', 44: 'P', 45: 'N', 46: 'N', 47: 'N', 48: 'N', 49: 'N', 50: 'N', 51: 'N', 52: 'N', 53: 'N', 54: 'N', 55: 'N', 56: 'N', 57: 'N', 58: 'N', 59: 'N', 60: 'N', 61: 'N', 62: 'N', 63: 'N', 64: 'N', 65: 'N', 66: 'N', 67: 'N', 68: 'N', 69: 'P', 70: 'N', 71: 'N', 72: 'N', 73: 'P', 74: 'N', 75: 'N', 76: 'N', 77: 'N', 78: 'N', 79: 'P', 80: 'N', 81: 'N', 82: 'N', 83: 'N', 84: 'N', 85: 'N', 86: 'N', 87: 'N', 88: 'N', 89: 'N', 90: 'P', 91: 'N', 92: 'N', 93: 'N', 94: 'P', 95: 'N', 96: 'N', 97: 'N', 98: 'N', 99: 'N', 100: 'N', 101: 'N', 102: 'N', 103: 'N', 104: 'N', 105: 'P', 106: 'N', 107: 'N', 108: 'P', 109: 'N', 110: 'N', 111: 'N', 112: 'N', 113: 'N', 114: 'P', 115: 'N', 116: 'N', 117: 'N', 118: 'N', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'N', 124: 'N', 125: 'N', 126: 'N', 127: 'N', 128: 'N', 129: 'N', 130: 'N', 131: 'N', 132: 'N', 133: 'P', 134: 'N', 135: 'N', 136: 'N', 137: 'N', 138: 'N', 139: 'N', 140: 'N', 141: 'N', 142: 'N', 143: 'N', 144: 'N', 145: 'N', 146: 'N', 147: 'N', 148: 'N', 149: 'N', 150: 'N', 151: 'N', 152: 'P', 153: 'N', 154: 'N', 155: 'N', 156: 'N', 157: 'N', 158: 'N', 159: 'N', 160: 'P', 161: 'N', 162: 'N', 163: 'N', 164: 'N', 165: 'N', 166: 'N', 167: 'N', 168: 'P', 169: 'N', 170: 'N', 171: 'N', 172: 'N', 173: 'N', 174: 'N', 175: 'P', 176: 'N', 177: 'N', 178: 'N', 179: 'N', 180: 'N', 181: 'N', 182: 'N', 183: 'N', 184: 'N', 185: 'N', 186: 'N', 187: 'P', 188: 'N', 189: 'N', 190: 'N', 191: 'N', 192: 'N', 193: 'N', 194: 'P', 195: 'P', 196: 'P', 197: 'N', 198: 'N', 199: 'N', 200: 'P', 201: 'P', 202: 'N', 203: 'N', 204: 'N', 205: 'N', 206: 'N', 207: 'N', 208: 'N', 209: 'N', 210: 'N', 211: 'N', 212: 'N', 213: 'N', 214: 'N', 215: 'N', 216: 'N', 217: 'N', 218: 'N', 219: 'N', 220: 'N', 221: 'N', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'N', 227: 'N', 228: 'N', 229: 'N', 230: 'N', 231: 'N', 232: 'N', 233: 'N', 234: 'N', 235: 'N', 236: 'N', 237: 'N', 238: 'N', 239: 'N', 240: 'N', 241: 'N', 242: 'N', 243: 'N', 244: 'N', 245: 'N', 246: 'N', 247: 'N', 248: 'N', 249: 'P', 250: 'N', 251: 'N', 252: 'N', 253: 'N', 254: 'N', 255: 'N', 256: 'P', 257: 'N', 258: 'N', 259: 'N', 260: 'N', 261: 'N', 262: 'N', 263: 'N', 264: 'N', 265: 'N', 266: 'N', 267: 'N', 268: 'N', 269: 'N', 270: 'N', 271: 'N', 272: 'N', 273: 'P', 274: 'N', 275: 'N', 276: 'N', 277: 'N', 278: 'N', 279: 'N', 280: 'P', 281: 'N', 282: 'N', 283: 'N', 284: 'N', 285: 'P', 286: 'N', 287: 'N', 288: 'N', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'N', 294: 'N', 295: 'N', 296: 'N', 297: 'N', 298: 'N', 299: 'N', 300: 'N', 301: 'N', 302: 'N', 303: 'N', 304: 'N', 305: 'P', 306: 'N', 307: 'N', 308: 'N', 309: 'N', 310: 'N', 311: 'P', 312: 'N', 313: 'N', 314: 'N', 315: 'N', 316: 'N', 317: 'N', 318: 'N', 319: 'N', 320: 'N', 321: 'N', 322: 'P', 323: 'N', 324: 'N', 325: 'N', 326: 'N', 327: 'N', 328: 'N', 329: 'N', 330: 'N', 331: 'N', 332: 'N', 333: 'N', 334: 'N', 335: 'P', 336: 'N', 337: 'N', 338: 'N', 339: 'N', 340: 'N', 341: 'N', 342: 'N', 343: 'P', 344: 'N', 345: 'N', 346: 'N', 347: 'N', 348: 'N', 349: 'N', 350: 'N', 351: 'N', 352: 'N', 353: 'N', 354: 'N', 355: 'N', 356: 'N', 357: 'N', 358: 'N', 359: 'N', 360: 'N', 361: 'N', 362: 'P', 363: 'N', 364: 'N', 365: 'N', 366: 'N', 367: 'N', 368: 'N', 369: 'N', 370: 'N', 371: 'N', 372: 'N', 373: 'N', 374: 'N', 375: 'N', 376: 'N', 377: 'N', 378: 'N', 379: 'N', 380: 'N', 381: 'N', 382: 'N', 383: 'N', 384: 'P', 385: 'N', 386: 'N', 387: 'N', 388: 'N', 389: 'N', 390: 'P', 391: 'P', 392: 'N', 393: 'N', 394: 'N', 395: 'P', 396: 'N', 397: 'N', 398: 'N', 399: 'N'}\n"
          ]
        }
      ],
      "source": [
        "# Test:\n",
        "fraction_protected = 0.1  # 40% of nodes will be protected\n",
        "protection_status_dict = assign_protection(H2, fraction_protected)\n",
        "print(protection_status_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F71C7Qfa_b9I"
      },
      "source": [
        "\n",
        "## Part 3: Assign Threshold\n",
        "The following steps assigns a threshold value to each node in the network. The threshold follows a uniform or normal distribution with predefined mean (mu) and standard deviation (sigma)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ky4HFlQR_jBY"
      },
      "outputs": [],
      "source": [
        "# Defines the parameters to be used\n",
        "mu = 0.1\n",
        "sigma = 0.05\n",
        "\n",
        "# Function to assign thresholds to the individual nodes\n",
        "def assign_thresholds(hypergraph, mu, sigma):\n",
        "    NV = hypergraph.order()\n",
        "    Ltre = {}\n",
        "\n",
        "    for node in hypergraph.nodes():\n",
        "          # Uniform distribution: #\n",
        "          #Ltre[node] = np.random.uniform()\n",
        "          # Normal distrution\n",
        "          while True:\n",
        "              threshold = random.gauss(mu, sigma)\n",
        "              if 0 < threshold < 1:\n",
        "                  break\n",
        "          Ltre[node] = threshold\n",
        "\n",
        "    return Ltre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ11eyyS_o1O",
        "outputId": "38e00d13-7130-4d0b-8d66-ea653359dea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold List for Nodes:  {0: 0.023064013072024186, 1: 0.11157786024770298, 2: 0.18113017286629435, 3: 0.15090488300236846, 4: 0.11012013721249655, 5: 0.08638259626650875, 6: 0.058259195643140714, 7: 0.11332461022375327, 8: 0.10613791416417077, 9: 0.10308942513276001, 10: 0.05686789530427577, 11: 0.14083726599918153, 12: 0.14423560915272624, 13: 0.08424017085650572, 14: 0.17101491036877164, 15: 0.08607279297111105, 16: 0.09056253336309963, 17: 0.114529913439477, 18: 0.07968706605284884, 19: 0.040282284334420826, 20: 0.08080613508923312, 21: 0.11486987031253439, 22: 0.042722359537921376, 23: 0.14258109054528967, 24: 0.1454472566607996, 25: 0.057166675809292244, 26: 0.022019780532953004, 27: 0.13561634600690758, 28: 0.03996708122537909, 29: 0.02659495486646775, 30: 0.08235122691618857, 31: 0.1685998019646193, 32: 0.13626787628521075, 33: 0.05952579131514745, 34: 0.23393409212941574, 35: 0.123748265664311, 36: 0.06696100976811001, 37: 0.11833663325440923, 38: 0.12287134154380436, 39: 0.08811493549439425, 40: 0.13992743113089345, 41: 0.027293259232553713, 42: 0.08055079557400525, 43: 0.12985567864486341, 44: 0.020730940351032248, 45: 0.07750038737560816, 46: 0.17437831450177876, 47: 0.12595750883173168, 48: 0.10151223975232217, 49: 0.09748101455884199, 50: 0.064887394708781, 51: 0.15448704946662747, 52: 0.0554259374695945, 53: 0.08790095678590965, 54: 0.16911528258308955, 55: 0.11411497076434435, 56: 0.11067851209920126, 57: 0.06435877752521385, 58: 0.1671042855101969, 59: 0.18532888327223018, 60: 0.13092155895761648, 61: 0.11422861240617772, 62: 0.0926943640500403, 63: 0.051674999536437255, 64: 0.08793931458196597, 65: 0.15199933303721713, 66: 0.10270054058970271, 67: 0.16877084878312212, 68: 0.12806765426896363, 69: 0.05546761239175649, 70: 0.14742851754133385, 71: 0.14816608834062506, 72: 0.1480290761152543, 73: 0.10758671694048523, 74: 0.1239682319096274, 75: 0.11719198966063826, 76: 0.07956838235981684, 77: 0.08617703827314217, 78: 0.1254477233466506, 79: 0.05651451906887744, 80: 0.057247833213052865, 81: 0.11224996238351741, 82: 0.06028074204423753, 83: 0.12527537050641313, 84: 0.029685113389930087, 85: 0.08880435722083166, 86: 0.07650599686722052, 87: 0.11182971351977192, 88: 0.0999337892741919, 89: 0.10844437729888204, 90: 0.03941982694989652, 91: 0.1220701176797067, 92: 0.06830344006867273, 93: 0.08776333910336556, 94: 0.1470032189533435, 95: 0.13922878535562294, 96: 0.04749813176833263, 97: 0.06413145532110143, 98: 0.06158260966257788, 99: 0.14267391848337604, 100: 0.06394117488843121, 101: 0.11797602839597628, 102: 0.07267889182164634, 103: 0.0530071179089924, 104: 0.14993384644358532, 105: 0.08232556468247088, 106: 0.11112761900448857, 107: 0.03431753079349638, 108: 0.1859467072460787, 109: 0.06727747298537595, 110: 0.09740799635223348, 111: 0.0781868308089348, 112: 0.05429480614923601, 113: 0.035157552109891674, 114: 0.10522117611587735, 115: 0.10011697732002374, 116: 0.20358626999031315, 117: 0.11510772578221176, 118: 0.10811421553743668, 119: 0.13937276666031523, 120: 0.19366829214184753, 121: 0.07117119406978364, 122: 0.12947558966854905, 123: 0.02687696629937246, 124: 0.06451312469614495, 125: 0.08069490700052111, 126: 0.116045913764812, 127: 0.10139052990116862, 128: 0.13177507487196585, 129: 0.07105680394854749, 130: 0.14176403678548868, 131: 0.10429193443832899, 132: 0.09390580718161952, 133: 0.1079882679312263, 134: 0.10165994307617399, 135: 0.05629108116031623, 136: 0.09211381417246257, 137: 0.10244108359374558, 138: 0.05114201575023947, 139: 0.07771750779229825, 140: 0.13311020509335916, 141: 0.08839924764292384, 142: 0.09065986478435437, 143: 0.02184310084493049, 144: 0.09180470471008306, 145: 0.007848138186125203, 146: 0.07454477945094402, 147: 0.04908416645844887, 148: 0.10530432067261618, 149: 0.14417585813786926, 150: 0.11274414129297018, 151: 0.02575954639651558, 152: 0.12966322334191807, 153: 0.1380271346341882, 154: 0.07989905414786273, 155: 0.0986409927153561, 156: 0.07818468640410733, 157: 0.10935479435512126, 158: 0.06934300467112331, 159: 0.05699059139743962, 160: 0.12699559815562392, 161: 0.10097736469992365, 162: 0.09756606000038595, 163: 0.1439414242638954, 164: 0.13476011606681104, 165: 0.11391698354945828, 166: 0.06785519415910193, 167: 0.035784409346525256, 168: 0.024882892486241676, 169: 0.13663560726853854, 170: 0.1087268863261928, 171: 0.10511620657756715, 172: 0.0859555849849817, 173: 0.06330326054076371, 174: 0.09725102037059849, 175: 0.16289015085244635, 176: 0.027805301533878807, 177: 0.12724434404930826, 178: 0.13329693421313862, 179: 0.16773660303642413, 180: 0.032513846009110434, 181: 0.03634500314101918, 182: 0.23213645189082593, 183: 0.10747364114601736, 184: 0.04494946975687258, 185: 0.0899258665275339, 186: 0.05617144239778697, 187: 0.0643997608730324, 188: 0.08004481668136909, 189: 0.09341042497311501, 190: 0.11870781720927874, 191: 0.1297972771307755, 192: 0.07500333629023147, 193: 0.08639165972628113, 194: 0.052714424420534645, 195: 0.11892634449116046, 196: 0.11099212110523062, 197: 0.10019843179755615, 198: 0.10278728216794365, 199: 0.004449925151842005, 200: 0.14401483051741135, 201: 0.12619403206893068, 202: 0.12908069264289523, 203: 0.1366996555441133, 204: 0.12951210782805844, 205: 0.08780748461968349, 206: 0.03922065277381081, 207: 0.030189932754553978, 208: 0.08415161663505516, 209: 0.11210173864997658, 210: 0.0986610232210932, 211: 0.010080728843363446, 212: 0.128639282384663, 213: 0.04500234761424962, 214: 0.09318578960969781, 215: 0.1411677804323812, 216: 0.09392072991218281, 217: 0.13970049706093962, 218: 0.06549969466461114, 219: 0.10389421305944804, 220: 0.04925412067070816, 221: 0.09303413269584347, 222: 0.10828272205634598, 223: 0.15778666780176515, 224: 0.15392927647293994, 225: 0.17780756563027023, 226: 0.09581706951318382, 227: 0.05849819551508662, 228: 0.09339420466460041, 229: 0.03176830027967503, 230: 0.16604067750805168, 231: 0.12249751120065544, 232: 0.095842964387088, 233: 0.11116243560146531, 234: 0.09932117419665691, 235: 0.13840631497293213, 236: 0.11584149606490282, 237: 0.05073460304781002, 238: 0.12598822067487367, 239: 0.1057842325912663, 240: 0.07339255457956054, 241: 0.1822682625426043, 242: 0.048239441634516815, 243: 0.039082351591618464, 244: 0.170866361603555, 245: 0.12372435109348182, 246: 0.10588053858266275, 247: 0.05834278653518899, 248: 0.12372452063824177, 249: 0.2127416781323872, 250: 0.10120654320293614, 251: 0.12227371843595829, 252: 0.03244568282307035, 253: 0.073822605877048, 254: 0.10117248439547576, 255: 0.09316982782245514, 256: 0.03949888516317103, 257: 0.09257463348611698, 258: 0.13496698784348662, 259: 0.1818929717476178, 260: 0.08817974243431734, 261: 0.0918945327513195, 262: 0.13094651526151846, 263: 0.11040627904161687, 264: 0.13115112636302978, 265: 0.1292084711097991, 266: 0.13329937445597764, 267: 0.11660842239153167, 268: 0.17316253381292657, 269: 0.07671479934945269, 270: 0.09594962960752074, 271: 0.10335412802541007, 272: 0.0504022024519122, 273: 0.09590825116779168, 274: 0.08239443569197849, 275: 0.06366091713296979, 276: 0.17247616859706447, 277: 0.03858765055937035, 278: 0.14479631728758838, 279: 0.1370622044471209, 280: 0.09002229530386405, 281: 0.20212755754222542, 282: 0.15590886558095834, 283: 0.16887999194434816, 284: 0.07352907147426972, 285: 0.015981394632214235, 286: 0.09259840785292062, 287: 0.08440100198746345, 288: 0.09154301646958203, 289: 0.04287289337118651, 290: 0.019070811725412376, 291: 0.12615737145918968, 292: 0.05463426451265813, 293: 0.2229828532001432, 294: 0.09138098169060084, 295: 0.12178989349543504, 296: 0.20967242105171552, 297: 0.08111481331969828, 298: 0.11283773403040731, 299: 0.03927972402381927, 300: 0.23130561738569339, 301: 0.11282450693648378, 302: 0.12822865905604736, 303: 0.049292589245881736, 304: 0.23597412607966206, 305: 0.020612064065637578, 306: 0.0875918548880085, 307: 0.1549852843294215, 308: 0.03841239880974461, 309: 0.06296322833302229, 310: 0.11387761093228091, 311: 0.16409340711231313, 312: 0.052829403790072504, 313: 0.18451359954680152, 314: 0.06788225857492344, 315: 0.15643355092930422, 316: 0.1203773034337163, 317: 0.1290868615947771, 318: 0.14234644955797876, 319: 0.004625473712895067, 320: 0.07845538597552235, 321: 0.13437452408109915, 322: 0.09668680735428536, 323: 0.08625044684852556, 324: 0.04678838936066724, 325: 0.12255456746036703, 326: 0.14267802921146153, 327: 0.10981027406585092, 328: 0.10958560814212788, 329: 0.17342581449303418, 330: 0.13935230549241762, 331: 0.0829873774494119, 332: 0.03232594225999491, 333: 0.07479821079180612, 334: 0.1687583542198327, 335: 0.11074009466834486, 336: 0.16218084288091422, 337: 0.08847192421511252, 338: 0.11633323384296515, 339: 0.046051185447750234, 340: 0.09298764937036713, 341: 0.10991607155794711, 342: 0.12998455625503777, 343: 0.07800677312710523, 344: 0.18585882459672967, 345: 0.11150650759142641, 346: 0.11179684845798467, 347: 0.15951419372332076, 348: 0.07289864854126397, 349: 0.0959305014746019, 350: 0.20274806560367076, 351: 0.17658693768341255, 352: 0.12607978587957622, 353: 0.12149383528149109, 354: 0.09776263852242338, 355: 0.15896693464258685, 356: 0.15310413733584718, 357: 0.06726095843639135, 358: 0.1335308193604037, 359: 0.15430127487893613, 360: 0.09173716332897959, 361: 0.06301299717369135, 362: 0.07558690558747422, 363: 0.1433012564441648, 364: 0.03185880608036819, 365: 0.10453900453037354, 366: 0.1802497997767671, 367: 0.11414725419996541, 368: 0.17375948850353956, 369: 0.12489256001075812, 370: 0.07924476906944058, 371: 0.13552117945742803, 372: 0.06278995704330419, 373: 0.04245415046118937, 374: 0.20218371001456104, 375: 0.1446956556150585, 376: 0.2029926484348241, 377: 0.06064848031816886, 378: 0.052413269189300754, 379: 0.11489706395080439, 380: 0.1387369807464581, 381: 0.0751483914038233, 382: 0.08254330826764968, 383: 0.14314990455252335, 384: 0.0588804051374694, 385: 0.09404786898801998, 386: 0.13275345122085525, 387: 0.004077907737579975, 388: 0.0891094862220648, 389: 0.14538468609023808, 390: 0.06786566883182873, 391: 0.17787069160023578, 392: 0.1516934040982118, 393: 0.13896783813765867, 394: 0.13826265425874462, 395: 0.06843558419788584, 396: 0.066557892441369, 397: 0.09043548893861232, 398: 0.08066868689484702, 399: 0.1045867921393058}\n"
          ]
        }
      ],
      "source": [
        "Ltre2 = assign_thresholds(H2, mu, sigma)\n",
        "\n",
        "print(\"Threshold List for Nodes: \", Ltre2 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSmz7Gj6AA9m"
      },
      "source": [
        "# Part 4: The ICE Model (The Information Cognition Epidemics Model)\n",
        "## Information Layer\n",
        "The misinformation spread occurs on a hyperedge network involving group spreading. The three stages are U(unaware), G(gossip/spreader), and C(stifler/corrected).  \n",
        "\n",
        "## Cognition Layer\n",
        "In the cognitive behavioral layer, P is protected, and N is not protected. The rate of transition from state P to N, p, depends on the information layer. The rate from NP to P is 1-p. The transition rate of a node is also affected by the number of active spreader/stiflers. The bigger number of active neighbors, the faster the rate. Another way behavior may change is based on the fraction of protected neighbors.\n",
        "\n",
        "## Epidemics Layer\n",
        "In the epidemics layer, the possible disease states are S(susceptible), I(infected), and R(recovered). The illness spreading is pairwise. The disease propagation rate depends on the fraction of protected individuals $\\rho_P$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "i3rNTHw7F-6v"
      },
      "outputs": [],
      "source": [
        "def ICE_model_no_control(inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "      inw - information hyperedge network\n",
        "      ltre - list of thresholds for informaiton spread\n",
        "      ldeg_i - degree sequence of information layer\n",
        "\n",
        "      cnw - cognitive network\n",
        "      lprot - list of protection status\n",
        "      ldeg_c - degree sequence of cognition layer\n",
        "\n",
        "      enw - epidemic pairwise network\n",
        "      ldeg_e - degree sequence of epidemic layer\n",
        "\n",
        "      lambda - information spreading rate\n",
        "      alp - informaiton stifling rate\n",
        "\n",
        "      zeta_1 - removing protection rate based on information\n",
        "      zeta_2 - removing protection rate based on neighborhood behavior\n",
        "      zeta_1 - adopting protection rate based on information\n",
        "      zeta_2 - adopting protection rate based on neighborhood behavior\n",
        "\n",
        "      beta_PP - disease transmission rate between protected S and protected I\n",
        "      beta_NP - disease transmission rate between not protected S and protected I\n",
        "      beta_PN - disease transmission rate between protected S and not protected I\n",
        "      beta_NN - disease transmission rate between not protected S and not protected I\n",
        "\n",
        "      mu - disease recovery rate\n",
        "\n",
        "      n_sample - number of samples\n",
        "  \"\"\"\n",
        "\n",
        "  t_max = 100000      # Set maximum time\n",
        "  kmax_i = max (ldeg_i)     # Get maximum hyperedge degree in information layer\n",
        "  kmax_c = max (ldeg_c)     # Get maximum hyperedge degree in cognition layer\n",
        "  kmax_e = max (ldeg_e)     # Get maximum degree in epidemic layer\n",
        "  N = inw.order()  # Get the network size\n",
        "\n",
        "  rho_C = []   # Keep track of fraction of corrected in information layer\n",
        "  rho_P = []   # Keep track of fraction of protected in cognition layer\n",
        "  rho_R = []   # Keep track of fraction of recovered in epidemic layer\n",
        "\n",
        "  for i_samp in range(1, n_sample + 1):\n",
        "      t = 0                 # Initialize time, number of corrected, number of recovered\n",
        "      N_corrected = 0\n",
        "      N_recovered = 0\n",
        "\n",
        "      info_states = {j: \"U\" for j in inw.nodes()}   # Initialize information and disease states\n",
        "      disease_states = {k: \"S\" for k in enw.nodes()}\n",
        "\n",
        "      protected = list(filter(lambda node: lprot[node] == \"P\", lprot))\n",
        "      N_protected = len(protected)\n",
        "      not_protected = list(filter(lambda node: lprot[node] == \"N\", lprot))\n",
        "\n",
        "\n",
        "      gossip = []     # Create lists to store gossip and corrected individuals in information layer\n",
        "      corrected = []\n",
        "\n",
        "      rumor_node_0 = np.random.choice(list(inw.nodes()))   # Pick a random person to start misinformaiton spreading\n",
        "      info_states[rumor_node_0] = \"G\"\n",
        "      gossip.append(rumor_node_0)\n",
        "      N_gossip = 1\n",
        "      N_e_i = inw.degree(rumor_node_0)\n",
        "\n",
        "      infected = []     # Create lists to store infected and recovered individuals in epidemic layer\n",
        "      recovered = []\n",
        "\n",
        "      ill_node_0 = np.random.choice(list(enw.nodes()))   # Pick a random person to start disease spreading\n",
        "      disease_states[ill_node_0] = \"I\"\n",
        "      infected.append(ill_node_0)\n",
        "      N_infected = 1\n",
        "      N_e_e = enw.degree(ill_node_0)\n",
        "\n",
        "      while N_gossip > 0:   # We stop when there is no infection and no gossip\n",
        "          total_rate = lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip + zeta_2 * (N-N_gossip) + zeta_3 * (N-N_protected) + zeta_4 * N_protected\n",
        "          tau = -np.log(np.random.uniform(1e-6, 1)) / total_rate\n",
        "          t += tau\n",
        "\n",
        "          if t >= t_max:\n",
        "                break\n",
        "\n",
        "          # Determine which event occurs\n",
        "          event = np.random.uniform()\n",
        "          p1 = (lam * N_e_i) / total_rate     # rumor spreading\n",
        "          p2 = (lam * N_e_i + alp * N_e_i) / total_rate  # rumor stifling (by meeting stifling neighbor threshold)\n",
        "          p3 = (lam * N_e_i + 2 * alp * N_e_i) / total_rate  # rumor stifling (by meeting gossip neighbor threshold)\n",
        "\n",
        "          p4 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e) / total_rate  # disease propagation\n",
        "          p5 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected) / total_rate  # disease recovery\n",
        "\n",
        "          p6 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip) / total_rate # change to not adopting protection by information\n",
        "          p7 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip + zeta_2 * (N-N_gossip)) / total_rate # change to adopting protection by information\n",
        "          p8 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip + zeta_2 * (N-N_gossip) + zeta_3 * (N-N_protected)) / total_rate # change to not adopting protection by neighborhood behavior\n",
        "          # > p8 # change to adopting protection by neighborhood behavior\n",
        "          #print(p1, p2, p3, p4, p5, p6, p7, p8)\n",
        "\n",
        "          # Determine if accept selected individual based on degree distribution\n",
        "          q_deg_i = np.random.uniform()\n",
        "          q_deg_c = np.random.uniform()\n",
        "          q_deg_e = np.random.uniform()\n",
        "\n",
        "          # Case 1: Rumor spreading\n",
        "          if event < p1:\n",
        "                gossip_node = random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(gossip_node) / kmax_i:\n",
        "                    rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[rumor_hyper_edge]\n",
        "                    \"\"\"\n",
        "                    while gossip_node not in neighbors:\n",
        "                        rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                        neighbors = inw[rumor_hyper_edge]\n",
        "                    \"\"\"\n",
        "                    MAX_ITERATIONS = 20 # Set a reasonable limit based on your specific case\n",
        "                    iterations = 0\n",
        "                    while gossip_node not in neighbors:\n",
        "                        if iterations > MAX_ITERATIONS:\n",
        "                           break\n",
        "                        rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                        neighbors = inw[rumor_hyper_edge]\n",
        "                        iterations += 1\n",
        "\n",
        "                    for neighbor in neighbors:\n",
        "                            if info_states[neighbor] == \"U\":\n",
        "                                count_gossip_neighbors = sum(1 for node in inw.neighbors(neighbor) if info_states[node] == \"G\")\n",
        "                                if count_gossip_neighbors / len(inw.neighbors(neighbor)) >= ltre[neighbor]:\n",
        "                                    info_states[neighbor] = \"G\"  # uninformed neighbor becomes gossip spreader\n",
        "                                    gossip.append(neighbor)\n",
        "                                    N_gossip += 1\n",
        "\n",
        "\n",
        "\n",
        "          # Case 2: Rumor stifling (by meeting stifling neighbor threshold)\n",
        "          elif event < p2:\n",
        "            #if N_gossip > 0:\n",
        "                stifler_node = np.random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(stifler_node)  / kmax_i:\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_stifler_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"C\")\n",
        "                    if count_stifler_neighbors / len(neighbors) >= ltre[stifler_node]:\n",
        "                            info_states[stifler_node] = \"C\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            corrected.append(stifler_node)\n",
        "                            N_corrected += 1\n",
        "\n",
        "          # Case 3: Rumor stifling (by meeting gossip neighbor threshold)\n",
        "          elif event < p3:\n",
        "            #if N_gossip > 0:\n",
        "                stifler_node = np.random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(stifler_node) / kmax_i:\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_gossip_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"G\")\n",
        "                    if count_gossip_neighbors / len(neighbors) >= ltre[stifler_node]:\n",
        "                            info_states[stifler_node] = \"C\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            corrected.append(stifler_node)\n",
        "                            N_corrected += 1\n",
        "\n",
        "          # Case 4: Disease propagation\n",
        "          elif event < p4:\n",
        "            if N_infected > 0:\n",
        "              infected_node = np.random.choice(infected)\n",
        "              infected_protected = lprot[infected_node]\n",
        "              neighbors = list(enw.neighbors(infected_node))\n",
        "              susceptible_neighbors = [n for n in neighbors if disease_states[n] == \"S\"]\n",
        "\n",
        "              if len(susceptible_neighbors) > 0:\n",
        "                  neighbor = np.random.choice(susceptible_neighbors)\n",
        "                  neighbor_protected = lprot[neighbor]\n",
        "\n",
        "                  # Determine the appropriate transmission rate based on protection status\n",
        "                  if neighbor_protected == \"P\" and infected_protected == \"P\":\n",
        "                            transmission_rate = beta_PP/beta_NN\n",
        "                  elif neighbor_protected == \"N\" and infected_protected == \"P\":\n",
        "                            transmission_rate = beta_NP/beta_NN\n",
        "                  elif neighbor_protected == \"P\" and infected_protected == \"N\":\n",
        "                            transmission_rate = beta_PN/beta_NN\n",
        "                  else:\n",
        "                            transmission_rate = beta_NN/beta_NN\n",
        "\n",
        "                  if np.random.uniform() < transmission_rate:\n",
        "                      disease_states[neighbor] = \"I\"\n",
        "                      infected.append(neighbor)\n",
        "                      N_infected += 1\n",
        "                      N_e_e += enw.degree(neighbor)\n",
        "\n",
        "          # Case 5: Disease recovery\n",
        "          elif event < p5:\n",
        "            if N_infected > 0:\n",
        "                recovered_node = np.random.choice(infected)\n",
        "                if q_deg_e < ldeg_e[recovered_node]/kmax_e:\n",
        "                    disease_states[recovered_node] = \"R\"\n",
        "                    infected.remove(recovered_node)\n",
        "                    recovered.append(recovered_node)\n",
        "                    N_infected -= 1\n",
        "                    N_recovered += 1\n",
        "                    N_e_e -= enw.degree(recovered_node)\n",
        "\n",
        "          # Case 6: # Change to not adopting protection based on information layer\n",
        "          # rate = zeta_1 * n_G / k_info\n",
        "          # n_G is the total spreader neighbors on the information layer,\n",
        "          # while k_info is the total neighbor count on the information layer\n",
        "          elif event < p6:\n",
        "            if len(protected) > 0:\n",
        "              node_to_not_protect = np.random.choice(protected)\n",
        "              n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_not_protect)))\n",
        "              k_info = len(inw.neighbors(node_to_not_protect))\n",
        "              if np.random.uniform() < zeta_1 * n_G / k_info:\n",
        "                    lprot[node_to_not_protect] = \"N\"\n",
        "                    protected.remove(node_to_not_protect)\n",
        "                    not_protected.append(node_to_not_protect)\n",
        "                    N_protected -= 1\n",
        "\n",
        "          # Case 7: Change to adopting protection based on information layer\n",
        "          # rate = zeta_2 * (1 - n_G / k_info)\n",
        "          elif event < p7:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_protect)))\n",
        "                k_info = len(inw.neighbors(node_to_protect))\n",
        "                if np.random.uniform() < zeta_2 * (1 - n_G / k_info):\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "\n",
        "\n",
        "          # Case 8: # Change to not adopting protection based on neighborhood behavior in cognition layer\n",
        "          # rate = zeta_3 * (1 - n_P / k_cog)\n",
        "          # n_P is the total protected neighbors on the cognition layer,\n",
        "          # while k_cog is the total neighbor count on the cognition layer\n",
        "          elif event < p8:\n",
        "            if len(protected) > 0:\n",
        "                node_to_not_protect = np.random.choice(protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_not_protect)))\n",
        "                k_cog = len(cnw.neighbors(node_to_not_protect))\n",
        "                if np.random.uniform() < zeta_3 * (1 - n_P / k_cog):\n",
        "                        lprot[node_to_not_protect] = \"N\"\n",
        "                        protected.remove(node_to_not_protect)\n",
        "                        not_protected.append(node_to_not_protect)\n",
        "                        N_protected -= 1\n",
        "\n",
        "\n",
        "          # Case 9: # Change to adopting protection based on neighborhood behavior in cognition layer\n",
        "          # rate = zeta_4 * n_P / k_cog\n",
        "          else:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_protect)))\n",
        "                k_cog = len(cnw.neighbors(node_to_protect))\n",
        "                if np.random.uniform() < zeta_4 * n_P / k_cog:\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "      #print(\"N_infected\", N_infected, \"N_gossip\", N_gossip)\n",
        "      if N_infected == 0:\n",
        "          corrected_frac = N_corrected / N\n",
        "          protected_frac = N_protected / N\n",
        "          recovered_frac = N_recovered / N\n",
        "          rho_C.append(corrected_frac)\n",
        "          rho_P.append(protected_frac)\n",
        "          rho_R.append(recovered_frac)\n",
        "          #print(\"corrected_frac\", corrected_frac, \"recovered_frac\", recovered_frac)\n",
        "\n",
        "  if len(rho_C)>0 and len(rho_P)>0 and len(rho_R)>0:\n",
        "      avg_rho_C = sum(rho_C) / len(rho_C)\n",
        "      avg_rho_P = sum(rho_P) / len(rho_P)\n",
        "      avg_rho_R = sum(rho_R) / len(rho_R)\n",
        "  else:\n",
        "      avg_rho_R = 0\n",
        "\n",
        "  return avg_rho_R\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ICE_model_block_superspreaders(inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample):\n",
        "\n",
        "  t_max = 100000      # Set maximum time\n",
        "  kmax_i = max (ldeg_i)     # Get maximum hyperedge degree in information layer\n",
        "  kmax_c = max (ldeg_c)     # Get maximum hyperedge degree in cognition layer\n",
        "  kmax_e = max (ldeg_e)     # Get maximum degree in epidemic layer\n",
        "  N = inw.order()  # Get the network size\n",
        "\n",
        "  rho_C = []   # Keep track of fraction of corrected in information layer\n",
        "  rho_P = []   # Keep track of fraction of protected in cognition layer\n",
        "  rho_R = []   # Keep track of fraction of recovered in epidemic layer\n",
        "\n",
        "  for i_samp in range(1, n_sample + 1):\n",
        "      t = 0                 # Initialize time, number of corrected, number of recovered\n",
        "      N_corrected = 0\n",
        "      N_recovered = 0\n",
        "\n",
        "      info_states = {j: \"U\" for j in inw.nodes()}   # Initialize information and disease states\n",
        "      disease_states = {k: \"S\" for k in enw.nodes()}\n",
        "\n",
        "      protected = list(filter(lambda node: lprot[node] == \"P\", lprot))\n",
        "      N_protected = len(protected)\n",
        "      not_protected = list(filter(lambda node: lprot[node] == \"N\", lprot))\n",
        "\n",
        "\n",
        "      gossip = []     # Create lists to store gossip and corrected individuals in information layer\n",
        "      corrected = []\n",
        "\n",
        "      rumor_node_0 = np.random.choice(list(inw.nodes()))   # Pick a random person to start misinformaiton spreading\n",
        "      info_states[rumor_node_0] = \"G\"\n",
        "      gossip.append(rumor_node_0)\n",
        "      N_gossip = 1\n",
        "      N_e_i = inw.degree(rumor_node_0)\n",
        "\n",
        "      infected = []     # Create lists to store infected and recovered individuals in epidemic layer\n",
        "      recovered = []\n",
        "\n",
        "      ill_node_0 = np.random.choice(list(enw.nodes()))   # Pick a random person to start disease spreading\n",
        "      disease_states[ill_node_0] = \"I\"\n",
        "      infected.append(ill_node_0)\n",
        "      N_infected = 1\n",
        "      N_e_e = enw.degree(ill_node_0)\n",
        "\n",
        "      while N_gossip > 0:   # We stop when there is no infection and no gossip\n",
        "          total_rate = lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip + zeta_2 * (N-N_gossip) + zeta_3 * (N-N_protected) + zeta_4 * N_protected\n",
        "          tau = -np.log(np.random.uniform(1e-6, 1)) / total_rate\n",
        "          t += tau\n",
        "\n",
        "          if t >= t_max:\n",
        "                break\n",
        "\n",
        "          # Determine which event occurs\n",
        "          event = np.random.uniform()\n",
        "          p1 = (lam * N_e_i) / total_rate     # rumor spreading\n",
        "          p2 = (lam * N_e_i + alp * N_e_i) / total_rate  # rumor stifling (by meeting stifling neighbor threshold)\n",
        "          p3 = (lam * N_e_i + 2 * alp * N_e_i) / total_rate  # rumor stifling (by meeting gossip neighbor threshold)\n",
        "\n",
        "          p4 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e) / total_rate  # disease propagation\n",
        "          p5 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected) / total_rate  # disease recovery\n",
        "\n",
        "          p6 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip) / total_rate # change to not adopting protection by information\n",
        "          p7 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip + zeta_2 * (N-N_gossip)) / total_rate # change to adopting protection by information\n",
        "          p8 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip + zeta_2 * (N-N_gossip) + zeta_3 * (N-N_protected)) / total_rate # change to not adopting protection by neighborhood behavior\n",
        "          # > p8 # change to adopting protection by neighborhood behavior\n",
        "          #print(p1, p2, p3, p4, p5, p6, p7, p8)\n",
        "\n",
        "          # Determine if accept selected individual based on degree distribution\n",
        "          q_deg_i = np.random.uniform()\n",
        "          q_deg_c = np.random.uniform()\n",
        "          q_deg_e = np.random.uniform()\n",
        "\n",
        "          # Case 1: Rumor spreading\n",
        "          if event < p1:\n",
        "                gossip_node = random.choice(gossip)\n",
        "                if inw.degree(gossip_node) > 10:\n",
        "                    break\n",
        "                if q_deg_i < inw.degree(gossip_node) / kmax_i:\n",
        "                    rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[rumor_hyper_edge]\n",
        "                    \"\"\"\n",
        "                    while gossip_node not in neighbors:\n",
        "                        rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                        neighbors = inw[rumor_hyper_edge]\n",
        "                    \"\"\"\n",
        "                    MAX_ITERATIONS = 20 # Set a reasonable limit based on your specific case\n",
        "                    iterations = 0\n",
        "                    while gossip_node not in neighbors:\n",
        "                        if iterations > MAX_ITERATIONS:\n",
        "                           break\n",
        "                        rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                        neighbors = inw[rumor_hyper_edge]\n",
        "                        iterations += 1\n",
        "\n",
        "                    for neighbor in neighbors:\n",
        "                            if info_states[neighbor] == \"U\":\n",
        "                                count_gossip_neighbors = sum(1 for node in inw.neighbors(neighbor) if info_states[node] == \"G\")\n",
        "                                if count_gossip_neighbors / len(inw.neighbors(neighbor)) >= ltre[neighbor]:\n",
        "                                    info_states[neighbor] = \"G\"  # uninformed neighbor becomes gossip spreader\n",
        "                                    gossip.append(neighbor)\n",
        "                                    N_gossip += 1\n",
        "\n",
        "          # Case 2: Rumor stifling (by meeting stifling neighbor threshold)\n",
        "          elif event < p2:\n",
        "            #if N_gossip > 0:\n",
        "                stifler_node = np.random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(stifler_node)  / kmax_i:\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_stifler_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"C\")\n",
        "                    if count_stifler_neighbors / len(neighbors) >= ltre[stifler_node]:\n",
        "                            info_states[stifler_node] = \"C\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            corrected.append(stifler_node)\n",
        "                            N_corrected += 1\n",
        "\n",
        "          # Case 3: Rumor stifling (by meeting gossip neighbor threshold)\n",
        "          elif event < p3:\n",
        "            #if N_gossip > 0:\n",
        "                stifler_node = np.random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(stifler_node) / kmax_i:\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_gossip_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"G\")\n",
        "                    if count_gossip_neighbors / len(neighbors) >= ltre[stifler_node]:\n",
        "                            info_states[stifler_node] = \"C\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            corrected.append(stifler_node)\n",
        "                            N_corrected += 1\n",
        "\n",
        "          # Case 4: Disease propagation\n",
        "          elif event < p4:\n",
        "            if N_infected > 0:\n",
        "              infected_node = np.random.choice(infected)\n",
        "              infected_protected = lprot[infected_node]\n",
        "              neighbors = list(enw.neighbors(infected_node))\n",
        "              susceptible_neighbors = [n for n in neighbors if disease_states[n] == \"S\"]\n",
        "\n",
        "              if len(susceptible_neighbors) > 0:\n",
        "                  neighbor = np.random.choice(susceptible_neighbors)\n",
        "                  neighbor_protected = lprot[neighbor]\n",
        "\n",
        "                  # Determine the appropriate transmission rate based on protection status\n",
        "                  if neighbor_protected == \"P\" and infected_protected == \"P\":\n",
        "                            transmission_rate = beta_PP/beta_NN\n",
        "                  elif neighbor_protected == \"N\" and infected_protected == \"P\":\n",
        "                            transmission_rate = beta_NP/beta_NN\n",
        "                  elif neighbor_protected == \"P\" and infected_protected == \"N\":\n",
        "                            transmission_rate = beta_PN/beta_NN\n",
        "                  else:\n",
        "                            transmission_rate = beta_NN/beta_NN\n",
        "\n",
        "                  if np.random.uniform() < transmission_rate:\n",
        "                      disease_states[neighbor] = \"I\"\n",
        "                      infected.append(neighbor)\n",
        "                      N_infected += 1\n",
        "                      N_e_e += enw.degree(neighbor)\n",
        "\n",
        "          # Case 5: Disease recovery\n",
        "          elif event < p5:\n",
        "            if N_infected > 0:\n",
        "                recovered_node = np.random.choice(infected)\n",
        "                if q_deg_e < ldeg_e[recovered_node]/kmax_e:\n",
        "                    disease_states[recovered_node] = \"R\"\n",
        "                    infected.remove(recovered_node)\n",
        "                    recovered.append(recovered_node)\n",
        "                    N_infected -= 1\n",
        "                    N_recovered += 1\n",
        "                    N_e_e -= enw.degree(recovered_node)\n",
        "\n",
        "          # Case 6: # Change to not adopting protection based on information layer\n",
        "          # rate = zeta_1 * n_G / k_info\n",
        "          # n_G is the total spreader neighbors on the information layer,\n",
        "          # while k_info is the total neighbor count on the information layer\n",
        "          elif event < p6:\n",
        "            if len(protected) > 0:\n",
        "              node_to_not_protect = np.random.choice(protected)\n",
        "              n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_not_protect)))\n",
        "              k_info = len(inw.neighbors(node_to_not_protect))\n",
        "              if np.random.uniform() < zeta_1 * n_G / k_info:\n",
        "                    lprot[node_to_not_protect] = \"N\"\n",
        "                    protected.remove(node_to_not_protect)\n",
        "                    not_protected.append(node_to_not_protect)\n",
        "                    N_protected -= 1\n",
        "\n",
        "          # Case 7: Change to adopting protection based on information layer\n",
        "          # rate = zeta_2 * (1 - n_G / k_info)\n",
        "          elif event < p7:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_protect)))\n",
        "                k_info = len(inw.neighbors(node_to_protect))\n",
        "                if np.random.uniform() < zeta_2 * (1 - n_G / k_info):\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "\n",
        "\n",
        "          # Case 8: # Change to not adopting protection based on neighborhood behavior in cognition layer\n",
        "          # rate = zeta_3 * (1 - n_P / k_cog)\n",
        "          # n_P is the total protected neighbors on the cognition layer,\n",
        "          # while k_cog is the total neighbor count on the cognition layer\n",
        "          elif event < p8:\n",
        "            if len(protected) > 0:\n",
        "                node_to_not_protect = np.random.choice(protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_not_protect)))\n",
        "                k_cog = len(cnw.neighbors(node_to_not_protect))\n",
        "                if np.random.uniform() < zeta_3 * (1 - n_P / k_cog):\n",
        "                        lprot[node_to_not_protect] = \"N\"\n",
        "                        protected.remove(node_to_not_protect)\n",
        "                        not_protected.append(node_to_not_protect)\n",
        "                        N_protected -= 1\n",
        "\n",
        "\n",
        "          # Case 9: # Change to adopting protection based on neighborhood behavior in cognition layer\n",
        "          # rate = zeta_4 * n_P / k_cog\n",
        "          else:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_protect)))\n",
        "                k_cog = len(cnw.neighbors(node_to_protect))\n",
        "                if np.random.uniform() < zeta_4 * n_P / k_cog:\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "      #print(\"N_infected\", N_infected, \"N_gossip\", N_gossip)\n",
        "      if N_infected == 0:\n",
        "          corrected_frac = N_corrected / N\n",
        "          protected_frac = N_protected / N\n",
        "          recovered_frac = N_recovered / N\n",
        "          rho_C.append(corrected_frac)\n",
        "          rho_P.append(protected_frac)\n",
        "          rho_R.append(recovered_frac)\n",
        "          #print(\"corrected_frac\", corrected_frac, \"recovered_frac\", recovered_frac)\n",
        "  if len(rho_C)>0 and len(rho_P)>0 and len(rho_R)>0:\n",
        "      avg_rho_C = sum(rho_C) / len(rho_C)\n",
        "      avg_rho_P = sum(rho_P) / len(rho_P)\n",
        "      avg_rho_R = sum(rho_R) / len(rho_R)\n",
        "  else:\n",
        "      avg_rho_R = 0\n",
        "\n",
        "  return avg_rho_C, avg_rho_P, avg_rho_R"
      ],
      "metadata": {
        "id": "dRIIjI9qhcrq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_NnnBI-BZpo",
        "outputId": "215d42a0-3348-4ff9-9efb-656a298aa70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degree Sequence:  [3, 3, 3, 6, 3, 3, 7, 3, 6, 3, 3, 4, 3, 3, 5, 5, 3, 5, 3, 6, 14, 3, 4, 4, 3, 4, 3, 6, 3, 3, 3, 7, 6, 4, 3, 4, 4, 3, 3, 14, 4, 3, 3, 5, 3, 4, 3, 5, 3, 4, 3, 3, 5, 6, 3, 3, 3, 3, 3, 4, 3, 12, 3, 4, 4, 3, 3, 3, 6, 3, 6, 5, 4, 4, 3, 4, 6, 19, 4, 3, 12, 5, 4, 3, 3, 6, 4, 5, 5, 8, 5, 3, 3, 3, 4, 3, 17, 3, 12, 6, 7, 3, 5, 7, 5, 8, 7, 3, 3, 3, 3, 5, 6, 3, 15, 5, 10, 4, 6, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 9, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [31, 31, 16, 14, 14, 9, 4, 16, 12, 24, 6, 27, 30, 8, 31, 31, 15, 29, 30, 27, 4, 24, 21, 20, 7, 32, 22, 34, 25, 26, 30, 26, 34, 17, 14, 37, 9, 29, 18, 32, 25, 27, 6, 12, 28, 24, 12, 31, 36, 17, 28, 4, 22, 25, 18, 13, 21, 7, 36, 22, 15, 32, 8, 35, 16, 14, 25, 34, 35, 33, 28, 11, 21, 4, 32, 29, 28, 17, 37, 16, 26, 3, 18, 30, 12, 20, 28, 8, 31, 3, 12, 34, 15, 23, 3, 13, 12, 11, 15, 3]\n",
            "Hypergraph Dictionary:  {14: [0, 18, 39, 40, 68, 75, 78, 79, 90, 168, 169, 180, 185, 188, 195, 205, 234, 315, 334, 344, 355, 385, 386], 9: [0, 8, 53, 77, 80, 91, 93, 98, 103, 163, 174, 202, 216, 226, 231], 48: [0, 14, 17, 19, 57, 67, 74, 75, 78, 106, 109, 112, 155, 200, 225, 237, 260, 263, 296, 305, 321, 325, 331, 365, 368, 371, 381, 389, 392], 36: [1, 33, 53, 71, 111, 164, 249], 2: [1, 2, 44, 57, 80, 85, 105, 114, 135, 191, 253], 67: [1, 7, 9, 18, 19, 20, 33, 39, 53, 70, 89, 103, 111, 114, 128, 136, 153, 158, 220, 276, 303, 336], 80: [2, 8, 22, 68, 79, 116, 125, 126, 133, 160, 187, 208, 218, 265, 303, 381, 387], 49: [2, 28, 34, 47, 86, 100, 148, 151, 175, 177, 179, 204, 374], 28: [3, 12, 61, 62, 80, 92, 101, 112, 129, 152, 157, 212, 241, 242, 252, 261, 268, 277, 332], 68: [3, 15, 27, 30, 77, 80, 92, 96, 98, 121, 128, 163, 170, 214, 235, 266, 294, 309, 341, 348, 353, 366], 21: [3, 32, 39, 59, 72, 76, 103, 117, 142, 185, 230, 241, 258, 317, 321, 354, 398], 35: [3, 16, 22, 84, 85, 96, 98, 102, 141, 154, 161, 186, 198, 206, 220, 224, 229, 236, 266, 308, 328, 344, 363, 385], 98: [3, 31, 44, 69, 122, 183, 232, 243, 315, 324, 330, 398], 44: [3, 6, 10, 42, 48, 80, 81, 82, 119, 147, 149, 165, 210, 235, 241, 248, 304, 323, 331, 346, 390, 396], 4: [4, 39, 71, 73, 112, 137, 210, 275, 284, 314, 370], 33: [4, 17, 61, 77, 89, 130, 142, 175, 253, 259, 271, 285, 360, 370], 88: [4, 22, 36, 60, 77, 88, 94, 98, 102, 152, 246, 278, 288, 294, 334, 344, 347, 357, 369, 380], 27: [5, 6, 14, 15, 21, 64, 77, 98, 149, 158, 170, 183, 259, 281, 287, 292, 316, 375, 384], 91: [5, 31, 32, 64, 78, 80, 94, 104, 111, 123, 201, 205, 212, 247, 250, 258, 272, 296, 301, 324, 333, 334, 342, 379], 86: [5, 43, 61, 82, 88, 91, 96, 117, 202, 214, 222, 224, 228, 237, 239, 250, 285, 306, 320, 372, 385], 74: [6, 12, 29, 38, 46, 47, 70, 77, 80, 108, 115, 118, 120, 148, 174, 233, 247, 254, 310, 373, 382, 396], 8: [6, 20, 43, 54, 105, 161, 301, 387], 45: [6, 29, 39, 47, 86, 88, 90, 112, 116, 120, 132, 218, 240, 248, 295, 348], 72: [6, 28, 61, 69, 70, 96, 122, 143, 226, 233, 239, 244], 61: [6, 36, 37, 52, 54, 76, 77, 88, 90, 95, 96, 161, 167, 180, 207, 227, 240, 245, 283, 289, 306, 310, 365, 382, 386], 0: [7, 20, 28, 72, 85, 99, 114, 133, 134, 138, 234, 237, 295, 309, 326, 329, 341, 372, 379, 390, 395], 17: [7, 18, 76, 87, 100, 103, 137, 138, 166, 197, 198, 230, 254, 298, 313, 333, 351, 359, 362, 376, 393], 43: [8, 51, 93, 151, 194, 265, 269, 291, 332, 352], 18: [8, 39, 56, 61, 80, 89, 105, 114, 116, 120, 126, 145, 151, 181, 184, 189, 246, 274, 284, 288, 313, 345, 397], 26: [8, 10, 33, 52, 65, 85, 91, 99, 127, 146, 251, 293, 299, 317, 338, 342, 368], 23: [8, 68, 99, 100, 104, 110, 112, 156, 201, 225, 277, 377, 388], 40: [9, 20, 25, 35, 52, 86, 96, 105, 116, 133, 145, 165, 249, 286, 287, 289, 351, 366, 393], 92: [9, 23, 25, 39, 50, 129, 138, 199, 297, 367], 90: [10, 30, 100, 153, 328], 15: [11, 20, 40, 95, 106, 159, 194, 219, 231, 265, 290, 309, 316, 323, 345, 373], 12: [11, 19, 20, 31, 45, 49, 65, 83, 96, 99, 103, 105, 113, 168, 178, 195, 239, 269, 293, 318, 358, 389], 55: [11, 57, 89, 114, 142, 325], 54: [11, 46, 56, 73, 89, 129, 193, 195, 202, 256, 270], 95: [12, 71, 115, 181, 251, 268, 307, 335], 93: [13, 35, 84, 99, 114, 140, 148, 199, 236, 292, 304, 340, 396, 397], 19: [13, 31, 39, 49, 92, 96, 107, 114, 115, 129, 162, 179, 184, 211, 231, 257, 258, 275, 384], 5: [13, 150, 250, 254, 256, 357, 378, 394], 20: [14, 217], 31: [14, 17, 30, 66, 70, 77, 110, 127, 180, 229, 240, 320, 333, 394], 76: [14, 20, 27, 64, 72, 77, 98, 108, 140, 147, 171, 194, 205, 232, 278, 280, 283, 284, 305, 322, 362, 367, 381], 65: [15, 104, 105, 107, 119, 181, 185, 213, 230], 96: [15, 77, 82, 106, 243, 294, 327, 388], 37: [15, 40, 45, 50, 63, 74, 81, 102, 114, 190, 196, 218, 220, 232, 233, 243, 269, 297, 302, 349, 350], 3: [16, 50, 62, 100, 101, 105, 139, 162, 209, 337, 346, 374], 58: [16, 27, 63, 77, 87, 88, 102, 117, 124, 172, 215, 276, 286, 321, 324, 339, 363, 371, 376], 50: [17, 22, 24, 49, 61, 73, 77, 100, 125, 146, 179, 200, 217, 226, 235, 262, 273, 281], 25: [17, 19, 49, 55, 60, 68, 84, 106, 114, 118, 173, 192, 238, 299, 301, 346, 356, 359], 30: [19, 37, 47, 59, 61, 83, 96, 116, 120, 126, 166, 173, 177, 191, 203, 219, 223, 264, 300, 319, 322, 368, 378, 383, 384, 397], 75: [19, 75, 80, 82, 83, 89, 93, 95, 105, 134, 139, 165, 263, 274, 308, 362, 364], 83: [20, 39, 60, 123, 129, 153, 160, 171, 192, 196, 245, 271, 272, 281, 291, 295, 300, 310, 318, 328, 358, 367, 371], 82: [20, 34, 85, 96, 103, 116, 146, 154, 197, 199, 282, 302, 307, 343, 352], 16: [20, 162, 164, 178, 209, 211, 228, 262, 278, 305, 326, 347], 60: [20, 48, 58, 78, 90, 157, 225, 349, 351], 73: [20, 398], 64: [20, 27, 38, 45, 52, 106, 112, 143, 260, 317, 364], 11: [20, 25, 39, 77, 89, 118, 157, 167, 176, 177, 189, 217, 229, 247, 273, 311, 343, 376], 79: [21, 39, 96, 100, 114, 129, 135, 244, 251, 322, 356, 399], 34: [21, 51, 81, 85, 156, 190, 246, 372], 63: [23, 26, 39, 51, 54, 77, 114, 130, 132, 182, 200, 208, 213, 261, 282, 287, 336, 339, 353, 375, 380, 383, 387, 392], 85: [23, 43, 96, 118, 122, 124, 160, 172, 182, 314, 331, 356, 380, 395], 69: [23, 36, 61, 70, 71, 75, 81, 98, 114, 140, 143, 214, 221, 238, 255, 267, 293, 337, 341, 342, 347, 360, 361, 366, 379, 399], 53: [24, 27, 31, 35, 61, 72, 97, 118, 150, 156, 159, 174, 207, 314, 350, 357, 370, 399], 52: [24, 45, 62, 64, 69, 76, 108, 116, 171, 173, 206, 296, 358, 378], 57: [25, 53, 58, 339], 59: [26, 71, 89, 111, 139, 196, 222, 249, 268, 279, 297, 374], 38: [26, 38, 61, 65, 70, 101, 168, 204, 211, 215, 252, 257, 267, 273, 335], 29: [27, 43, 55, 56, 87, 96, 145, 167, 176, 183, 198, 255, 292, 311, 316, 325, 348, 353, 369], 39: [29, 53, 86, 98, 114, 123, 141, 154, 163, 169, 197, 201, 223, 227, 228, 234, 255, 260, 274, 282, 312, 330, 332, 338, 340, 343, 354, 377], 22: [31, 43, 59, 120, 129, 134, 136, 166, 329, 335, 340, 392], 78: [31, 87, 96, 102, 130, 149, 159, 169, 175, 176, 186, 187, 189, 192, 206, 238, 244, 253, 262, 264, 306, 327, 329], 10: [32, 35, 37, 48, 63, 223], 77: [32, 77, 80, 115, 150, 216, 318, 319, 352], 42: [32, 66, 117, 299], 1: [32, 61, 74, 97, 98, 135, 155, 193, 203, 215, 222, 267, 290, 298, 312, 345, 354, 375, 391], 41: [33, 63, 67, 76, 96, 98, 109, 131, 137, 182, 207, 248, 257, 272, 280, 303, 330, 361, 391, 394], 47: [34, 44, 61, 66, 68, 106, 109, 114, 115, 127, 178, 204, 208, 227, 270, 300, 308, 359, 391], 7: [36, 120, 136, 144, 188, 210, 264, 320, 336], 84: [39, 76, 110, 114, 252, 277, 311, 373], 70: [39, 42, 46, 67, 77, 79, 81, 94, 118, 121, 188, 242, 279, 283, 302, 307, 323, 327, 355, 369], 51: [40, 41, 224], 32: [41, 53, 58, 80, 94, 96, 113, 124, 129, 158, 184, 191, 219, 280, 290, 304, 319, 337, 350, 388], 56: [41, 42, 77, 90, 99, 104, 121, 125, 164, 221, 236, 261, 275, 285, 286, 298, 338, 395], 99: [47, 98, 131], 6: [52, 77, 186], 66: [55, 68, 98, 104, 106, 111, 116, 129, 131, 132, 152, 170, 190, 212, 221, 256, 259, 271, 276, 315, 363], 94: [59, 291, 389], 13: [73, 80, 144, 203, 383, 393], 87: [77, 187, 245, 312], 46: [87, 97, 116, 172, 209, 349, 361, 377, 382, 390], 81: [96, 128], 97: [103, 144, 213, 270, 313, 326, 364], 62: [107, 147, 193, 242, 288, 360, 365], 71: [113, 116, 119, 216, 279, 289], 24: [141, 155, 266, 355, 386], 89: [263]}\n",
            "Degree Sequence:  [5, 3, 10, 5, 3, 3, 4, 18, 7, 4, 3, 4, 4, 3, 7, 12, 3, 4, 3, 3, 3, 3, 4, 3, 3, 3, 4, 8, 3, 3, 11, 4, 3, 13, 3, 5, 5, 5, 10, 3, 3, 3, 5, 3, 3, 13, 3, 4, 7, 3, 3, 7, 3, 3, 5, 4, 3, 5, 6, 3, 3, 3, 3, 4, 5, 3, 9, 4, 3, 4, 5, 3, 3, 4, 5, 3, 4, 9, 3, 3, 3, 4, 4, 4, 3, 4, 3, 5, 3, 5, 5, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [23, 28, 9, 14, 35, 15, 17, 34, 11, 23, 12, 9, 18, 34, 21, 21, 10, 28, 35, 6, 3, 26, 26, 11, 13, 7, 24, 20, 24, 25, 15, 18, 13, 34, 10, 9, 7, 26, 2, 7, 7, 20, 13, 30, 36, 7, 17, 9, 33, 29, 11, 11, 8, 32, 10, 32, 16, 15, 18, 9, 26, 27, 3, 6, 20, 36, 31, 29, 5, 14, 27, 32, 14, 35, 19, 8, 7, 18, 27, 33, 36, 11, 14, 31, 28, 17, 5, 33, 2, 22, 24, 9, 5, 2, 30, 16, 18, 15, 2, 18]\n",
            "Hypergraph Dictionary:  {2: [0, 4, 106, 148, 191, 232, 289, 325], 86: [0, 153, 176, 209], 43: [0, 33, 36, 66, 77, 78, 95, 113, 137, 154, 198, 242, 272, 273, 274, 285, 322, 335, 341, 350, 355, 364, 387], 22: [0, 14, 25, 29, 73, 83, 107, 112, 126, 148, 172, 174, 179, 182, 230, 236, 318, 324, 368, 395, 399], 10: [0, 8, 13, 66, 80, 174, 218, 347], 61: [1, 4, 7, 51, 78, 87, 137, 164, 172, 189, 208, 230, 251, 272, 295, 308, 349, 376, 390], 0: [1, 2, 9, 13, 18, 72, 79, 89, 90, 94, 120, 165, 248, 255, 284, 298, 301, 311, 350, 370], 7: [1, 7, 9, 49, 57, 58, 65, 73, 77, 112, 116, 145, 166, 176, 206, 232, 236, 254, 258, 299, 335, 336, 367], 97: [2, 14, 77, 79, 117, 163, 280, 291, 295, 300], 37: [2, 8, 40, 66, 117, 126, 151, 238, 244, 261, 272, 283, 294, 320, 354, 368, 385, 392], 6: [2, 3, 16, 33, 54, 103, 152, 154, 284, 297, 326], 17: [2, 5, 6, 30, 45, 52, 64, 121, 134, 179, 188, 203, 204, 215, 234, 239, 321, 324, 337, 342, 343, 371, 377, 383], 48: [2, 7, 29, 39, 52, 64, 83, 95, 158, 160, 162, 175, 213, 231, 245, 249, 253, 255, 268, 293, 297, 321, 373, 399], 18: [2, 45, 51, 53, 59, 66, 69, 81, 90, 99, 118, 120, 140, 163, 169, 209, 220, 252, 290, 362, 375, 395], 32: [2, 37, 38, 39, 42, 195, 200, 283, 333], 70: [2, 30, 48, 64, 81, 92, 136, 163, 186, 200, 212, 231, 233, 244, 273, 281, 282, 314, 332, 341, 392], 60: [2, 10, 49, 51, 57, 76, 82, 118, 130, 138, 150, 170, 184, 191, 196, 222, 229, 250, 276, 330, 355], 53: [3, 14, 15, 27, 42, 54, 76, 133, 140, 168, 171, 198, 211, 221, 284, 315, 338, 356, 389, 398], 65: [3, 6, 12, 18, 25, 26, 30, 33, 38, 85, 87, 99, 107, 109, 116, 117, 125, 130, 152, 162, 190, 219, 237, 242, 243, 257, 310, 320, 379], 19: [3, 15, 35, 70, 381], 4: [3, 7, 15, 28, 33, 44, 84, 111, 126, 166, 173, 181, 202, 211, 213, 214, 236, 260, 265, 275, 296, 297, 304, 311, 320, 346, 350, 352, 353], 13: [4, 6, 40, 41, 62, 68, 70, 77, 80, 87, 88, 132, 147, 155, 178, 183, 195, 207, 208, 225, 227, 241, 279, 306, 326, 328], 50: [5, 26, 124, 142, 189, 229, 275, 391], 78: [5, 35, 82, 93, 98, 119, 136, 167, 168, 181, 225, 273, 294, 303, 356, 358, 364, 384, 390], 87: [6, 7, 11, 15, 45, 47, 55, 75, 155, 214, 241, 260, 278, 292, 309, 346, 377], 42: [7, 61, 114, 132, 171, 197, 270, 309, 334, 360], 34: [7, 17, 22, 91, 247, 303, 307, 394], 69: [7, 11, 15, 22, 48, 150, 151, 159, 185, 333, 359], 1: [7, 27, 36, 56, 60, 120, 200, 201, 226, 239, 243, 247, 257, 264, 286, 307, 312, 315, 318, 319, 326, 331], 64: [7, 29, 31, 71, 81, 134, 151, 154, 155, 256, 266, 271, 301, 307, 325, 340], 79: [7, 15, 16, 33, 88, 89, 97, 115, 123, 146, 177, 178, 207, 222, 233, 259, 263, 293, 339, 373, 385, 388], 95: [7, 19, 26, 60, 94, 142, 150, 161, 224, 279, 281, 306, 365], 49: [7, 21, 54, 84, 91, 121, 122, 141, 144, 164, 177, 227, 286, 292, 304, 330, 351, 370, 373, 382], 55: [7, 28, 57, 69, 86, 127, 156, 158, 164, 174, 175, 210, 216, 250, 262, 336, 372, 376, 378, 386, 398], 29: [7, 18, 23, 30, 51, 67, 74, 84, 180, 187, 209, 262, 289, 299, 311, 312, 317, 358, 391, 393], 27: [7, 30, 33, 66, 74, 123, 133, 146, 301, 303, 382, 392], 30: [7, 15, 77, 127, 128, 138, 182, 251, 277, 305, 329, 338, 371, 388], 57: [7, 9, 35, 85, 113, 131, 256, 327, 375], 99: [8, 14, 33, 61, 90, 91, 110, 129, 139, 156, 157, 169, 240, 250, 292, 323], 28: [8, 15, 30, 33, 47, 55, 65, 72, 82, 114, 158, 193, 201, 215, 245, 260, 334, 347, 354], 96: [8, 9, 27, 45, 58, 68, 74, 103, 141, 321, 337, 367, 386], 74: [8, 102, 106, 125, 131, 134, 138, 143, 187, 223, 226, 234, 268, 269, 331, 345], 56: [8, 23, 32, 38, 48, 103, 105, 228, 291, 305, 329], 54: [10, 24, 34, 74, 78, 202, 313, 381], 46: [10, 30, 38, 58, 62, 63, 88, 104, 105, 108, 188, 192, 255, 261, 290], 58: [11, 27, 45, 48, 75, 190, 220, 238, 245, 302, 344], 51: [11, 184, 332, 345, 380, 388, 396], 23: [12, 40, 94, 110, 112, 132, 149, 183, 363], 66: [12, 20, 71, 83, 89, 92, 98, 108, 116, 122, 123, 145, 165, 179, 228, 239, 252, 267, 280, 323, 328, 348, 357, 361, 376], 76: [12, 15, 263, 266, 287, 289, 323], 26: [13, 30, 38, 45, 86, 105, 124, 127, 147, 167, 222, 251, 254, 263, 300, 318, 322, 331, 379, 380], 73: [14, 46, 48, 69, 82, 101, 153, 156, 161, 181, 199, 203, 221, 235, 240, 265, 279, 298, 302, 327, 340, 341, 393, 396], 89: [14, 32, 79, 80, 135, 166, 173, 186, 196, 205, 218, 223, 227, 248, 267, 274, 276, 313], 94: [14, 27, 33, 51, 85, 100, 165, 192, 248, 249, 258, 281, 287, 302, 310, 336, 351, 357, 374, 375, 393], 3: [15, 27, 111, 133, 256, 312, 316, 369, 387, 397], 90: [15, 33, 38, 45, 65, 124, 145, 170, 190, 246, 257, 286, 308, 343, 360, 366, 385, 389], 67: [15, 20, 25, 31, 43, 45, 62, 69, 97, 111, 178, 219, 295, 298, 327, 340, 361, 362, 382, 394], 85: [16, 34, 48, 58, 102, 107, 131, 142, 149, 309, 314, 330, 332, 361, 369], 5: [17, 38, 57, 66, 137, 143, 172, 189, 196, 347, 390], 80: [17, 50, 70, 75, 77, 87, 96, 108, 113, 128, 171, 180, 182, 184, 185, 187, 193, 194, 202, 203, 214, 242, 316, 372, 383, 384, 395], 36: [17, 42, 66, 267], 33: [19, 33, 43, 56, 77, 93, 109, 135, 162, 173, 199, 223, 225, 235, 254, 258, 277, 296, 304, 335, 353, 369, 372], 44: [19, 27, 35, 45, 46, 51, 54, 67, 73, 81, 90, 143, 186, 204, 205, 210, 213, 237, 247, 262, 277, 278, 300, 328, 344, 349, 399], 81: [20, 96, 334, 342, 377, 378], 45: [21, 24, 41, 55, 169, 212], 11: [21, 68, 92, 159, 234, 252, 288, 337, 354], 92: [22, 42, 70, 208, 291], 72: [22, 28, 45, 66, 216, 224, 226, 314, 358], 62: [23, 394], 83: [24, 45, 50, 63, 76, 93, 100, 129, 139, 153, 161, 191, 210, 233, 249, 253, 264, 271, 285, 339, 366, 381], 39: [26, 90, 180, 246, 270, 380, 397], 84: [27, 36, 63, 64, 76, 85, 114, 141, 220, 228, 237, 244, 275, 287, 288, 299, 342, 351, 362, 365, 366], 68: [30, 83, 175, 232, 259], 41: [30, 31, 37, 38, 47, 77, 118, 198, 270, 276, 305, 359, 383], 59: [30, 63, 177, 188, 306, 374], 77: [31, 98, 99, 101, 104, 195, 243, 315, 359, 360, 363, 364, 374], 9: [32, 45, 73, 89, 106, 136, 159, 193, 197, 221, 265, 325, 338, 391], 15: [33, 34, 37, 44, 48, 52, 53, 57, 66, 74, 119, 135, 204, 264, 280, 296, 308, 389], 98: [33, 152], 14: [35, 42, 67, 95, 96, 101, 109, 140, 144, 148, 201, 212, 216, 217, 230, 317], 52: [36, 56, 72, 139, 207, 370], 21: [36, 38, 43, 50, 71, 77, 167, 168, 194, 197, 219, 269, 271, 319, 346, 371, 397], 91: [37, 41, 130, 192, 218, 240, 352], 71: [37, 44, 47, 51, 53, 61, 67, 86, 87, 97, 157, 170, 206, 217, 224, 282, 316, 317, 322, 339, 344, 367, 398], 82: [38, 55, 104, 115, 149, 217, 246, 269, 319, 333, 396], 8: [39, 49, 58, 59, 92, 343, 345], 47: [45, 54, 211, 290, 329], 31: [46, 89, 122, 231, 235, 294, 349, 357, 365, 379], 40: [58, 70, 129, 176, 205, 283, 348], 35: [59, 102, 110, 144, 199, 313], 25: [60, 146, 183, 238, 266], 20: [64, 310], 24: [100, 194, 229, 278, 282, 348, 356, 387], 16: [115, 121, 128, 160, 241, 274, 368], 12: [119, 157, 185, 206, 268, 285, 293, 324, 352, 363, 378, 384, 386], 75: [125, 215, 253, 261, 353], 93: [147, 288], 63: [160, 259], 38: [355]}\n",
            "{0: 'N', 1: 'N', 2: 'N', 3: 'P', 4: 'N', 5: 'N', 6: 'N', 7: 'N', 8: 'N', 9: 'N', 10: 'N', 11: 'N', 12: 'N', 13: 'N', 14: 'N', 15: 'N', 16: 'N', 17: 'N', 18: 'N', 19: 'N', 20: 'N', 21: 'N', 22: 'N', 23: 'N', 24: 'P', 25: 'N', 26: 'N', 27: 'N', 28: 'P', 29: 'P', 30: 'N', 31: 'P', 32: 'N', 33: 'N', 34: 'N', 35: 'N', 36: 'N', 37: 'P', 38: 'P', 39: 'N', 40: 'N', 41: 'N', 42: 'N', 43: 'N', 44: 'N', 45: 'N', 46: 'N', 47: 'N', 48: 'N', 49: 'N', 50: 'N', 51: 'N', 52: 'P', 53: 'N', 54: 'N', 55: 'N', 56: 'N', 57: 'N', 58: 'N', 59: 'N', 60: 'N', 61: 'N', 62: 'N', 63: 'N', 64: 'N', 65: 'N', 66: 'N', 67: 'N', 68: 'N', 69: 'N', 70: 'N', 71: 'N', 72: 'N', 73: 'N', 74: 'N', 75: 'N', 76: 'N', 77: 'N', 78: 'P', 79: 'N', 80: 'P', 81: 'P', 82: 'N', 83: 'N', 84: 'P', 85: 'N', 86: 'N', 87: 'N', 88: 'N', 89: 'N', 90: 'P', 91: 'N', 92: 'N', 93: 'N', 94: 'N', 95: 'N', 96: 'N', 97: 'N', 98: 'N', 99: 'N', 100: 'N', 101: 'N', 102: 'N', 103: 'N', 104: 'N', 105: 'N', 106: 'N', 107: 'N', 108: 'N', 109: 'N', 110: 'N', 111: 'P', 112: 'N', 113: 'N', 114: 'N', 115: 'N', 116: 'N', 117: 'N', 118: 'N', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'N', 124: 'N', 125: 'N', 126: 'N', 127: 'N', 128: 'N', 129: 'N', 130: 'P', 131: 'N', 132: 'P', 133: 'N', 134: 'N', 135: 'N', 136: 'N', 137: 'N', 138: 'N', 139: 'N', 140: 'N', 141: 'N', 142: 'N', 143: 'N', 144: 'N', 145: 'N', 146: 'N', 147: 'P', 148: 'N', 149: 'N', 150: 'N', 151: 'N', 152: 'N', 153: 'N', 154: 'N', 155: 'N', 156: 'N', 157: 'N', 158: 'N', 159: 'N', 160: 'P', 161: 'N', 162: 'N', 163: 'N', 164: 'N', 165: 'N', 166: 'N', 167: 'N', 168: 'N', 169: 'N', 170: 'N', 171: 'N', 172: 'N', 173: 'N', 174: 'N', 175: 'N', 176: 'P', 177: 'N', 178: 'N', 179: 'N', 180: 'N', 181: 'N', 182: 'N', 183: 'N', 184: 'P', 185: 'N', 186: 'N', 187: 'N', 188: 'N', 189: 'P', 190: 'N', 191: 'N', 192: 'N', 193: 'N', 194: 'N', 195: 'N', 196: 'N', 197: 'N', 198: 'N', 199: 'N', 200: 'N', 201: 'N', 202: 'N', 203: 'N', 204: 'N', 205: 'N', 206: 'N', 207: 'N', 208: 'N', 209: 'N', 210: 'N', 211: 'N', 212: 'P', 213: 'N', 214: 'N', 215: 'N', 216: 'N', 217: 'N', 218: 'P', 219: 'N', 220: 'N', 221: 'N', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'N', 227: 'N', 228: 'N', 229: 'N', 230: 'N', 231: 'P', 232: 'N', 233: 'N', 234: 'N', 235: 'P', 236: 'N', 237: 'N', 238: 'N', 239: 'N', 240: 'N', 241: 'N', 242: 'N', 243: 'N', 244: 'N', 245: 'N', 246: 'N', 247: 'N', 248: 'N', 249: 'N', 250: 'N', 251: 'N', 252: 'N', 253: 'P', 254: 'N', 255: 'N', 256: 'N', 257: 'N', 258: 'P', 259: 'N', 260: 'N', 261: 'N', 262: 'N', 263: 'N', 264: 'N', 265: 'N', 266: 'N', 267: 'N', 268: 'P', 269: 'N', 270: 'N', 271: 'N', 272: 'N', 273: 'N', 274: 'N', 275: 'N', 276: 'N', 277: 'P', 278: 'N', 279: 'N', 280: 'N', 281: 'N', 282: 'N', 283: 'N', 284: 'N', 285: 'N', 286: 'P', 287: 'N', 288: 'N', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'N', 294: 'N', 295: 'N', 296: 'N', 297: 'N', 298: 'N', 299: 'N', 300: 'N', 301: 'N', 302: 'P', 303: 'N', 304: 'N', 305: 'N', 306: 'N', 307: 'N', 308: 'N', 309: 'N', 310: 'N', 311: 'N', 312: 'N', 313: 'N', 314: 'N', 315: 'N', 316: 'N', 317: 'N', 318: 'N', 319: 'P', 320: 'N', 321: 'P', 322: 'N', 323: 'N', 324: 'N', 325: 'N', 326: 'N', 327: 'N', 328: 'P', 329: 'N', 330: 'N', 331: 'N', 332: 'N', 333: 'N', 334: 'N', 335: 'N', 336: 'N', 337: 'N', 338: 'N', 339: 'N', 340: 'N', 341: 'N', 342: 'N', 343: 'N', 344: 'N', 345: 'P', 346: 'N', 347: 'N', 348: 'N', 349: 'N', 350: 'N', 351: 'N', 352: 'N', 353: 'N', 354: 'N', 355: 'N', 356: 'N', 357: 'N', 358: 'N', 359: 'P', 360: 'N', 361: 'P', 362: 'N', 363: 'N', 364: 'P', 365: 'N', 366: 'N', 367: 'N', 368: 'N', 369: 'N', 370: 'N', 371: 'N', 372: 'N', 373: 'N', 374: 'P', 375: 'N', 376: 'N', 377: 'N', 378: 'N', 379: 'N', 380: 'N', 381: 'N', 382: 'N', 383: 'N', 384: 'N', 385: 'N', 386: 'N', 387: 'N', 388: 'N', 389: 'N', 390: 'P', 391: 'N', 392: 'N', 393: 'N', 394: 'N', 395: 'N', 396: 'N', 397: 'N', 398: 'N', 399: 'N'}\n",
            "Degree Sequence:  [3, 3, 3, 4, 4, 5, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 5, 3, 3, 4, 3, 3, 3, 3, 4, 9, 3, 3, 5, 6, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 4, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
          ]
        }
      ],
      "source": [
        "n = 400  # Number of nodes\n",
        "\n",
        "# Information Layer\n",
        "gamma_i = 2.5  # Power-law exponent\n",
        "kmin_i = 3  # Minimum degree\n",
        "num_hyper_edges_i = 100  # Desired number of hyper edges\n",
        "ldeg_i, hyperedge_dict_i = build_hypergraph(n, gamma_i, kmin_i, num_hyper_edges_i)\n",
        "inw = hnx.Hypergraph(hyperedge_dict_i)\n",
        "ltre = assign_thresholds(inw, 0.05, 0.03)\n",
        "\n",
        "# Cognition Layer\n",
        "gamma_c = 3.0  # Power-law exponent\n",
        "kmin_c = 3  # Minimum degree\n",
        "num_hyper_edges_c = 100  # Desired number of hyper edges\n",
        "ldeg_c, hyperedge_dict_c = build_hypergraph(n, gamma_c, kmin_c, num_hyper_edges_c)\n",
        "cnw = hnx.Hypergraph(hyperedge_dict_c)\n",
        "frac_prot = 0.1\n",
        "lprot = assign_protection(cnw, frac_prot)\n",
        "\n",
        "# Epidemic Layer\n",
        "gamma_e = 4.0\n",
        "kmin_e = 3\n",
        "ldeg_e = generate_degree_sequence(n, gamma_e, kmin_e)\n",
        "print(\"Degree Sequence: \", ldeg_e)\n",
        "enw = nx.configuration_model(ldeg_e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGOHKVGoPuRu",
        "outputId": "d1bd2264-333a-4e2d-9abe-9feab43e4113"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UTIijADt_hr9"
      },
      "outputs": [],
      "source": [
        "alp = 1\n",
        "beta_NN = 0.4\n",
        "mu = 1\n",
        "n_sample = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping of csv column indices to varying parameter names\n",
        "csv_column_to_param = {\n",
        "    0: 'lam',\n",
        "    1: 'zeta_1',\n",
        "    2: 'zeta_2',\n",
        "    3: 'zeta_3',\n",
        "    4: 'zeta_4',\n",
        "    5: 'beta_PP',\n",
        "    6: 'beta_NP',\n",
        "    7: 'beta_PN'\n",
        "}\n",
        "\n",
        "# read the LHS parameter csv\n",
        "df = pd.read_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/LHS_parameters_1000_samples.csv', header=None)\n",
        "\n",
        "# fixed parameters\n",
        "fixed_params = {\n",
        "    'inw': inw,\n",
        "    'ldeg_i': ldeg_i,\n",
        "    'ltre': ltre,\n",
        "    'cnw': cnw,\n",
        "    'ldeg_c': ldeg_c,\n",
        "    'lprot': lprot,\n",
        "    'enw': enw,\n",
        "    'ldeg_e': ldeg_e,\n",
        "    'alp': alp,\n",
        "    'beta_NN': beta_NN,\n",
        "    'mu': mu,\n",
        "    'n_sample': n_sample\n",
        "}\n",
        "\n",
        "\n",
        "# order of all parameters\n",
        "param_order = ['inw', 'ldeg_i', 'ltre', 'cnw', 'ldeg_c', 'lprot', 'enw', 'ldeg_e', 'lam', 'alp', 'zeta_1', 'zeta_2', 'zeta_3', 'zeta_4', 'beta_PP', 'beta_NP', 'beta_PN', 'beta_NN', 'mu', 'n_sample']\n",
        "\n",
        "\n",
        "# run the model for each sample\n",
        "outputs = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    params_from_csv = {csv_column_to_param[i]: row[i] for i in csv_column_to_param.keys()}\n",
        "\n",
        "    ordered_params = [params_from_csv[p] if p in params_from_csv else fixed_params[p] for p in param_order]\n",
        "\n",
        "    output = ICE_model_no_control(*ordered_params)\n",
        "    outputs.append(output)\n",
        "    print(output)\n",
        "\n",
        "# store outputs\n",
        "output_df = pd.DataFrame({'Output': outputs})\n",
        "output_df.to_csv('LHS_1000_samples_outputs_1_each.csv', index=False)\n",
        "\n",
        "\"\"\"\n",
        "# sensitivity analysis using Morris method\n",
        "# assuming the range (max - min) for each parameter is known\n",
        "parameter_ranges = df.max() - df.min()\n",
        "delta = parameter_ranges / (len(df) - 1)\n",
        "df_shifted = df + delta\n",
        "outputs_shifted = []\n",
        "\n",
        "for index, row in df_shifted.iterrows():\n",
        "    output_shifted = ICE_model_no_control(*row)\n",
        "    outputs_shifted.append(output_shifted)\n",
        "\n",
        "sensitivity = []\n",
        "for orig, shifted in zip(outputs, outputs_shifted):\n",
        "    sensitivity.append((shifted - orig) / delta)\n",
        "\n",
        "sensitivity_df = pd.DataFrame(sensitivity, columns=df.columns)\n",
        "sensitivity_rank = sensitivity_df.abs().mean().sort_values(ascending=False)\n",
        "\n",
        "print(\"Sensitivity Rankings:\\n\", sensitivity_rank)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# store sensitivity rankings\n",
        "sensitivity_df = pd.DataFrame(sensitivity_rank).reset_index()\n",
        "sensitivity_df.columns = ['Parameter', 'Sensitivity']\n",
        "sensitivity_df.to_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/sensitivity_rankings_1_each.csv', index=False)\n",
        "\n",
        "# plot sensitivity results\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Sensitivity', y='Parameter', data=sensitivity_df.sort_values('Sensitivity', ascending=False))\n",
        "plt.title('Sensitivity Rankings')\n",
        "plt.xlabel('Sensitivity')\n",
        "plt.ylabel('Parameter')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/My Drive/Information_Behavior_Disease_Networks/sensitivity_plot_1_each.png')\n",
        "plt.show()\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HO74tuCNt3wH",
        "outputId": "86e01440-8c58-48e8-a076-f1e13b75352d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9775\n",
            "0.0025\n",
            "0.955\n",
            "0.96\n",
            "0.0025\n",
            "0.98\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0125\n",
            "0.84\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.005\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.01\n",
            "0.98\n",
            "0.95\n",
            "0.93\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.8525\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.9125\n",
            "0.0025\n",
            "0.02\n",
            "0.7875\n",
            "0.01\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.01\n",
            "0.7525\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.955\n",
            "0.0025\n",
            "0.935\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0575\n",
            "0.0025\n",
            "0.0125\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.955\n",
            "0.9075\n",
            "0\n",
            "0.0025\n",
            "0.0025\n",
            "0.025\n",
            "0.0025\n",
            "0.0075\n",
            "0.6675\n",
            "0.0025\n",
            "0.9675\n",
            "0\n",
            "0.0025\n",
            "0.0025\n",
            "0.92\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.675\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.9375\n",
            "0.9525\n",
            "0.93\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.02\n",
            "0.0025\n",
            "0.875\n",
            "0.92\n",
            "0.0025\n",
            "0.94\n",
            "0.9075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.9125\n",
            "0.98\n",
            "0.915\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.8875\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.3075\n",
            "0.005\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9425\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.65\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9275\n",
            "0.0325\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.945\n",
            "0.9125\n",
            "0.01\n",
            "0\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.8625\n",
            "0.96\n",
            "0.0025\n",
            "0.005\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.3225\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0\n",
            "0.9825\n",
            "0.93\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.92\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.96\n",
            "0.705\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.8925\n",
            "0.0025\n",
            "0.02\n",
            "0.92\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.1025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.02\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9625\n",
            "0.0025\n",
            "0.0025\n",
            "0.0175\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.01\n",
            "0.0025\n",
            "0.9275\n",
            "0.0025\n",
            "0.97\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.92\n",
            "0.0175\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.9225\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0175\n",
            "0.8475\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9175\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.01\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.015\n",
            "0.96\n",
            "0.0075\n",
            "0.4075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0075\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9125\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9125\n",
            "0.01\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.95\n",
            "0.0025\n",
            "0.005\n",
            "0.9325\n",
            "0.965\n",
            "0.79\n",
            "0.0025\n",
            "0.005\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.985\n",
            "0.0025\n",
            "0.9275\n",
            "0.925\n",
            "0.9475\n",
            "0.91\n",
            "0.8875\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.94\n",
            "0.95\n",
            "0.0025\n",
            "0.0025\n",
            "0.875\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.96\n",
            "0.9\n",
            "0.02\n",
            "0.005\n",
            "0.0125\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0225\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.9575\n",
            "0.8975\n",
            "0.8825\n",
            "0.0025\n",
            "0.0125\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9425\n",
            "0.9325\n",
            "0.015\n",
            "0.9375\n",
            "0.01\n",
            "0.9625\n",
            "0.0025\n",
            "0.54\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9025\n",
            "0.0125\n",
            "0.9625\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.935\n",
            "0.925\n",
            "0.97\n",
            "0.0025\n",
            "0.62\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.925\n",
            "0.965\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9625\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0075\n",
            "0.95\n",
            "0.0025\n",
            "0.005\n",
            "0.9425\n",
            "0.925\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.905\n",
            "0.96\n",
            "0.94\n",
            "0.92\n",
            "0.97\n",
            "0.9475\n",
            "0.965\n",
            "0.9575\n",
            "0.0025\n",
            "0.0025\n",
            "0.92\n",
            "0.94\n",
            "0.0025\n",
            "0.0025\n",
            "0.0325\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.955\n",
            "0.0025\n",
            "0.9275\n",
            "0.9125\n",
            "0.9175\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0075\n",
            "0.0025\n",
            "0.7925\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.085\n",
            "0.9825\n",
            "0.9775\n",
            "0.0075\n",
            "0.965\n",
            "0.0025\n",
            "0.1325\n",
            "0.005\n",
            "0.0025\n",
            "0.0125\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9675\n",
            "0.94\n",
            "0.0075\n",
            "0.005\n",
            "0.9375\n",
            "0.96\n",
            "0.97\n",
            "0.9575\n",
            "0.8175\n",
            "0.0025\n",
            "0.0025\n",
            "0.2625\n",
            "0.005\n",
            "0.0025\n",
            "0.01\n",
            "0.0025\n",
            "0.89\n",
            "0.0025\n",
            "0.005\n",
            "0.0925\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.01\n",
            "0.91\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.9525\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9625\n",
            "0.0025\n",
            "0.0025\n",
            "0.945\n",
            "0.8975\n",
            "0.0025\n",
            "0.595\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.96\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.925\n",
            "0.9075\n",
            "0.005\n",
            "0.0025\n",
            "0\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.92\n",
            "0.8775\n",
            "0.0025\n",
            "0.0025\n",
            "0.9825\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.9675\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0175\n",
            "0.0025\n",
            "0.9275\n",
            "0.9475\n",
            "0.4275\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.915\n",
            "0.92\n",
            "0.0075\n",
            "0.96\n",
            "0.0025\n",
            "0.8375\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.9525\n",
            "0.0025\n",
            "0.975\n",
            "0.675\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.875\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.955\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.94\n",
            "0.0025\n",
            "0.0025\n",
            "0.9425\n",
            "0.0025\n",
            "0.005\n",
            "0.795\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.01\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.255\n",
            "0.005\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.95\n",
            "0\n",
            "0.0025\n",
            "0.9125\n",
            "0.0025\n",
            "0.97\n",
            "0\n",
            "0.0025\n",
            "0.92\n",
            "0.925\n",
            "0.885\n",
            "0.0025\n",
            "0.97\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.955\n",
            "0.0025\n",
            "0.8725\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.965\n",
            "0.985\n",
            "0.9625\n",
            "0.945\n",
            "0.9625\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9475\n",
            "0.2325\n",
            "0.825\n",
            "0.045\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.92\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.01\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.955\n",
            "0.0025\n",
            "0.0075\n",
            "0.01\n",
            "0.0025\n",
            "0.0025\n",
            "0.01\n",
            "0.0025\n",
            "0.96\n",
            "0.9425\n",
            "0.925\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0175\n",
            "0.0025\n",
            "0.91\n",
            "0.93\n",
            "0.9575\n",
            "0.9225\n",
            "0.945\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.005\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.965\n",
            "0.03\n",
            "0.0025\n",
            "0.0075\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0075\n",
            "0.005\n",
            "0.0025\n",
            "0.025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.9525\n",
            "0.0225\n",
            "0.0025\n",
            "0.0025\n",
            "0.9725\n",
            "0.0075\n",
            "0.9475\n",
            "0.91\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.0025\n",
            "0.96\n",
            "0.89\n",
            "0.0025\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7aa43f1cd89a>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_shifted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0moutput_shifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mICE_model_no_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0moutputs_shifted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shifted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ICE_model_no_control() missing 12 required positional arguments: 'lam', 'alp', 'zeta_1', 'zeta_2', 'zeta_3', 'zeta_4', 'beta_PP', 'beta_NP', 'beta_PN', 'beta_NN', 'mu', and 'n_sample'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.to_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/LHS_1000_samples_outputs_1_each.csv', index=False)\n"
      ],
      "metadata": {
        "id": "QIW6aKGgQjKH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SALib\n",
        "from SALib.sample import saltelli\n",
        "from SALib.analyze import sobol\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcPhYNaPUdYJ",
        "outputId": "c4d7cb47-f8b6-44c3-ece3-081c14d31267"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SALib in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from SALib) (3.7.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from SALib) (0.70.15)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from SALib) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from SALib) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from SALib) (1.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.2->SALib) (2023.3)\n",
            "Requirement already satisfied: dill>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from multiprocess->SALib) (0.3.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->SALib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the varying parameters\n",
        "params_df = pd.read_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/LHS_parameters_1000_samples.csv', header=None)\n",
        "\n",
        "# Load the outputs (excluding the header)\n",
        "outputs_df = pd.read_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/LHS_1000_samples_outputs_1_each.csv', skiprows=1, header=None)\n",
        "outputs = outputs_df.iloc[:, 0].values\n",
        "\n",
        "# Define your problem again\n",
        "problem = {\n",
        "    'num_vars': 8,\n",
        "    'names': ['Lambda', 'Zeta_1', 'Zeta_2', 'Zeta_3', 'Zeta_4', 'beta_PP', 'beta_NP', 'beta_PN'],\n",
        "    'bounds': [[0, 1], [0, 0.2], [0, 0.2], [0, 0.2], [0, 0.2], [0, 0.05], [0.05, 0.2], [0.2, 0.4]]\n",
        "}\n",
        "\n",
        "# Perform Saltelli sampling\n",
        "param_samples = params_df.values\n",
        "\n",
        "# Initialize an array to store PRCC results\n",
        "prcc_results = np.zeros((problem['num_vars'],))\n",
        "\n",
        "# Iterate through each parameter and calculate PRCC\n",
        "for i, param_name in enumerate(problem['names']):\n",
        "    X = param_samples[:, i]\n",
        "\n",
        "    prcc_result = np.corrcoef(X, outputs)[0, 1]\n",
        "    prcc_results[i] = prcc_result\n",
        "\n",
        "# Print PRCC results\n",
        "for i, param_name in enumerate(problem['names']):\n",
        "    print(f\"{param_name}: {prcc_results[i]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qofJlfDcsUO",
        "outputId": "51f5d29c-44b5-4d21-b3ec-ee131d3b741e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lambda: 0.04982316842111468\n",
            "Zeta_1: -0.008162593540764474\n",
            "Zeta_2: -0.08623158344405754\n",
            "Zeta_3: 0.032737488598488074\n",
            "Zeta_4: -0.05228142411080979\n",
            "beta_PP: 0.011602362858952988\n",
            "beta_NP: 0.03329625449320173\n",
            "beta_PN: 0.03329625449320191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Latex math symbols for parameter labels\n",
        "param_labels = ['$\\lambda$', '$\\zeta_1$', '$\\zeta_2$', '$\\zeta_3$','$\\zeta_4$',r'$\\beta_{PP}$', r'$\\beta_{NP}$', r'$\\beta_{PN}$']\n",
        "\n",
        "# Plot PRCC results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(param_labels, prcc_results, color='blue')\n",
        "plt.xlabel('Parameters', fontsize=14)\n",
        "plt.ylabel('PRCC Value', fontsize=14)\n",
        "plt.title('PRCC Sensitivity Analysis', fontsize=16)\n",
        "plt.xticks(rotation=45, fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.grid(axis='y')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "iES0dAcEgL7G",
        "outputId": "dcb9376b-f774-4943-f6ed-de2625cfa998"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alp = 1\n",
        "beta_NN = 0.4\n",
        "mu = 1\n",
        "n_sample2 = 10"
      ],
      "metadata": {
        "id": "WeTdQVmy9P4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping of csv column indices to varying parameter names\n",
        "csv_column_to_param = {\n",
        "    0: 'lam',\n",
        "    1: 'zeta_1',\n",
        "    2: 'zeta_2',\n",
        "    3: 'zeta_3',\n",
        "    4: 'zeta_4',\n",
        "    5: 'beta_PP',\n",
        "    6: 'beta_NP',\n",
        "    7: 'beta_PN'\n",
        "}\n",
        "\n",
        "# read the LHS parameter csv\n",
        "df = pd.read_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/LHS_parameters_1000_samples.csv', header=None)\n",
        "\n",
        "# fixed parameters\n",
        "fixed_params = {\n",
        "    'inw': inw,\n",
        "    'ldeg_i': ldeg_i,\n",
        "    'ltre': ltre,\n",
        "    'cnw': cnw,\n",
        "    'ldeg_c': ldeg_c,\n",
        "    'lprot': lprot,\n",
        "    'enw': enw,\n",
        "    'ldeg_e': ldeg_e,\n",
        "    'alp': alp,\n",
        "    'beta_NN': beta_NN,\n",
        "    'mu': mu,\n",
        "    'n_sample': n_sample2\n",
        "}\n",
        "\n",
        "\n",
        "# order of all parameters\n",
        "param_order = ['inw', 'ldeg_i', 'ltre', 'cnw', 'ldeg_c', 'lprot', 'enw', 'ldeg_e', 'lam', 'alp', 'zeta_1', 'zeta_2', 'zeta_3', 'zeta_4', 'beta_PP', 'beta_NP', 'beta_PN', 'beta_NN', 'mu', 'n_sample']\n",
        "\n",
        "\n",
        "# run the model for each sample\n",
        "outputs = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    params_from_csv = {csv_column_to_param[i]: row[i] for i in csv_column_to_param.keys()}\n",
        "\n",
        "    ordered_params = [params_from_csv[p] if p in params_from_csv else fixed_params[p] for p in param_order]\n",
        "\n",
        "    output = ICE_model_no_control(*ordered_params)\n",
        "    outputs.append(output)\n",
        "    print(output)\n",
        "\n",
        "# store outputs\n",
        "output_df2 = pd.DataFrame({'Output': outputs})\n",
        "output_df2.to_csv('LHS_1000_samples_outputs_10_each.csv', index=False)\n",
        "\n",
        "# sensitivity analysis using Morris method\n",
        "# assuming the range (max - min) for each parameter is known\n",
        "parameter_ranges = df.max() - df.min()\n",
        "delta = parameter_ranges / (len(df) - 1)\n",
        "df_shifted = df + delta\n",
        "outputs_shifted = []\n",
        "\n",
        "for index, row in df_shifted.iterrows():\n",
        "    output_shifted = ICE_model_no_control(*row)\n",
        "    outputs_shifted.append(output_shifted)\n",
        "\n",
        "sensitivity_rank2 = []\n",
        "for orig, shifted in zip(outputs, outputs_shifted):\n",
        "    sensitivity.append((shifted - orig) / delta)\n",
        "\n",
        "sensitivity_df2 = pd.DataFrame(sensitivity, columns=df.columns)\n",
        "sensitivity_rank2 = sensitivity_df2.abs().mean().sort_values(ascending=False)\n",
        "\n",
        "print(\"Sensitivity Rankings:\\n\", sensitivity_rank2)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# store sensitivity rankings\n",
        "sensitivity_df2 = pd.DataFrame(sensitivity_rank2).reset_index()\n",
        "sensitivity_df2.columns = ['Parameter', 'Sensitivity']\n",
        "sensitivity_df2.to_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/sensitivity_rankings_10_each.csv', index=False)\n",
        "\n",
        "# plot sensitivity results\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Sensitivity', y='Parameter', data=sensitivity_df2.sort_values('Sensitivity', ascending=False))\n",
        "plt.title('Sensitivity Rankings')\n",
        "plt.xlabel('Sensitivity')\n",
        "plt.ylabel('Parameter')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/My Drive/Information_Behavior_Disease_Networks/sensitivity_plot_10_each.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1HhC-3wZ9Pmd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+dNWylJdeoF5B8HBygJMe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}