{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPn76Qzkm0sKJ9TdAOLXul9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nancy-Shi/Complex_Networks/blob/main/070323_Rumor_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbwfpU2mSnzl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import random\n",
        "import math as math\n",
        "from math import log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ybue32RTk2M",
        "outputId": "a35d9560-1a8c-4d76-f9ee-8404dea37d49"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_degree_sequence(n, gamma, kmin):\n",
        "    # Generate a random set from the power law distribution\n",
        "    u = np.random.uniform(size=n)\n",
        "    degrees = np.ceil((1.0 - u) ** (-1.0 / (gamma - 1.0)))\n",
        "\n",
        "    # Adjust degrees based on the minimum and maximum degree values\n",
        "    kmax = int(1.5*n**(1/4)) # max degree allowed is 1.5*n^(1/4)\n",
        "    degrees = degrees[(degrees >= kmin) & (degrees <= kmax)].astype(int)\n",
        "\n",
        "    # Truncate or pad the sequence to match the length specified\n",
        "    if len(degrees) >= n:\n",
        "        degrees = degrees[:n]\n",
        "    else:\n",
        "        degrees = np.concatenate((degrees, np.full(n - len(degrees), kmin)))\n",
        "\n",
        "    return degrees.tolist()"
      ],
      "metadata": {
        "id": "smHM8vxwVOkZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_configuration_model(degree_sequence):\n",
        "    # Create an empty graph and sum up the degrees\n",
        "    G = nx.Graph()\n",
        "    degree_sum = sum(degree_sequence)\n",
        "\n",
        "    # Print error message if the sum is odd\n",
        "    if degree_sum % 2 != 0:\n",
        "        raise ValueError(\"Degree sum is odd\")\n",
        "\n",
        "    # Create a list of nodes based on the degree sequence\n",
        "    nodes = []\n",
        "    for node, degree in enumerate(degree_sequence):\n",
        "        nodes.extend([node] * degree)\n",
        "\n",
        "    # Shuffle the nodes list\n",
        "    random.shuffle(nodes)\n",
        "\n",
        "    # Track visited edges\n",
        "    existing_edges = set()\n",
        "\n",
        "    # Pair the nodes and add edges to the graph\n",
        "    for i in range(0, len(nodes), 2):\n",
        "        node1 = nodes[i]\n",
        "        node2 = nodes[i + 1]\n",
        "\n",
        "        # Check for self-edges and duplicate edges\n",
        "        if node1 != node2 and (node1, node2) not in existing_edges:\n",
        "            G.add_edge(node1, node2)\n",
        "            existing_edges.add((node1, node2))\n",
        "            existing_edges.add((node2, node1))\n",
        "\n",
        "    return G"
      ],
      "metadata": {
        "id": "LfZBMofnVPUo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## The following is the baseline rumor model\n",
        "## There are 3 states: S(ignorant), I(spreader), R(stifler)\n",
        "\n",
        "def Rumor_Basic(nw, lam, alp, n_samp):\n",
        "   # initialize variables\n",
        "    t_max = 10000\n",
        "    #n_times = 100000  # number of time points at which rho_R is recorded and averaged\n",
        "    #rho_R_av = np.zeros(n_times+1)  # Initialize rho_R_av as a numpy array of zeros\n",
        "    #t_sav = np.zeros(n_times+1)  # Initialize t_sav as a numpy array of zeros\n",
        "    #t_sav0 = 0\n",
        "    N = len(nw.nodes)\n",
        "    degrees = dict(nw.degree())\n",
        "    kmax = max(degrees.values())\n",
        "\n",
        "    t_end = np.zeros(n_samp+1)\n",
        "    rho_R_end = np.zeros(n_samp+1)\n",
        "\n",
        "    # Initialize states with ignorant individuals\n",
        "    states = {j: 0 for j in nw.nodes()}\n",
        "\n",
        "    for i_samp in range(1, n_samp+1):\n",
        "        t = 0\n",
        "        n_sav = 0 # an index variable that keeps track of the current position in the rho_R_av array.\n",
        "        #t_sav[n_sav] = t_sav0\n",
        "        rho_R = 0\n",
        "        N_rec = 0\n",
        "\n",
        "        # Randomly select an initial spreader node\n",
        "        inf = []\n",
        "        #rec = []\n",
        "        initial_node = np.random.choice(nw.nodes())\n",
        "        states[initial_node] = 1\n",
        "        inf.append(initial_node)\n",
        "        N_inf = 1\n",
        "        N_e = nw.degree(initial_node)\n",
        "\n",
        "        while t < t_max and N_inf > 0:\n",
        "            total_rate = lam * N_e + 2 * alp * N_e\n",
        "            tau = -np.log(np.random.uniform(1e-6, 1)) / total_rate\n",
        "            t += tau\n",
        "\n",
        "            # Update average rho_R at specific time points\n",
        "            #while n_sav < n_times and t > t_sav[n_sav]:\n",
        "            #    rho_R_av[n_sav] += rho_R\n",
        "            #    n_sav += 1\n",
        "            #    t_sav[n_sav] += t_max/n_times\n",
        "\n",
        "            # Determine which event occurs\n",
        "            event = np.random.uniform()\n",
        "            p1 = lam / (lam + 2 * alp)\n",
        "            p2 = (lam + alp )/ (lam + 2 * alp)\n",
        "\n",
        "            # Determine if accept selected spreader based on degree distribution\n",
        "            q_deg = np.random.uniform()\n",
        "\n",
        "            if event > p1: # Recovery\n",
        "                # Select a spreader individual to recover\n",
        "                rec_node = np.random.choice(inf)\n",
        "                if q_deg > degrees[rec_node]/kmax:\n",
        "                    # Select a random neighbor to contact\n",
        "                    neighbors = list(nw.neighbors(rec_node))\n",
        "                    #if len(neighbors) > 0:\n",
        "                    # Recover event 1:  I + R --> 2R\n",
        "                    if event > p2:\n",
        "                        neighbor = np.random.choice(neighbors)\n",
        "                        if states[neighbor] == 2:\n",
        "                            # Update spreader to stifler if the selected neighbor is a stifler\n",
        "                            states[rec_node] = 2\n",
        "                            N_e -= nw.degree(rec_node)\n",
        "                            N_inf -= 1\n",
        "                            inf.remove(rec_node)\n",
        "                            rho_R += (1 / N)\n",
        "                            N_rec += 1\n",
        "\n",
        "                    else: # Recovery event 2: I + I --> R + I\n",
        "                        neighbor = np.random.choice(neighbors)\n",
        "                        if states[neighbor] == 1:\n",
        "                            # Update spreader to stifler if the selected neighbor is a spreader\n",
        "                            states[rec_node] = 2\n",
        "                            N_e -= nw.degree(rec_node)\n",
        "                            N_inf -= 1\n",
        "                            inf.remove(rec_node)\n",
        "                            rho_R += (1 / N)\n",
        "                            N_rec += 1\n",
        "\n",
        "            else: # Infection event: I + S --> 2I\n",
        "                # Select a spreader individual to spread the rumor\n",
        "                inf_node = np.random.choice(inf)\n",
        "                if q_deg > degrees[inf_node]/kmax:\n",
        "                  # Select a random neighbor to contact\n",
        "                  neighbors = list(nw.neighbors(inf_node))\n",
        "                  #if len(neighbors) > 0:\n",
        "                  neighbor = np.random.choice(neighbors)\n",
        "                  # Check if the selected neighbor is ignorant\n",
        "                  if states[neighbor] == 0:\n",
        "                        states[neighbor] = 1  # ignorant neighbor becomes spreader\n",
        "                        inf.append(neighbor)\n",
        "                        N_inf += 1\n",
        "                        N_e += nw.degree(neighbor)\n",
        "\n",
        "            if N_inf == 0:\n",
        "                t_end[i_samp] = t\n",
        "                rho_R_end[i_samp] = rho_R\n",
        "                print(t, N_rec, rho_R, lam)\n",
        "\n",
        "        # Reset spreader and stiflers for the next sample\n",
        "        for node, state in states.items():\n",
        "            if state == 1 or state == 2:\n",
        "                states[node] = 0\n",
        "\n",
        "    # Normalize the average rho_R values by dividing by the number of samples\n",
        "    #rho_R_av /= n_samp\n",
        "    #t_end_av = sum(t_end)/n_samp\n",
        "    rho_R_av = np.mean(rho_R_end)\n",
        "    t_end_av = np.mean(t_end)\n",
        "\n",
        "    return rho_R_av, t_end_av\n"
      ],
      "metadata": {
        "id": "8TuMt9AzTnbH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n= 2000\n",
        "gamma = 2.7\n",
        "kmin = 3\n",
        "degrees = generate_degree_sequence(n, gamma, kmin)\n",
        "print(degrees)\n",
        "nw = generate_configuration_model(degrees)\n",
        "\n",
        "alp = 1\n",
        "\n",
        "n_samp = 5\n",
        "\n",
        "lambda_values = np.linspace(0.05, 1, num=9)  # Generate lambda values from 0 to 1 with 0.05 steps\n",
        "rho_R_av_values = []\n",
        "t_end_av_values = []\n",
        "\n",
        "for lam in lambda_values:\n",
        "    rho_R_av, t_end_av = Rumor_Basic(nw, lam, alp, n_samp)\n",
        "    rho_R_av_values.append(rho_R_av)  # Append the last value of rho_R_av to the list\n",
        "    t_end_av_values.append(t_end_av)\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "avg_rho_R_values = np.array(rho_R_av_values)\n",
        "avg_t_end_values = np.array(t_end_av_values)\n",
        "\n",
        "# Plot the two-panel graph\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 10))\n",
        "\n",
        "# Top panel: average density of stifler rho_R against spreading rate lambda\n",
        "ax1.plot(lambda_values, avg_rho_R_values, 'o-')\n",
        "ax1.set_xlabel('Lambda')\n",
        "ax1.set_ylabel('Average Stifler Density')\n",
        "ax1.set_title('Average rho_R vs. Lambda')\n",
        "ax1.legend()\n",
        "\n",
        "# Bottom panel: average rumor die-out time t_max against spreading rate lambda\n",
        "ax2.plot(lambda_values, avg_t_end_values, 'o-')\n",
        "ax2.set_xlabel('Lambda')\n",
        "ax2.set_ylabel('Average Rumor Die-Out Time')\n",
        "ax2.set_title('Average t_max vs. Lambda')\n",
        "ax2.legend()\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "# Display the graph\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "at8hdk5MwREZ",
        "outputId": "fa89006f-650b-462f-943e-9dbfc8688bab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c7c5d415698e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdegrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_degree_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_configuration_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-47e03b043ce8>\u001b[0m in \u001b[0;36mgenerate_degree_sequence\u001b[0;34m(n, gamma, kmin)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_degree_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Generate a random set from the power law distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdegrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    }
  ]
}