{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN+jj9OTt4OFBEbZyI7X0E/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nancy-Shi/Complex_Networks/blob/main/3_Layer_Coupling_080423.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-Layer Model with Informtion, Behavior, Disease"
      ],
      "metadata": {
        "id": "qA_qQY-h8rAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install hypernetx\n",
        "import hypernetx as hnx"
      ],
      "metadata": {
        "id": "lvbMl01j8mD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7250fb-ab14-45e4-b242-ded434074e57"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " No module named 'igraph'. If you need to use hypernetx.algorithms.hypergraph_modularity, please install additional packages by running the following command: pip install .['all']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import random\n",
        "import math as math\n",
        "from math import log\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.ticker as ticker"
      ],
      "metadata": {
        "id": "Fan2mZxpB3Up"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Part 1: Hypergraph Generation\n",
        "The following steps generate a hyper graph using the XGI/HyperNetX python package,  following power-law degree distribution for predifined number of nodes n, number of hyperedges num_hyper_edges, degree exponent gamma, using a configuration model with data stored in a dictionary."
      ],
      "metadata": {
        "id": "FUCtz8IJ8VkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Generate Degree Sequence\n",
        "def generate_degree_sequence(n, gamma, kmin):\n",
        "    # Generate a random set from the power law distribution\n",
        "    u = np.random.uniform(size=n)\n",
        "    degrees = np.ceil((1.0 - u) ** (-1.0 / (gamma - 1.0)))\n",
        "\n",
        "    # Adjust degrees based on the minimum and maximum degree values\n",
        "    kmax = int(np.sqrt(n))\n",
        "    # kmax = int(1.5*n**(1/4)) # max degree allowed is 1.5*n^(1/4)\n",
        "    degrees = degrees[(degrees >= kmin) & (degrees <= kmax)].astype(int)\n",
        "\n",
        "    # Truncate or pad the sequence to match the length specified\n",
        "    if len(degrees) >= n:\n",
        "        degrees = degrees[:n]\n",
        "    else:\n",
        "        degrees = np.concatenate((degrees, np.full(n - len(degrees), kmin)))\n",
        "\n",
        "    return degrees.tolist()\n",
        "\n",
        "# Step 2: Generate Hyper Edge Size Sequence\n",
        "def generate_hyper_edge_sizes(degrees, num_hyper_edges):\n",
        "    total_degrees = sum(degrees)\n",
        "    hyper_edge_sizes = []\n",
        "\n",
        "    # Calculate the average size for each hyper edge\n",
        "    avg_size = total_degrees // num_hyper_edges\n",
        "    remainder = total_degrees % num_hyper_edges\n",
        "\n",
        "    # Define the range for the random distribution\n",
        "    min_size = 2  # Lower bound of the range\n",
        "    max_size = int(np.sqrt(total_degrees))  # Upper bound of the range\n",
        "    #max_size = len(degrees) - num_hyper_edges  # Upper bound of the range\n",
        "\n",
        "    # Generate hyper edge sizes\n",
        "    for _ in range(num_hyper_edges):\n",
        "        size = random.randint(min_size, max_size)\n",
        "        hyper_edge_sizes.append(size)\n",
        "\n",
        "    return hyper_edge_sizes\n",
        "\n",
        "\n",
        "# Step 3: Create Copies of Nodes\n",
        "def create_node_copies(degrees):\n",
        "    node_copies = []\n",
        "    for i, degree in enumerate(degrees):\n",
        "        for _ in range(degree):\n",
        "            node_copies.append(i)\n",
        "    return node_copies\n",
        "\n",
        "# Step 4: Create Copies of Hyper Edges\n",
        "def create_hyper_edge_copies(hyper_edge_sizes):\n",
        "    hyper_edge_copies = []\n",
        "    for i, size in enumerate(hyper_edge_sizes):\n",
        "        for _ in range(size):\n",
        "            hyper_edge_copies.append(i)\n",
        "    return hyper_edge_copies\n",
        "\n",
        "# Step 5: Randomly Pair Copies without Repeated Pairs\n",
        "def randomly_pair_copies(node_copies, hyper_edge_copies):\n",
        "    pairs = []\n",
        "    paired_hyper_edges = {} # Using a dictionary to track paired hyper-edges with nodes\n",
        "\n",
        "    for node_copy in node_copies:\n",
        "        available_hyper_edges = [h for h in hyper_edge_copies if (h, node_copy) not in paired_hyper_edges]\n",
        "\n",
        "        # If no available hyper-edges left, shuffle the paired hyper-edges and reset\n",
        "        if not available_hyper_edges:\n",
        "            paired_hyper_edges = {}\n",
        "            available_hyper_edges = [h for h in hyper_edge_copies if (h, node_copy) not in paired_hyper_edges]\n",
        "\n",
        "        # Randomly choose a hyper-edge that has not been paired yet with the current node\n",
        "        chosen_hyper_edge = random.choice(available_hyper_edges)\n",
        "        pairs.append((node_copy, chosen_hyper_edge))\n",
        "\n",
        "        # Add to paired_hyper_edges\n",
        "        paired_hyper_edges[(chosen_hyper_edge, node_copy)] = True\n",
        "        hyper_edge_copies.remove(chosen_hyper_edge)\n",
        "\n",
        "    return pairs\n",
        "\n",
        "# Step 6: Convert Bipartite Graph to A Hypergraph Dictionary\n",
        "def convert_to_hypergraph(pairs):\n",
        "    hypergraph = {}\n",
        "    for pair in pairs:\n",
        "        node, hyper_edge = pair\n",
        "        if hyper_edge in hypergraph:\n",
        "            hypergraph[hyper_edge].append(node)\n",
        "        else:\n",
        "            hypergraph[hyper_edge] = [node]\n",
        "    return hypergraph\n"
      ],
      "metadata": {
        "id": "3qvT8MAI8VEs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_hypergraph(n, gamma, kmin, num_hyper_edges):\n",
        "    # Step 1: Generate Degree Sequence\n",
        "    degrees = generate_degree_sequence(n, gamma, kmin)\n",
        "    print(\"Degree Sequence: \", degrees)\n",
        "\n",
        "    # Step 2: Generate Hyper Edge Size Sequence\n",
        "    hyper_edge_sizes = generate_hyper_edge_sizes(degrees, num_hyper_edges)\n",
        "    print(\"Hyper Edge Sizes: \", hyper_edge_sizes)\n",
        "\n",
        "    # Step 3: Create Copies of Nodes\n",
        "    node_copies = create_node_copies(degrees)\n",
        "\n",
        "    # Step 4: Create Copies of Hyper Edges\n",
        "    hyper_edge_copies = create_hyper_edge_copies(hyper_edge_sizes)\n",
        "\n",
        "    # Step 5: Randomly Pair Copies\n",
        "    pairs = randomly_pair_copies(node_copies, hyper_edge_copies)\n",
        "\n",
        "    # Step 6: Convert Bipartite Graph to Hypergraph\n",
        "    hyperedge_dict = convert_to_hypergraph(pairs)\n",
        "\n",
        "    # Print the resulting hypergraph\n",
        "    print(\"Hypergraph Dictionary: \", hyperedge_dict)\n",
        "\n",
        "    return degrees, hyperedge_dict"
      ],
      "metadata": {
        "id": "0b6c7yfU8hg8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2\n",
        "n2 =400  # Number of nodes\n",
        "gamma2 = 2.5  # Power-law exponent\n",
        "kmin2 = 3  # Minimum degree\n",
        "num_hyper_edges2 = 100  # Desired number of hyper edges\n",
        "\n",
        "degrees2, hyperedge_dict2 = build_hypergraph(n2, gamma2, kmin2, num_hyper_edges2)\n",
        "H2 = hnx.Hypergraph(hyperedge_dict2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-tEXGpf819Y",
        "outputId": "8708352f-e208-4949-db9a-c6c7d3820c24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degree Sequence:  [3, 3, 3, 5, 12, 3, 5, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 14, 3, 3, 7, 3, 11, 5, 13, 8, 5, 3, 5, 3, 3, 7, 3, 3, 4, 4, 7, 3, 3, 7, 10, 9, 3, 3, 3, 5, 11, 5, 3, 6, 3, 4, 3, 3, 4, 10, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 5, 4, 5, 3, 4, 8, 3, 3, 5, 4, 4, 3, 3, 3, 6, 4, 11, 4, 4, 4, 14, 8, 3, 3, 4, 3, 3, 3, 3, 3, 4, 12, 6, 4, 3, 3, 4, 4, 17, 3, 7, 3, 9, 4, 5, 3, 3, 3, 4, 3, 3, 3, 4, 3, 7, 3, 3, 3, 11, 14, 4, 4, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [28, 23, 29, 32, 12, 24, 13, 7, 21, 5, 30, 25, 3, 33, 33, 29, 14, 24, 20, 20, 14, 17, 23, 26, 3, 28, 29, 14, 13, 26, 33, 3, 33, 25, 29, 26, 22, 18, 27, 28, 9, 30, 13, 9, 23, 5, 15, 3, 29, 30, 6, 10, 12, 12, 37, 29, 4, 29, 33, 14, 30, 2, 35, 14, 19, 27, 16, 18, 12, 4, 24, 28, 23, 16, 8, 32, 35, 18, 21, 19, 13, 16, 30, 4, 35, 24, 36, 19, 8, 8, 5, 3, 8, 23, 23, 34, 37, 20, 8, 21]\n",
            "Hypergraph Dictionary:  {16: [0, 6, 36, 39, 82, 84, 137, 198, 242, 258, 365], 54: [0, 32, 40, 61, 76, 95, 97, 103, 104, 129, 138, 183, 215, 238, 255, 257, 259, 271, 280, 312, 325, 326, 344, 347], 60: [0, 8, 18, 43, 55, 60, 61, 71, 78, 141, 167, 194, 242, 243, 247, 295, 304, 317, 343, 350, 361], 84: [1, 31, 39, 55, 67, 68, 73, 91, 113, 115, 116, 121, 130, 133, 168, 178, 179, 184, 206, 237, 279, 284, 313, 327, 344, 359, 394], 92: [1, 24, 33, 66, 97, 189], 91: [1, 47], 13: [2, 22, 24, 80, 86, 96, 101, 105, 130, 149, 151, 185, 190, 234, 247, 249, 263, 281, 326, 328, 331, 334, 388], 67: [2, 28, 62, 75, 92, 102, 107, 113, 120, 130, 166, 250, 296, 319, 341, 383], 23: [2, 19, 81, 92, 99, 113, 142, 172, 229, 253, 309, 310, 314, 320, 322, 324, 371, 372], 96: [3, 15, 19, 25, 45, 46, 49, 72, 85, 91, 113, 142, 180, 188, 219, 235, 244, 252, 264, 269, 294, 299, 304, 318, 332, 337, 394], 83: [3, 63, 267, 391], 43: [3, 54, 77, 91, 128, 356], 26: [3, 25, 26, 84, 116, 125, 129, 133, 150, 194, 221, 233, 234, 258, 295, 303, 324, 385, 386], 10: [3, 6, 17, 31, 62, 86, 117, 144, 158, 177, 180, 184, 185, 219, 260, 273, 286, 317, 330, 340, 391, 398], 38: [4, 16, 39, 41, 81, 91, 109, 111, 138, 147, 149, 275, 280, 289, 291, 319, 354, 367], 95: [4, 6, 20, 44, 70, 76, 100, 109, 130, 167, 172, 177, 187, 200, 241, 262, 275, 278, 285, 297, 312, 368, 382], 46: [4, 46, 53, 75, 91, 111, 129, 135, 167, 247], 19: [4, 29, 53, 72, 87, 103, 129, 200, 235, 289, 307, 337, 345, 367, 375], 85: [4, 10, 12, 43, 50, 113, 146, 155, 223, 251, 261, 365, 374, 385], 32: [4, 11, 40, 87, 92, 109, 129, 136, 155, 169, 182, 197, 202, 223, 230, 241, 256, 273, 297, 320, 351, 352, 353, 381, 393], 28: [4, 24, 55, 60, 131, 136, 155, 292, 306, 397], 58: [4, 9, 11, 12, 22, 29, 31, 87, 95, 109, 143, 166, 181, 186, 188, 189, 197, 215, 260, 270, 277, 357, 380, 381], 36: [4, 6, 17, 28, 77, 106, 130, 160, 170, 183, 228, 280, 284, 287, 288, 314, 374, 382], 17: [4, 40, 46, 86, 91, 103, 104, 125, 128, 135, 152, 193, 198, 240, 331, 371, 399], 78: [4, 8, 30, 39, 40, 45, 56, 82, 89, 109, 122, 173, 174, 211, 232, 237, 291, 308], 39: [4, 11, 25, 36, 48, 123, 130, 151, 162, 169, 204, 212, 216, 220, 244, 253, 257, 375, 379, 396], 77: [5, 7, 58, 64, 75, 114, 124, 140, 150, 276, 283, 362], 37: [5, 27, 30, 33, 54, 55, 87, 109, 196, 225, 248, 332, 373, 384], 57: [5, 18, 22, 24, 44, 49, 51, 54, 57, 70, 87, 93, 128, 162, 175, 193, 270, 279, 282, 338, 346, 362, 376, 384], 71: [6, 32, 83, 102, 108, 132, 133, 139, 145, 196, 209, 231, 256, 257, 265, 309, 330, 332, 347], 89: [7, 69, 140, 359, 378], 21: [7, 14, 17, 41, 85, 156, 195, 216, 346, 374, 386], 8: [8, 24, 28, 43, 74, 89, 91, 92, 101, 217, 226, 252, 316, 342, 385], 76: [9, 36, 41, 47, 78, 87, 91, 109, 113, 125, 137, 141, 143, 144, 154, 156, 157, 191, 214, 228, 239, 245, 256, 258, 292, 294, 334], 11: [9, 17, 22, 23, 46, 63, 66, 97, 159, 160, 171, 191, 253, 304, 334, 340, 352, 388], 73: [10, 22, 25, 28, 52, 78, 112, 141, 170, 246, 248, 357, 378], 29: [10, 73, 79, 88, 92, 109, 111, 131, 139, 142, 196, 218, 221, 277, 288, 295, 308, 330, 341, 342, 363], 93: [10, 34, 70, 72, 91, 118, 119, 199, 267, 268, 271, 287, 294, 301, 310, 315, 321, 397], 4: [11, 40, 71, 94, 127, 129, 131, 201, 348], 49: [12, 62, 71, 109, 118, 119, 120, 121, 127, 132, 154, 156, 212, 249, 251, 282, 371], 33: [12, 14, 24, 40, 148, 172, 203, 204, 222, 246, 254, 299, 300, 327, 335, 355, 358, 369], 75: [13, 15, 17, 58, 76, 88, 95, 107, 108, 111, 149, 164, 181, 190, 200, 201, 217, 261, 339, 357, 362, 370, 392], 80: [13, 17, 25, 28, 71, 76, 103, 227, 271, 283, 367], 18: [13, 35, 42, 56, 91, 133, 139, 188, 268, 272, 306, 318], 88: [14, 22, 38, 50, 100, 293], 3: [15, 17, 20, 31, 59, 87, 98, 109, 113, 114, 129, 143, 157, 175, 187, 189, 262, 273, 368, 387], 30: [16, 32, 41, 45, 48, 55, 59, 75, 79, 93, 121, 148, 186, 236, 272, 286, 297, 310, 324, 342, 354, 360, 377, 392, 395, 396], 86: [16, 20, 26, 41, 42, 85, 90, 91, 113, 125, 134, 153, 159, 164, 181, 205, 208, 227, 290, 300, 305, 313, 323, 329, 333, 347, 366], 62: [17, 23, 45, 47, 68, 77, 85, 102, 107, 110, 111, 117, 129, 131, 152, 165, 178, 244, 252, 259, 262, 263, 308, 317, 358, 364, 393, 396], 87: [17, 24, 26, 31, 48, 54, 129, 202, 217, 285, 293, 336, 353, 356], 99: [17, 20, 24, 26, 95, 98, 144, 153, 191, 213, 265], 81: [17, 25, 33, 69, 106, 115, 127, 130, 145, 161, 162, 296, 336, 389], 82: [17, 26, 41, 47, 65, 92, 105, 109, 130, 133, 164, 175, 206, 224, 229, 234, 248, 263, 322, 329, 363, 368], 2: [17, 27, 67, 108, 146, 195, 207, 238, 293, 311, 315, 319, 370, 395], 14: [17, 20, 22, 24, 31, 38, 49, 90, 100, 102, 103, 119, 130, 151, 153, 165, 168, 250, 255, 314, 343, 350, 373, 377, 381, 383, 386], 0: [18, 20, 24, 35, 45, 46, 52, 57, 102, 108, 112, 130, 157, 176, 187, 221, 239, 254, 260, 301, 305, 325, 397], 44: [19, 39, 47, 86, 99, 109, 182, 211, 213, 232, 272, 282, 337, 338, 361, 364, 369, 375, 380, 390], 48: [20, 25, 38, 87, 88, 96, 115, 125, 136, 222, 225, 241, 243, 250, 265, 274, 277, 350, 372], 1: [21, 91, 102, 107, 123, 138, 145, 192, 210, 233, 290, 301, 303, 307, 351], 97: [21, 46, 91, 92, 94, 102, 122, 179, 198, 236, 289, 354, 395], 72: [21, 22, 42, 56, 102, 109, 119, 159, 168, 209, 213, 328, 339, 399], 41: [22, 23, 31, 80, 81, 92, 109, 111, 135, 171, 179, 182, 190, 230, 232, 242, 291, 298, 300, 311, 351, 377, 388], 25: [22, 24, 29, 35, 37, 73, 109, 124, 134, 161, 192, 287, 302, 329, 335, 336, 340, 349, 379, 383, 393, 398], 64: [22, 80, 81, 113, 130, 132, 137, 174, 204, 214, 224, 225, 246, 268, 269, 341], 94: [23, 34, 64, 72, 79, 83, 117, 161, 210, 267, 286, 290, 333, 343, 364, 392, 398], 51: [23, 37, 66, 73, 76, 79, 80, 177, 363, 390], 79: [24, 35, 67, 96, 116, 147, 173, 219, 259, 292, 316, 322, 331, 387, 390], 42: [24, 61, 74, 102, 309, 387], 20: [25, 37, 65, 195, 199, 236, 240, 306, 321, 353, 391], 34: [27, 30, 76, 87, 110, 112, 126, 152, 205, 227, 245, 303, 321, 323, 345, 369, 379, 382], 5: [34, 46, 55, 85, 104, 109, 129, 173, 199, 208, 216, 223, 237, 312, 366, 376], 35: [34, 39, 46, 49, 115, 118, 132, 163, 185, 197, 201, 218, 229, 299, 335, 366, 372], 45: [36, 249, 266, 316], 66: [36, 49, 76, 102, 150, 178, 215, 243, 284, 318, 339, 346, 355], 70: [36, 46, 65, 103, 114, 147, 163, 171, 176, 180, 202, 203, 298, 305, 307, 333, 356], 90: [36, 57], 68: [39, 41, 46, 74, 84, 125, 126, 323, 338, 344, 358], 63: [40, 52, 53, 64, 68, 170, 274, 278, 279, 327, 345], 65: [40, 44, 46, 51, 55, 58, 76, 94, 101, 110, 111, 169, 174, 203, 209, 231, 349, 365, 378, 389], 6: [40, 51, 184, 193, 214, 218, 233, 264, 274, 276], 52: [40, 87, 90, 102, 123, 226, 245, 251], 15: [41, 83, 90, 91, 130, 166, 206, 211, 220, 239, 255, 266, 276, 281, 373, 394], 7: [41, 89, 98, 101, 264, 360], 22: [49, 51, 73, 89, 93, 104, 120, 126, 130, 160, 194, 226, 235, 238, 325, 370, 380], 27: [50, 55, 124, 146, 176, 210, 311, 376], 53: [55, 62, 85, 122, 158, 208, 220, 222, 348], 59: [55, 82, 134, 154, 192, 205, 224, 228, 266, 270, 281, 296], 55: [59, 60, 69, 99, 106, 109, 130, 158, 163, 207, 212, 240, 254, 261, 283, 285, 302, 349, 360], 98: [63, 65, 230, 302, 313], 74: [71, 88, 328, 355], 56: [79, 320, 348, 361], 50: [87, 125, 186], 9: [102, 315, 359, 384], 40: [105, 115, 129, 140, 165, 183, 231], 24: [114, 275, 389], 31: [123, 269], 12: [133, 298], 47: [148, 207], 69: [278, 288, 326], 61: [352, 399]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Assign Behavior Status\n",
        "NP represents the state of no protection, while P represents the state of with protection."
      ],
      "metadata": {
        "id": "6bbX083i9Htn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_protection(hypergraph, fraction_protected):\n",
        "    # Get the list of nodes from the hypergraph\n",
        "    nodes = list(hypergraph.nodes())\n",
        "\n",
        "    # Calculate the number of nodes to protect\n",
        "    num_nodes_to_protect = int(len(nodes) * fraction_protected)\n",
        "\n",
        "    # Randomly choose nodes to protect\n",
        "    nodes_to_protect = random.sample(nodes, num_nodes_to_protect)\n",
        "\n",
        "    # Initialize the protection status dictionary\n",
        "    protection_status = {}\n",
        "\n",
        "    # Assign protection status to each node\n",
        "    for node in nodes:\n",
        "        if node in nodes_to_protect:\n",
        "            protection_status[node] = \"P\"  # Protected node\n",
        "        else:\n",
        "            protection_status[node] = \"N\"  # Non-protected node\n",
        "\n",
        "    print(protection_status)\n",
        "\n",
        "    return protection_status"
      ],
      "metadata": {
        "id": "elKpYEaU9HE1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "fraction_protected = 0.1  # 40% of nodes will be protected\n",
        "protection_status_dict = assign_protection(H2, fraction_protected)\n",
        "print(protection_status_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxZAdvJR-TXv",
        "outputId": "68461cd2-202f-4f27-8e41-324c277523b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'N', 1: 'N', 2: 'N', 3: 'N', 4: 'N', 5: 'N', 6: 'N', 7: 'N', 8: 'N', 9: 'N', 10: 'N', 11: 'N', 12: 'N', 13: 'P', 14: 'N', 15: 'N', 16: 'N', 17: 'N', 18: 'N', 19: 'P', 20: 'N', 21: 'N', 22: 'N', 23: 'P', 24: 'N', 25: 'P', 26: 'N', 27: 'N', 28: 'N', 29: 'N', 30: 'N', 31: 'N', 32: 'N', 33: 'N', 34: 'N', 35: 'N', 36: 'N', 37: 'N', 38: 'P', 39: 'N', 40: 'N', 41: 'N', 42: 'N', 43: 'N', 44: 'N', 45: 'N', 46: 'P', 47: 'N', 48: 'N', 49: 'N', 50: 'N', 51: 'N', 52: 'N', 53: 'N', 54: 'N', 55: 'N', 56: 'N', 57: 'N', 58: 'N', 59: 'N', 60: 'N', 61: 'N', 62: 'N', 63: 'N', 64: 'N', 65: 'N', 66: 'N', 67: 'N', 68: 'N', 69: 'N', 70: 'N', 71: 'N', 72: 'N', 73: 'N', 74: 'N', 75: 'P', 76: 'N', 77: 'N', 78: 'N', 79: 'N', 80: 'N', 81: 'N', 82: 'N', 83: 'N', 84: 'N', 85: 'N', 86: 'P', 87: 'P', 88: 'N', 89: 'N', 90: 'N', 91: 'N', 92: 'N', 93: 'N', 94: 'N', 95: 'N', 96: 'P', 97: 'N', 98: 'N', 99: 'N', 100: 'N', 101: 'N', 102: 'N', 103: 'N', 104: 'N', 105: 'N', 106: 'N', 107: 'P', 108: 'P', 109: 'N', 110: 'N', 111: 'N', 112: 'N', 113: 'N', 114: 'N', 115: 'N', 116: 'P', 117: 'N', 118: 'N', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'N', 124: 'N', 125: 'N', 126: 'N', 127: 'N', 128: 'N', 129: 'P', 130: 'N', 131: 'N', 132: 'P', 133: 'N', 134: 'P', 135: 'N', 136: 'N', 137: 'N', 138: 'N', 139: 'N', 140: 'N', 141: 'N', 142: 'N', 143: 'N', 144: 'N', 145: 'N', 146: 'P', 147: 'N', 148: 'N', 149: 'N', 150: 'N', 151: 'N', 152: 'N', 153: 'N', 154: 'N', 155: 'N', 156: 'N', 157: 'N', 158: 'N', 159: 'N', 160: 'N', 161: 'P', 162: 'N', 163: 'N', 164: 'N', 165: 'N', 166: 'N', 167: 'N', 168: 'N', 169: 'N', 170: 'N', 171: 'N', 172: 'N', 173: 'N', 174: 'N', 175: 'N', 176: 'N', 177: 'N', 178: 'N', 179: 'N', 180: 'N', 181: 'N', 182: 'N', 183: 'N', 184: 'N', 185: 'N', 186: 'N', 187: 'N', 188: 'N', 189: 'N', 190: 'N', 191: 'N', 192: 'P', 193: 'N', 194: 'N', 195: 'N', 196: 'P', 197: 'N', 198: 'N', 199: 'N', 200: 'N', 201: 'N', 202: 'N', 203: 'N', 204: 'N', 205: 'N', 206: 'N', 207: 'N', 208: 'N', 209: 'N', 210: 'N', 211: 'N', 212: 'N', 213: 'N', 214: 'N', 215: 'N', 216: 'N', 217: 'N', 218: 'N', 219: 'N', 220: 'N', 221: 'N', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'N', 227: 'N', 228: 'N', 229: 'N', 230: 'N', 231: 'N', 232: 'N', 233: 'N', 234: 'N', 235: 'N', 236: 'N', 237: 'N', 238: 'N', 239: 'P', 240: 'N', 241: 'N', 242: 'N', 243: 'N', 244: 'N', 245: 'N', 246: 'N', 247: 'N', 248: 'N', 249: 'P', 250: 'N', 251: 'N', 252: 'N', 253: 'N', 254: 'N', 255: 'N', 256: 'N', 257: 'P', 258: 'N', 259: 'N', 260: 'N', 261: 'N', 262: 'N', 263: 'N', 264: 'N', 265: 'N', 266: 'N', 267: 'P', 268: 'N', 269: 'N', 270: 'N', 271: 'N', 272: 'N', 273: 'N', 274: 'N', 275: 'N', 276: 'P', 277: 'P', 278: 'P', 279: 'N', 280: 'P', 281: 'N', 282: 'P', 283: 'N', 284: 'N', 285: 'N', 286: 'N', 287: 'N', 288: 'N', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'N', 294: 'N', 295: 'N', 296: 'N', 297: 'N', 298: 'N', 299: 'N', 300: 'N', 301: 'N', 302: 'N', 303: 'N', 304: 'N', 305: 'N', 306: 'P', 307: 'N', 308: 'N', 309: 'N', 310: 'N', 311: 'N', 312: 'P', 313: 'N', 314: 'N', 315: 'N', 316: 'N', 317: 'N', 318: 'N', 319: 'P', 320: 'N', 321: 'N', 322: 'N', 323: 'N', 324: 'P', 325: 'N', 326: 'P', 327: 'N', 328: 'N', 329: 'N', 330: 'N', 331: 'N', 332: 'N', 333: 'N', 334: 'N', 335: 'N', 336: 'N', 337: 'N', 338: 'N', 339: 'P', 340: 'N', 341: 'N', 342: 'N', 343: 'N', 344: 'N', 345: 'N', 346: 'N', 347: 'N', 348: 'N', 349: 'P', 350: 'N', 351: 'N', 352: 'N', 353: 'N', 354: 'N', 355: 'N', 356: 'N', 357: 'N', 358: 'N', 359: 'N', 360: 'N', 361: 'P', 362: 'N', 363: 'N', 364: 'N', 365: 'N', 366: 'N', 367: 'N', 368: 'N', 369: 'N', 370: 'N', 371: 'N', 372: 'N', 373: 'N', 374: 'N', 375: 'N', 376: 'N', 377: 'P', 378: 'N', 379: 'N', 380: 'N', 381: 'N', 382: 'N', 383: 'P', 384: 'N', 385: 'N', 386: 'N', 387: 'N', 388: 'N', 389: 'N', 390: 'N', 391: 'N', 392: 'N', 393: 'N', 394: 'N', 395: 'N', 396: 'N', 397: 'P', 398: 'N', 399: 'N'}\n",
            "{0: 'N', 1: 'N', 2: 'N', 3: 'N', 4: 'N', 5: 'N', 6: 'N', 7: 'N', 8: 'N', 9: 'N', 10: 'N', 11: 'N', 12: 'N', 13: 'P', 14: 'N', 15: 'N', 16: 'N', 17: 'N', 18: 'N', 19: 'P', 20: 'N', 21: 'N', 22: 'N', 23: 'P', 24: 'N', 25: 'P', 26: 'N', 27: 'N', 28: 'N', 29: 'N', 30: 'N', 31: 'N', 32: 'N', 33: 'N', 34: 'N', 35: 'N', 36: 'N', 37: 'N', 38: 'P', 39: 'N', 40: 'N', 41: 'N', 42: 'N', 43: 'N', 44: 'N', 45: 'N', 46: 'P', 47: 'N', 48: 'N', 49: 'N', 50: 'N', 51: 'N', 52: 'N', 53: 'N', 54: 'N', 55: 'N', 56: 'N', 57: 'N', 58: 'N', 59: 'N', 60: 'N', 61: 'N', 62: 'N', 63: 'N', 64: 'N', 65: 'N', 66: 'N', 67: 'N', 68: 'N', 69: 'N', 70: 'N', 71: 'N', 72: 'N', 73: 'N', 74: 'N', 75: 'P', 76: 'N', 77: 'N', 78: 'N', 79: 'N', 80: 'N', 81: 'N', 82: 'N', 83: 'N', 84: 'N', 85: 'N', 86: 'P', 87: 'P', 88: 'N', 89: 'N', 90: 'N', 91: 'N', 92: 'N', 93: 'N', 94: 'N', 95: 'N', 96: 'P', 97: 'N', 98: 'N', 99: 'N', 100: 'N', 101: 'N', 102: 'N', 103: 'N', 104: 'N', 105: 'N', 106: 'N', 107: 'P', 108: 'P', 109: 'N', 110: 'N', 111: 'N', 112: 'N', 113: 'N', 114: 'N', 115: 'N', 116: 'P', 117: 'N', 118: 'N', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'N', 124: 'N', 125: 'N', 126: 'N', 127: 'N', 128: 'N', 129: 'P', 130: 'N', 131: 'N', 132: 'P', 133: 'N', 134: 'P', 135: 'N', 136: 'N', 137: 'N', 138: 'N', 139: 'N', 140: 'N', 141: 'N', 142: 'N', 143: 'N', 144: 'N', 145: 'N', 146: 'P', 147: 'N', 148: 'N', 149: 'N', 150: 'N', 151: 'N', 152: 'N', 153: 'N', 154: 'N', 155: 'N', 156: 'N', 157: 'N', 158: 'N', 159: 'N', 160: 'N', 161: 'P', 162: 'N', 163: 'N', 164: 'N', 165: 'N', 166: 'N', 167: 'N', 168: 'N', 169: 'N', 170: 'N', 171: 'N', 172: 'N', 173: 'N', 174: 'N', 175: 'N', 176: 'N', 177: 'N', 178: 'N', 179: 'N', 180: 'N', 181: 'N', 182: 'N', 183: 'N', 184: 'N', 185: 'N', 186: 'N', 187: 'N', 188: 'N', 189: 'N', 190: 'N', 191: 'N', 192: 'P', 193: 'N', 194: 'N', 195: 'N', 196: 'P', 197: 'N', 198: 'N', 199: 'N', 200: 'N', 201: 'N', 202: 'N', 203: 'N', 204: 'N', 205: 'N', 206: 'N', 207: 'N', 208: 'N', 209: 'N', 210: 'N', 211: 'N', 212: 'N', 213: 'N', 214: 'N', 215: 'N', 216: 'N', 217: 'N', 218: 'N', 219: 'N', 220: 'N', 221: 'N', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'N', 227: 'N', 228: 'N', 229: 'N', 230: 'N', 231: 'N', 232: 'N', 233: 'N', 234: 'N', 235: 'N', 236: 'N', 237: 'N', 238: 'N', 239: 'P', 240: 'N', 241: 'N', 242: 'N', 243: 'N', 244: 'N', 245: 'N', 246: 'N', 247: 'N', 248: 'N', 249: 'P', 250: 'N', 251: 'N', 252: 'N', 253: 'N', 254: 'N', 255: 'N', 256: 'N', 257: 'P', 258: 'N', 259: 'N', 260: 'N', 261: 'N', 262: 'N', 263: 'N', 264: 'N', 265: 'N', 266: 'N', 267: 'P', 268: 'N', 269: 'N', 270: 'N', 271: 'N', 272: 'N', 273: 'N', 274: 'N', 275: 'N', 276: 'P', 277: 'P', 278: 'P', 279: 'N', 280: 'P', 281: 'N', 282: 'P', 283: 'N', 284: 'N', 285: 'N', 286: 'N', 287: 'N', 288: 'N', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'N', 294: 'N', 295: 'N', 296: 'N', 297: 'N', 298: 'N', 299: 'N', 300: 'N', 301: 'N', 302: 'N', 303: 'N', 304: 'N', 305: 'N', 306: 'P', 307: 'N', 308: 'N', 309: 'N', 310: 'N', 311: 'N', 312: 'P', 313: 'N', 314: 'N', 315: 'N', 316: 'N', 317: 'N', 318: 'N', 319: 'P', 320: 'N', 321: 'N', 322: 'N', 323: 'N', 324: 'P', 325: 'N', 326: 'P', 327: 'N', 328: 'N', 329: 'N', 330: 'N', 331: 'N', 332: 'N', 333: 'N', 334: 'N', 335: 'N', 336: 'N', 337: 'N', 338: 'N', 339: 'P', 340: 'N', 341: 'N', 342: 'N', 343: 'N', 344: 'N', 345: 'N', 346: 'N', 347: 'N', 348: 'N', 349: 'P', 350: 'N', 351: 'N', 352: 'N', 353: 'N', 354: 'N', 355: 'N', 356: 'N', 357: 'N', 358: 'N', 359: 'N', 360: 'N', 361: 'P', 362: 'N', 363: 'N', 364: 'N', 365: 'N', 366: 'N', 367: 'N', 368: 'N', 369: 'N', 370: 'N', 371: 'N', 372: 'N', 373: 'N', 374: 'N', 375: 'N', 376: 'N', 377: 'P', 378: 'N', 379: 'N', 380: 'N', 381: 'N', 382: 'N', 383: 'P', 384: 'N', 385: 'N', 386: 'N', 387: 'N', 388: 'N', 389: 'N', 390: 'N', 391: 'N', 392: 'N', 393: 'N', 394: 'N', 395: 'N', 396: 'N', 397: 'P', 398: 'N', 399: 'N'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Part 3: Assign Threshold\n",
        "The following steps assigns a threshold value to each node in the network. The threshold follows a uniform or normal distribution with predefined mean (mu) and standard deviation (sigma)."
      ],
      "metadata": {
        "id": "F71C7Qfa_b9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines the parameters to be used\n",
        "mu = 0.1\n",
        "sigma = 0.05\n",
        "\n",
        "# Function to assign thresholds to the individual nodes\n",
        "def assign_thresholds(hypergraph, mu, sigma):\n",
        "    NV = hypergraph.order()\n",
        "    Ltre = {}\n",
        "\n",
        "    for node in hypergraph.nodes():\n",
        "          # Uniform distribution: #\n",
        "          #Ltre[node] = np.random.uniform()\n",
        "          # Normal distrution\n",
        "          while True:\n",
        "              threshold = random.gauss(mu, sigma)\n",
        "              if 0 < threshold < 1:\n",
        "                  break\n",
        "          Ltre[node] = threshold\n",
        "\n",
        "    return Ltre"
      ],
      "metadata": {
        "id": "ky4HFlQR_jBY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ltre2 = assign_thresholds(H2, mu, sigma)\n",
        "\n",
        "print(\"Threshold List for Nodes: \", Ltre2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ11eyyS_o1O",
        "outputId": "0d6801ca-3a8b-4ac7-fd2e-b7b22f43572e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold List for Nodes:  {0: 0.08274826250418099, 1: 0.07378668632072478, 2: 0.16356225630723034, 3: 0.04922271535915125, 4: 0.14827750481490967, 5: 0.039159475315706085, 6: 0.11203654805149894, 7: 0.17145983980308077, 8: 0.05749291698281379, 9: 0.05611409435756683, 10: 0.14180998841752368, 11: 0.04523655590106708, 12: 0.04657622416702986, 13: 0.11973067557999115, 14: 0.13188584580298796, 15: 0.12719035061329442, 16: 0.1080801270002266, 17: 0.07083164197341535, 18: 0.027673320273770494, 19: 0.18874390187321896, 20: 0.09618328004212233, 21: 0.15091641866695596, 22: 0.07635155687530566, 23: 0.18345780655631, 24: 0.13739242240026703, 25: 0.17127297471455388, 26: 0.1744974055238611, 27: 0.09959164424759293, 28: 0.12019174937717987, 29: 0.09169287250273317, 30: 0.09196336501660832, 31: 0.09176692685778767, 32: 0.15016078965086807, 33: 0.11722400130495071, 34: 0.05667639421386789, 35: 0.08725060541350228, 36: 0.1117622802800346, 37: 0.19054196085635097, 38: 0.11071931563513583, 39: 0.12998657343074005, 40: 0.059971921715657205, 41: 0.002761180776218272, 42: 0.13844898159721092, 43: 0.1031965698922474, 44: 0.17495523476687586, 45: 0.10754309352458136, 46: 0.12424650605277165, 47: 0.21475097882574076, 48: 0.18289260951225964, 49: 0.13044728895637397, 50: 0.1043358408354797, 51: 0.05698689072638244, 52: 0.14876488496323803, 53: 0.13271064907799024, 54: 0.13319662598805215, 55: 0.11096554428754764, 56: 0.01998737867933699, 57: 0.0748811194673272, 58: 0.12545328659477026, 59: 0.02117801580245178, 60: 0.03400717667814994, 61: 0.02811148220094009, 62: 0.08964206766702028, 63: 0.21716036372154457, 64: 0.02575503722734307, 65: 0.10170364121508683, 66: 0.06468782682761826, 67: 0.09265080162797237, 68: 0.08265688782443542, 69: 0.11949410263718598, 70: 0.11926132785891339, 71: 0.12861149594634474, 72: 0.06844928495816802, 73: 0.15974358504393732, 74: 0.073667473954289, 75: 0.03784083352663306, 76: 0.13218000357051335, 77: 0.08077844123252093, 78: 0.04563748965755098, 79: 0.04733913393059558, 80: 0.08656472100143975, 81: 0.03735211661379782, 82: 0.13654079738896024, 83: 0.14051674579310283, 84: 0.09081996684339669, 85: 0.1007941025939475, 86: 0.0745627251377648, 87: 0.04604650643684599, 88: 0.11129255502435181, 89: 0.05761626081959044, 90: 0.09818032246500052, 91: 0.13052224724416106, 92: 0.04814616667797689, 93: 0.1817312988224058, 94: 0.038546029891372485, 95: 0.14406994316779892, 96: 0.11362056924221922, 97: 0.17235607474942205, 98: 0.08211112192174655, 99: 0.09456437166892866, 100: 0.12076127563675965, 101: 0.04479468361200695, 102: 0.07017797993036658, 103: 0.0550835160709547, 104: 0.10188036097784528, 105: 0.14979026270228318, 106: 0.10608038467610792, 107: 0.13625016166562667, 108: 0.18085587529463587, 109: 0.142356265143921, 110: 0.11579577639553933, 111: 0.0312567400166731, 112: 0.18176173144854338, 113: 0.043460361300802164, 114: 0.08054142935253762, 115: 0.1310856455235589, 116: 0.1456739355305865, 117: 0.09912103718151191, 118: 0.12081416859484018, 119: 0.05572010668749437, 120: 0.07672431957923428, 121: 0.025607418645497718, 122: 0.00283613290371601, 123: 0.11557969472863605, 124: 0.05020909012944607, 125: 0.14542335622837602, 126: 0.1012999428487087, 127: 0.0341806034118258, 128: 0.06965454019456653, 129: 0.08492909190747344, 130: 0.06953688150984501, 131: 0.16501852083292207, 132: 0.12095344238994396, 133: 0.1569121238817097, 134: 0.11681833242563922, 135: 0.14860622231615686, 136: 0.11830284069588748, 137: 0.06725087664132084, 138: 0.045639037975430896, 139: 0.16086409556020256, 140: 0.05160231027287608, 141: 0.07065532961454453, 142: 0.08270568258123813, 143: 0.03488193834236278, 144: 0.08700659978776493, 145: 0.12428480195346187, 146: 0.172547278027951, 147: 0.10772018404900324, 148: 0.15549960310769295, 149: 0.05937647417141228, 150: 0.06681394272280282, 151: 0.10230921713585414, 152: 0.05790115028556755, 153: 0.09598745275960852, 154: 0.046626549173028525, 155: 0.1248411671071395, 156: 0.06833356151864464, 157: 0.19580110155204014, 158: 0.09112637913793115, 159: 0.11884980847932315, 160: 0.09074931687122198, 161: 0.07713834523387798, 162: 0.1857225476478459, 163: 0.09851160317977758, 164: 0.05112711453757931, 165: 0.029391410874717597, 166: 0.11698490969609128, 167: 0.12774016648944292, 168: 0.03237070247018116, 169: 0.11202196889658822, 170: 0.11236614975055574, 171: 0.07957867486939751, 172: 0.1276886851120262, 173: 0.07793037030976048, 174: 0.05674649610899235, 175: 0.058853548631161066, 176: 0.12171333631618966, 177: 0.10082241524844668, 178: 0.1653248068134216, 179: 0.13755090103830714, 180: 0.040619907127002954, 181: 0.004214834836670817, 182: 0.05498333583749902, 183: 0.15425774575563755, 184: 0.10719044481587445, 185: 0.1689708906901848, 186: 0.005906770526216604, 187: 0.14730259406939816, 188: 0.010298559399227941, 189: 0.1312234291283601, 190: 0.15696819420651004, 191: 0.12696519091044509, 192: 0.03449279499745225, 193: 0.015788749176924605, 194: 0.06447988367158256, 195: 0.1107759621023144, 196: 0.03990445833127725, 197: 0.09715116951226199, 198: 0.11524230048983748, 199: 0.05953912316003379, 200: 0.0247526901107524, 201: 0.12104296303565837, 202: 0.053968459672670804, 203: 0.005426902354124935, 204: 0.08723057502939079, 205: 0.06684259232601131, 206: 0.11873539690909057, 207: 0.14415480577628165, 208: 0.06159014471061767, 209: 0.09581869359679605, 210: 0.016417770266556914, 211: 0.04968167049450824, 212: 0.043786197590835144, 213: 0.07521190810972125, 214: 0.03027090238473633, 215: 0.14972080566015733, 216: 0.13253341308774255, 217: 0.14227256880200348, 218: 0.09391285064107702, 219: 0.09763523378546204, 220: 0.050184331188581684, 221: 0.12262283892635646, 222: 0.09628407195327061, 223: 0.0017530257307975805, 224: 0.12620935855965867, 225: 0.17906483146113453, 226: 0.13773041603258895, 227: 0.07994560534161518, 228: 0.170363658460118, 229: 0.07772620102239114, 230: 0.11762369037541545, 231: 0.0712225674735244, 232: 0.1502270994748945, 233: 0.06533139170175811, 234: 0.06894256142085983, 235: 0.08872102620164535, 236: 0.0811701980474697, 237: 0.06284300868318843, 238: 0.14544294964061166, 239: 0.07336743780246194, 240: 0.07063585168926985, 241: 0.12465868096061453, 242: 0.01427016018933916, 243: 0.10132588916284849, 244: 0.05148084043205175, 245: 0.10312509275256707, 246: 0.10369930654661198, 247: 0.07436600568291943, 248: 0.042486743807847664, 249: 0.104088818216537, 250: 0.09496458281811826, 251: 0.060765906051701395, 252: 0.14483041766638516, 253: 0.08431208157470016, 254: 0.12281074409907079, 255: 0.11892771108508361, 256: 0.044021002506458344, 257: 0.0112986955893596, 258: 0.13763892115720028, 259: 0.044605186069568606, 260: 0.1510876756761903, 261: 0.050377427659958146, 262: 0.10576364509799453, 263: 0.07657245594114094, 264: 0.09628719496074281, 265: 0.1070911630581872, 266: 0.12898898500787145, 267: 0.2023361176227504, 268: 0.19158352766608117, 269: 0.029260009558589525, 270: 0.10426629864966212, 271: 0.020861397697747128, 272: 0.08724510319652622, 273: 0.038668962154844146, 274: 0.1128374534734715, 275: 0.07241426826954313, 276: 0.053348546009271504, 277: 0.08362119767634799, 278: 0.10710936525607845, 279: 0.15407199259970186, 280: 0.11357557452024163, 281: 0.12897183779225033, 282: 0.0852021204795522, 283: 0.10350915200871214, 284: 0.002412503351247708, 285: 0.021022119561295974, 286: 0.1037102515755449, 287: 0.056500892309940216, 288: 0.08800398573956651, 289: 0.0730877695877442, 290: 0.15608148712072423, 291: 0.056103058130648836, 292: 0.12610248322349307, 293: 0.029360876830637428, 294: 0.09575536451669556, 295: 0.034698347829081544, 296: 0.11976408827475984, 297: 0.15991272691328623, 298: 0.1821154654784506, 299: 0.05193535248555622, 300: 0.030364142145550138, 301: 0.16192204253264975, 302: 0.12199746649312941, 303: 0.1353443358642753, 304: 0.0881513025088802, 305: 0.152368173308575, 306: 0.18469568664686875, 307: 0.09448268925533915, 308: 0.06792889279625369, 309: 0.09053054609497445, 310: 0.17750511259977209, 311: 0.07528278213140895, 312: 0.07675409533217922, 313: 0.1655980209574353, 314: 0.08959008807116707, 315: 0.07542585758420613, 316: 0.13654607715885944, 317: 0.09089118720384917, 318: 0.16964785215600603, 319: 0.14656241246289195, 320: 0.07815116693194113, 321: 0.08738499766630847, 322: 0.124910757064776, 323: 0.06843807991865725, 324: 0.06268930266578017, 325: 0.07560421246446948, 326: 0.15887686200083195, 327: 0.17007464100433156, 328: 0.08974307662102131, 329: 0.048922691720960115, 330: 0.08391668321476656, 331: 0.1405812088223943, 332: 0.15600457338643242, 333: 0.1298742040710604, 334: 0.14602528907852955, 335: 0.11302730090739353, 336: 0.08416993435497266, 337: 0.046899817696848034, 338: 0.1178940313095608, 339: 0.08879725551734904, 340: 0.1546253985217953, 341: 0.05952035470503037, 342: 0.11124129012518358, 343: 0.046268876206374515, 344: 0.15320507841925882, 345: 0.09600809669899724, 346: 0.1281371307628218, 347: 0.09787920270633924, 348: 0.13254314926480742, 349: 0.16057924435991652, 350: 0.07597344640686467, 351: 0.16421176650194796, 352: 0.07242666160155468, 353: 0.11637179329502757, 354: 0.17120397991843267, 355: 0.141242594101782, 356: 0.11047702315071428, 357: 0.10541796598655216, 358: 0.11848256166589978, 359: 0.1438867010520639, 360: 0.06116213727420005, 361: 0.011419903656423772, 362: 0.07466720266465329, 363: 0.129118413259526, 364: 0.08676358435916741, 365: 0.16178005311493307, 366: 0.13629100220510115, 367: 0.14338702915332144, 368: 0.09405392311315053, 369: 0.10950724864937326, 370: 0.0697910910607762, 371: 0.155826541669687, 372: 0.06870052822025471, 373: 0.07940662872242649, 374: 0.14331737229902136, 375: 0.16351680561819787, 376: 0.15084694495370884, 377: 0.15944704012339844, 378: 0.06064953391767733, 379: 0.06944353290687115, 380: 0.08625441929310888, 381: 0.10851433062334924, 382: 0.2036456079178513, 383: 0.13195623911945, 384: 0.1520728781036682, 385: 0.09878865121708624, 386: 0.11870035301449848, 387: 0.04262945129106052, 388: 0.05195352692323606, 389: 0.10885901003483242, 390: 0.0724000696346423, 391: 0.15352842243624779, 392: 0.15073111672024875, 393: 0.15686271657032966, 394: 0.04838983565172075, 395: 0.14393927732310818, 396: 0.1440671115331187, 397: 0.15711598601458177, 398: 0.060022269668814465, 399: 0.12202212556889314}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: The ICE Model (The Information Cognition Epidemics Model)\n",
        "## Information Layer\n",
        "The misinformation spread occurs on a hyperedge network involving group spreading. The three stages are U(unaware), G(gossip/spreader), and C(stifler/corrected).  \n",
        "\n",
        "## Cognition Layer\n",
        "In the cognitive behavioral layer, P is protected, and N is not protected. The rate of transition from state P to N, p, depends on the information layer. The rate from NP to P is 1-p. The transition rate of a node is also affected by the number of active spreader/stiflers. The bigger number of active neighbors, the faster the rate. Another way behavior may change is based on the fraction of protected neighbors.\n",
        "\n",
        "## Epidemics Layer\n",
        "In the epidemics layer, the possible disease states are S(susceptible), I(infected), and R(recovered). The illness spreading is pairwise. The disease propagation rate depends on the fraction of protected individuals $\\rho_P$.\n",
        "\n"
      ],
      "metadata": {
        "id": "pSmz7Gj6AA9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ICE_model(inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "      inw - information hyperedge network\n",
        "      ltre - list of thresholds for informaiton spread\n",
        "      ldeg_i - degree sequence of information layer\n",
        "\n",
        "      cnw - cognitive network\n",
        "      lprot - list of protection status\n",
        "      ldeg_c - degree sequence of cognition layer\n",
        "\n",
        "      enw - epidemic pairwise network\n",
        "      ldeg_e - degree sequence of epidemic layer\n",
        "\n",
        "      lambda - information spreading rate\n",
        "      alp - informaiton stifling rate\n",
        "\n",
        "      zeta_1 - removing protection rate based on information\n",
        "      zeta_2 - removing protection rate based on neighborhood behavior\n",
        "      zeta_1 - adopting protection rate based on information\n",
        "      zeta_2 - adopting protection rate based on neighborhood behavior\n",
        "\n",
        "      beta_PP - disease transmission rate between protected S and protected I\n",
        "      beta_NP - disease transmission rate between not protected S and protected I\n",
        "      beta_PN - disease transmission rate between protected S and not protected I\n",
        "      beta_NN - disease transmission rate between not protected S and not protected I\n",
        "\n",
        "      mu - disease recovery rate\n",
        "\n",
        "      n_sample - number of samples\n",
        "  \"\"\"\n",
        "\n",
        "  t_max = 100000      # Set maximum time\n",
        "  kmax_i = max (ldeg_i)     # Get maximum hyperedge degree in information layer\n",
        "  kmax_c = max (ldeg_c)     # Get maximum hyperedge degree in cognition layer\n",
        "  kmax_e = max (ldeg_e)     # Get maximum degree in epidemic layer\n",
        "  N = inw.order()  # Get the network size\n",
        "\n",
        "  rho_C = []   # Keep track of fraction of corrected in information layer\n",
        "  rho_P = []   # Keep track of fraction of protected in cognition layer\n",
        "  rho_R = []   # Keep track of fraction of recovered in epidemic layer\n",
        "\n",
        "  for i_samp in range(1, n_sample + 1):\n",
        "      t = 0                 # Initialize time, number of corrected, number of recovered\n",
        "      N_corrected = 0\n",
        "      N_recovered = 0\n",
        "\n",
        "      info_states = {j: \"U\" for j in inw.nodes()}   # Initialize information and disease states\n",
        "      disease_states = {k: \"S\" for k in enw.nodes()}\n",
        "\n",
        "      protected = list(filter(lambda node: lprot[node] == \"P\", lprot))\n",
        "      N_protected = len(protected)\n",
        "      not_protected = list(filter(lambda node: lprot[node] == \"N\", lprot))\n",
        "\n",
        "\n",
        "      gossip = []     # Create lists to store gossip and corrected individuals in information layer\n",
        "      corrected = []\n",
        "\n",
        "      rumor_node_0 = np.random.choice(list(inw.nodes()))   # Pick a random person to start misinformaiton spreading\n",
        "      info_states[rumor_node_0] = \"G\"\n",
        "      gossip.append(rumor_node_0)\n",
        "      N_gossip = 1\n",
        "      N_e_i = inw.degree(rumor_node_0)\n",
        "\n",
        "      infected = []     # Create lists to store infected and recovered individuals in epidemic layer\n",
        "      recovered = []\n",
        "\n",
        "      ill_node_0 = np.random.choice(list(enw.nodes()))   # Pick a random person to start disease spreading\n",
        "      disease_states[ill_node_0] = \"I\"\n",
        "      infected.append(ill_node_0)\n",
        "      N_infected = 1\n",
        "      N_e_e = enw.degree(ill_node_0)\n",
        "\n",
        "      while N_gossip > 0:   # We stop when there is no infection and no gossip\n",
        "          total_rate = lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip + zeta_2 * (N-N_gossip) + zeta_3 * (N-N_protected) + zeta_4 * N_protected\n",
        "          tau = -np.log(np.random.uniform(1e-6, 1)) / total_rate\n",
        "          t += tau\n",
        "\n",
        "          if t >= t_max:\n",
        "                break\n",
        "\n",
        "          # Determine which event occurs\n",
        "          event = np.random.uniform()\n",
        "          p1 = (lam * N_e_i) / total_rate     # rumor spreading\n",
        "          p2 = (lam * N_e_i + alp * N_e_i) / total_rate  # rumor stifling (by meeting stifling neighbor threshold)\n",
        "          p3 = (lam * N_e_i + 2 * alp * N_e_i) / total_rate  # rumor stifling (by meeting gossip neighbor threshold)\n",
        "\n",
        "          p4 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e) / total_rate  # disease propagation\n",
        "          p5 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected) / total_rate  # disease recovery\n",
        "\n",
        "          p6 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip) / total_rate # change to not adopting protection by information\n",
        "          p7 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip + zeta_2 * (N-N_gossip)) / total_rate # change to adopting protection by information\n",
        "          p8 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_gossip + zeta_2 * (N-N_gossip) + zeta_3 * (N-N_protected)) / total_rate # change to not adopting protection by neighborhood behavior\n",
        "          # > p8 # change to adopting protection by neighborhood behavior\n",
        "          #print(p1, p2, p3, p4, p5, p6, p7, p8)\n",
        "\n",
        "          # Determine if accept selected individual based on degree distribution\n",
        "          q_deg_i = np.random.uniform()\n",
        "          q_deg_c = np.random.uniform()\n",
        "          q_deg_e = np.random.uniform()\n",
        "\n",
        "          # Case 1: Rumor spreading\n",
        "          if event < p1:\n",
        "                gossip_node = random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(gossip_node) / kmax_i:\n",
        "                    rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[rumor_hyper_edge]\n",
        "                    \"\"\"\n",
        "                    while gossip_node not in neighbors:\n",
        "                        rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                        neighbors = inw[rumor_hyper_edge]\n",
        "                    \"\"\"\n",
        "                    MAX_ITERATIONS = 10 # Set a reasonable limit based on your specific case\n",
        "                    iterations = 0\n",
        "                    while gossip_node not in neighbors:\n",
        "                        if iterations > MAX_ITERATIONS:\n",
        "                           break\n",
        "                        rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                        neighbors = inw[rumor_hyper_edge]\n",
        "                        iterations += 1\n",
        "\n",
        "                    for neighbor in neighbors:\n",
        "                            if info_states[neighbor] == \"U\":\n",
        "                                count_gossip_neighbors = sum(1 for node in inw.neighbors(neighbor) if info_states[node] == \"G\")\n",
        "                                if count_gossip_neighbors / len(inw.neighbors(neighbor)) >= ltre[neighbor]:\n",
        "                                    info_states[neighbor] = \"G\"  # uninformed neighbor becomes gossip spreader\n",
        "                                    gossip.append(neighbor)\n",
        "                                    N_gossip += 1\n",
        "\n",
        "\n",
        "\n",
        "          # Case 2: Rumor stifling (by meeting stifling neighbor threshold)\n",
        "          elif event < p2:\n",
        "            #if N_gossip > 0:\n",
        "                stifler_node = np.random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(stifler_node)  / kmax_i:\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_stifler_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"C\")\n",
        "                    if count_stifler_neighbors / len(neighbors) >= ltre[stifler_node]:\n",
        "                            info_states[stifler_node] = \"C\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            corrected.append(stifler_node)\n",
        "                            N_corrected += 1\n",
        "\n",
        "          # Case 3: Rumor stifling (by meeting gossip neighbor threshold)\n",
        "          elif event < p3:\n",
        "            #if N_gossip > 0:\n",
        "                stifler_node = np.random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(stifler_node) / kmax_i:\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_gossip_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"G\")\n",
        "                    if count_gossip_neighbors / len(neighbors) >= ltre[stifler_node]:\n",
        "                            info_states[stifler_node] = \"C\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            corrected.append(stifler_node)\n",
        "                            N_corrected += 1\n",
        "\n",
        "          # Case 4: Disease propagation\n",
        "          elif event < p4:\n",
        "            if N_infected > 0:\n",
        "              infected_node = np.random.choice(infected)\n",
        "              infected_protected = lprot[infected_node]\n",
        "              neighbors = list(enw.neighbors(infected_node))\n",
        "              susceptible_neighbors = [n for n in neighbors if disease_states[n] == \"S\"]\n",
        "\n",
        "              if len(susceptible_neighbors) > 0:\n",
        "                  neighbor = np.random.choice(susceptible_neighbors)\n",
        "                  neighbor_protected = lprot[neighbor]\n",
        "\n",
        "                  # Determine the appropriate transmission rate based on protection status\n",
        "                  if neighbor_protected == \"P\" and infected_protected == \"P\":\n",
        "                            transmission_rate = beta_PP/beta_NN\n",
        "                  elif neighbor_protected == \"N\" and infected_protected == \"P\":\n",
        "                            transmission_rate = beta_NP/beta_NN\n",
        "                  elif neighbor_protected == \"P\" and infected_protected == \"N\":\n",
        "                            transmission_rate = beta_PN/beta_NN\n",
        "                  else:\n",
        "                            transmission_rate = beta_NN/beta_NN\n",
        "\n",
        "                  if np.random.uniform() < transmission_rate:\n",
        "                      disease_states[neighbor] = \"I\"\n",
        "                      infected.append(neighbor)\n",
        "                      N_infected += 1\n",
        "                      N_e_e += enw.degree(neighbor)\n",
        "\n",
        "          # Case 5: Disease recovery\n",
        "          elif event < p5:\n",
        "            if N_infected > 0:\n",
        "                recovered_node = np.random.choice(infected)\n",
        "                if q_deg_e < ldeg_e[recovered_node]/kmax_e:\n",
        "                    disease_states[recovered_node] = \"R\"\n",
        "                    infected.remove(recovered_node)\n",
        "                    recovered.append(recovered_node)\n",
        "                    N_infected -= 1\n",
        "                    N_recovered += 1\n",
        "                    N_e_e -= enw.degree(recovered_node)\n",
        "\n",
        "          # Case 6: # Change to not adopting protection based on information layer\n",
        "          # rate = zeta_1 * n_G / k_info\n",
        "          # n_G is the total spreader neighbors on the information layer,\n",
        "          # while k_info is the total neighbor count on the information layer\n",
        "          elif event < p6:\n",
        "            if len(protected) > 0:\n",
        "              node_to_not_protect = np.random.choice(protected)\n",
        "              n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_not_protect)))\n",
        "              k_info = len(inw.neighbors(node_to_not_protect))\n",
        "              if np.random.uniform() < zeta_1 * n_G / k_info:\n",
        "                    lprot[node_to_not_protect] = \"N\"\n",
        "                    protected.remove(node_to_not_protect)\n",
        "                    not_protected.append(node_to_not_protect)\n",
        "                    N_protected -= 1\n",
        "\n",
        "          # Case 7: Change to adopting protection based on information layer\n",
        "          # rate = zeta_2 * (1 - n_G / k_info)\n",
        "          elif event < p7:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_protect)))\n",
        "                k_info = len(inw.neighbors(node_to_protect))\n",
        "                if np.random.uniform() < zeta_2 * (1 - n_G / k_info):\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "\n",
        "\n",
        "          # Case 8: # Change to not adopting protection based on neighborhood behavior in cognition layer\n",
        "          # rate = zeta_3 * (1 - n_P / k_cog)\n",
        "          # n_P is the total protected neighbors on the cognition layer,\n",
        "          # while k_cog is the total neighbor count on the cognition layer\n",
        "          elif event < p8:\n",
        "            if len(protected) > 0:\n",
        "                node_to_not_protect = np.random.choice(protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_not_protect)))\n",
        "                k_cog = len(cnw.neighbors(node_to_not_protect))\n",
        "                if np.random.uniform() < zeta_3 * (1 - n_P / k_cog):\n",
        "                        lprot[node_to_not_protect] = \"N\"\n",
        "                        protected.remove(node_to_not_protect)\n",
        "                        not_protected.append(node_to_not_protect)\n",
        "                        N_protected -= 1\n",
        "\n",
        "\n",
        "          # Case 9: # Change to adopting protection based on neighborhood behavior in cognition layer\n",
        "          # rate = zeta_4 * n_P / k_cog\n",
        "          else:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_protect)))\n",
        "                k_cog = len(cnw.neighbors(node_to_protect))\n",
        "                if np.random.uniform() < zeta_4 * n_P / k_cog:\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "      #print(\"N_infected\", N_infected, \"N_gossip\", N_gossip)\n",
        "      if N_infected == 0:\n",
        "          corrected_frac = N_corrected / N\n",
        "          protected_frac = N_protected / N\n",
        "          recovered_frac = N_recovered / N\n",
        "          rho_C.append(corrected_frac)\n",
        "          rho_P.append(protected_frac)\n",
        "          rho_R.append(recovered_frac)\n",
        "          print(\"corrected_frac\", corrected_frac, \"recovered_frac\", recovered_frac)\n",
        "\n",
        "  avg_rho_C = sum(rho_C) / len(rho_C)\n",
        "  avg_rho_P = sum(rho_P) / len(rho_P)\n",
        "  avg_rho_R = sum(rho_R) / len(rho_R)\n",
        "\n",
        "  return avg_rho_C, avg_rho_P, avg_rho_R\n"
      ],
      "metadata": {
        "id": "i3rNTHw7F-6v"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 400  # Number of nodes\n",
        "\n",
        "# Information Layer\n",
        "gamma_i = 2.5  # Power-law exponent\n",
        "kmin_i = 3  # Minimum degree\n",
        "num_hyper_edges_i = 100  # Desired number of hyper edges\n",
        "ldeg_i, hyperedge_dict_i = build_hypergraph(n, gamma_i, kmin_i, num_hyper_edges_i)\n",
        "inw = hnx.Hypergraph(hyperedge_dict_i)\n",
        "ltre = assign_thresholds(inw, 0.05, 0.03)\n",
        "\n",
        "# Cognition Layer\n",
        "gamma_c = 3.0  # Power-law exponent\n",
        "kmin_c = 3  # Minimum degree\n",
        "num_hyper_edges_c = 100  # Desired number of hyper edges\n",
        "ldeg_c, hyperedge_dict_c = build_hypergraph(n, gamma_c, kmin_c, num_hyper_edges_c)\n",
        "cnw = hnx.Hypergraph(hyperedge_dict_c)\n",
        "frac_prot = 0.1\n",
        "lprot = assign_protection(cnw, frac_prot)\n",
        "\n",
        "# Epidemic Layer\n",
        "gamma_e = 4.0\n",
        "kmin_e = 3\n",
        "ldeg_e = generate_degree_sequence(n, gamma_e, kmin_e)\n",
        "print(\"Degree Sequence: \", ldeg_e)\n",
        "enw = nx.configuration_model(ldeg_e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_NnnBI-BZpo",
        "outputId": "dcb9c89a-5751-48a2-ceae-ca0671aa9584"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degree Sequence:  [4, 11, 5, 4, 3, 3, 3, 18, 5, 6, 8, 4, 5, 3, 5, 10, 13, 3, 5, 3, 3, 3, 3, 4, 3, 5, 3, 7, 16, 3, 4, 9, 4, 5, 3, 6, 3, 3, 4, 3, 4, 7, 3, 5, 4, 3, 4, 4, 3, 4, 3, 3, 3, 5, 3, 5, 3, 8, 3, 9, 12, 3, 4, 5, 3, 8, 3, 4, 3, 3, 3, 3, 6, 3, 3, 4, 3, 12, 3, 4, 6, 3, 9, 8, 3, 7, 6, 4, 3, 12, 6, 17, 3, 3, 3, 10, 3, 3, 3, 3, 3, 3, 5, 3, 5, 3, 4, 3, 4, 3, 4, 4, 4, 6, 5, 3, 14, 3, 3, 3, 3, 4, 4, 5, 4, 3, 5, 3, 3, 3, 3, 3, 4, 3, 10, 3, 5, 5, 4, 6, 7, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [8, 3, 28, 5, 24, 26, 4, 8, 19, 17, 25, 8, 33, 4, 12, 33, 23, 15, 34, 34, 24, 8, 34, 31, 26, 25, 5, 36, 8, 29, 5, 27, 2, 19, 20, 19, 18, 6, 2, 28, 16, 28, 15, 33, 37, 8, 11, 5, 21, 14, 28, 16, 8, 33, 14, 6, 10, 35, 19, 11, 4, 21, 23, 23, 31, 37, 30, 34, 2, 28, 19, 3, 27, 28, 22, 15, 6, 20, 13, 10, 35, 5, 28, 4, 9, 24, 2, 21, 21, 4, 29, 7, 2, 35, 34, 16, 37, 11, 19, 31]\n",
            "Hypergraph Dictionary:  {85: [0, 59, 65, 82, 83, 91, 102, 124, 162, 165, 177, 189, 249, 256, 305, 326, 331], 17: [0, 15, 18, 25, 38, 104, 116, 120, 134, 213, 224, 268, 274, 357], 45: [0, 9, 91, 108, 131, 179, 288], 20: [0, 2, 7, 25, 55, 85, 105, 140, 158, 173, 231, 239, 248, 264, 307, 316, 351, 362, 363, 366, 378, 379, 394], 51: [1, 5, 57, 63, 80, 83, 84, 89, 310], 0: [1, 78, 82, 136, 177, 211, 285, 311], 22: [1, 5, 26, 29, 55, 58, 59, 60, 63, 65, 77, 90, 91, 95, 96, 114, 121, 135, 236, 263, 267, 292, 296, 315, 333, 341, 346, 354], 53: [1, 7, 21, 28, 30, 46, 64, 65, 70, 85, 91, 113, 114, 116, 126, 140, 154, 191, 238, 250, 256, 261, 269, 283, 303, 347, 361], 97: [1, 2, 9, 139, 208, 294, 313, 397], 49: [1, 116, 145, 176, 273, 325, 333, 370], 39: [1, 23, 24, 27, 29, 39, 75, 77, 100, 103, 111, 119, 127, 195, 235, 252, 255, 280, 303, 304, 305, 373, 390], 66: [1, 2, 32, 39, 44, 45, 49, 56, 59, 86, 87, 89, 105, 116, 127, 144, 151, 156, 160, 295, 296, 364, 380, 388], 95: [1, 35, 47, 102, 136, 142, 272, 283, 290, 299, 323, 346, 356], 43: [1, 12, 16, 25, 33, 34, 35, 42, 54, 77, 124, 129, 152, 153, 154, 161, 223, 233, 241, 253, 257, 281, 316, 331, 335, 337, 347], 18: [1, 11, 13, 16, 41, 50, 57, 76, 97, 105, 113, 117, 126, 138, 151, 209, 231, 254, 298, 326, 337, 339, 344, 370, 372], 87: [2, 15, 28, 41, 42, 60, 70, 91, 120, 135, 141, 200, 206, 306, 334, 349, 381], 70: [2, 44, 60, 61, 139, 158, 163, 169, 199, 251, 282, 285, 287, 288, 303, 366], 8: [3, 6, 10, 28, 31, 35, 46, 63, 111, 126, 219, 243, 265, 353, 363, 368], 57: [3, 15, 28, 48, 60, 66, 72, 79, 81, 91, 98, 100, 115, 116, 125, 132, 167, 201, 211, 226, 232, 245, 257, 307, 312, 336, 343, 364, 367, 388, 396], 80: [3, 7, 28, 40, 77, 82, 85, 86, 94, 112, 136, 144, 145, 166, 170, 173, 178, 184, 186, 220, 223, 233, 307, 311, 322, 341, 368, 385, 387, 393], 61: [3, 11, 28, 82, 86, 89, 91, 170, 238, 264, 318, 329, 333, 355, 369], 67: [4, 16, 27, 28, 38, 54, 59, 63, 68, 77, 79, 89, 101, 113, 115, 124, 139, 180, 192, 193, 207, 228, 231, 275, 344, 345, 349, 384, 397], 84: [4, 10, 52, 83, 106, 206, 330, 332], 73: [4, 9, 35, 41, 49, 53, 60, 71, 91, 96, 119, 125, 166, 183, 199, 219, 265, 293, 302, 310, 331], 65: [5, 14, 16, 30, 33, 34, 49, 60, 88, 102, 115, 116, 132, 134, 155, 156, 171, 187, 196, 218, 229, 251, 287, 293, 298, 300, 304, 317, 318, 325, 327, 349, 365], 23: [6, 27, 30, 42, 43, 51, 55, 58, 76, 114, 133, 141, 159, 168, 175, 190, 229, 230, 246, 252, 314, 326, 352, 394], 30: [6, 54, 84, 360], 16: [7, 18, 35, 38, 44, 48, 65, 82, 106, 116, 123, 127, 151, 182, 193, 266, 277, 290, 373, 396], 88: [7, 15, 18, 28, 32, 40, 72, 95, 104, 116, 147, 167, 212, 227, 291, 389], 27: [7, 30, 31, 57, 62, 66, 69, 77, 82, 91, 93, 116, 130, 137, 146, 172, 178, 191, 198, 201, 202, 215, 241, 247, 316, 320, 343, 360, 370, 375], 69: [7, 11, 14, 22, 45, 71, 72, 75, 76, 78, 86, 101, 112, 135, 136, 138, 149, 248, 272, 276, 283, 294, 348, 350, 392], 74: [7, 31, 43, 44, 77, 91, 210, 214, 216, 244, 268, 306, 317, 361, 367, 386], 59: [7, 28, 33, 60, 62, 77, 188, 280, 394], 72: [7, 31, 53, 79, 89, 113, 128, 202, 217, 228, 235, 242, 261, 270, 288, 324, 328, 359, 364, 372, 395], 10: [7, 22, 31, 46, 62, 112, 150, 152, 155, 182, 183, 187, 232, 239, 324, 345, 397], 79: [7, 95, 113, 138, 205, 318], 14: [7, 18, 60, 67, 122, 155, 174, 356], 98: [7, 9, 41, 50, 75, 80, 131, 134, 136, 236, 237, 334, 359, 382], 56: [7, 8, 47, 91, 128, 134, 240, 276, 359], 96: [7, 31, 37, 47, 53, 60, 73, 95, 102, 122, 129, 138, 141, 143, 173, 181, 201, 213, 215, 216, 225, 229, 249, 258, 323, 329, 343, 350, 353, 379, 387], 46: [7, 29, 32, 94, 195, 237, 378], 50: [7, 20, 23, 41, 57, 89, 104, 116, 119, 122, 132, 137, 169, 185, 197, 222, 259, 264, 270, 342, 351, 398], 44: [8, 14, 24, 40, 53, 55, 61, 80, 86, 95, 103, 107, 109, 116, 130, 143, 146, 162, 234, 243, 247, 254, 269, 274, 286, 309, 395], 9: [8, 16, 99, 104, 110, 114, 180, 181, 314, 317, 363, 368, 388], 7: [8, 96, 208], 48: [8, 10, 16, 51, 65, 77, 95, 137, 248, 279, 284, 296, 297, 332, 366, 380], 63: [9, 21, 89, 91, 101, 106, 108, 116, 147, 148, 149, 153, 194, 203, 216, 235, 246, 269, 358, 374], 94: [9, 17, 19, 59, 90, 97, 100, 106, 123, 142, 166, 168, 178, 185, 194, 196, 204, 206, 225, 234, 238, 266, 277, 355, 376], 64: [10, 12, 13, 36, 57, 59, 95, 109, 118, 134, 181, 220, 221, 227, 257, 260, 270, 274, 277, 301, 309, 315, 327, 377, 398], 90: [10, 15, 41, 43, 59, 84, 104, 110, 121, 143, 159, 165, 171, 182, 233, 246, 263, 273, 286, 319, 321, 360, 383, 389], 33: [10, 27, 73, 79, 111, 123, 175, 184, 209, 222, 297, 320], 24: [10, 12, 17, 31, 65, 85, 108, 134, 140, 145, 157, 159, 190, 212, 244, 261, 275, 299, 319, 344, 346, 352], 29: [10, 12, 16, 43, 47, 51, 87, 93, 99, 111, 118, 190, 202, 211, 213, 218, 281, 292, 295, 342, 345, 376, 393], 5: [11, 43, 62, 88, 89, 91, 116, 134, 147, 174, 179, 204, 210, 281, 300, 319, 328, 342, 385, 395, 399], 12: [12, 15, 34, 41, 71, 89, 121, 150, 153, 164, 180, 198, 200, 208, 212, 221, 228, 253, 256, 301, 350, 354, 355, 385], 31: [13, 31, 32, 57, 87, 92, 130, 134, 160, 170, 194, 198, 252, 312, 339, 365, 383, 389], 25: [14, 27, 55, 57, 60, 64, 67, 82, 98, 134, 140, 158, 164, 175, 188, 197, 224, 230, 243, 279, 295, 308, 311, 321, 362], 99: [14, 15, 25, 27, 33, 36, 64, 85, 91, 95, 126, 142, 157, 163, 197, 293, 313, 362, 367, 378], 75: [15, 16, 148, 186, 285, 289, 309, 312, 323, 351, 374], 77: [15, 28, 77, 90, 91, 109, 121, 137, 161, 258, 259, 272, 369, 371, 382], 15: [15, 28, 56, 63, 67, 81, 89, 143, 164, 177, 200, 218, 253, 262, 268, 278, 286, 310, 320, 325, 330, 334, 371, 376, 392], 2: [16, 20, 28, 37, 69, 87, 113, 131, 140, 187, 226, 227, 247, 250, 255, 278, 305, 347, 381, 384], 71: [16, 82, 98], 19: [16, 28, 52, 53, 57, 60, 74, 75, 80, 91, 112, 139, 174, 188, 189, 192, 196, 205, 209, 240, 290, 302, 314, 327, 332, 336, 361], 54: [16, 50, 65, 82, 83, 140, 169, 172, 271, 386, 391], 62: [16, 22, 68, 74, 102, 108, 110, 116, 128, 144, 157, 168, 199, 207, 217, 244, 255, 308, 338], 93: [17, 20, 23, 26, 33, 61, 66, 73, 81, 91, 95, 123, 124, 134, 162, 167, 185, 214, 223, 232, 239, 249, 250, 263, 267, 282, 352, 365, 377, 392], 41: [18, 19, 25, 88, 107, 120, 152, 176, 184, 204, 221, 241, 251, 262, 287, 289, 292, 348, 373, 386, 398], 11: [19, 139, 176, 357], 52: [21, 94, 114, 160, 215], 35: [23, 48, 67, 77, 80, 83, 90, 271, 282, 284, 315, 328, 340, 341, 357, 369], 3: [24, 36, 380], 6: [26, 72, 140, 161], 89: [27, 92, 133, 195], 58: [28, 40, 90, 103, 110, 117, 123, 150, 186, 214, 226, 234, 242, 335, 396], 42: [28, 65, 93, 149, 179, 189, 259, 299, 322, 372, 382], 36: [28, 37, 46, 52, 58, 89, 143, 148, 225, 266, 321, 337], 40: [31, 56, 85, 90, 95, 118, 156, 191, 236, 258, 275, 329, 371], 34: [35, 38, 72, 83, 117, 126, 139, 143, 154, 172, 203, 222, 289, 297, 304, 330, 375], 4: [39, 59, 68, 99, 107, 122, 125, 132, 133, 193, 217, 262, 267, 302, 308, 384], 1: [45, 83, 340], 21: [49, 69, 278, 280, 301], 82: [59, 60, 74, 89, 171, 203, 219, 230, 240, 254, 265, 271, 336, 354, 375, 390], 86: [70], 38: [72, 339], 32: [77, 383], 28: [78, 192, 291, 322, 324, 374, 391], 83: [80, 163, 260, 276], 91: [83, 220, 300, 338], 78: [85, 207, 237, 273, 306, 340, 353, 358, 379, 381], 68: [86, 260], 37: [92, 245, 298, 348, 356, 399], 76: [97, 242, 294, 313, 358], 55: [129, 183, 338, 399], 26: [137, 393], 81: [146, 205, 335, 391], 60: [165, 377], 13: [210, 291], 47: [224, 279, 284, 390], 92: [245, 387]}\n",
            "Degree Sequence:  [3, 6, 3, 5, 4, 3, 9, 3, 5, 4, 3, 6, 3, 3, 3, 3, 3, 5, 3, 4, 3, 3, 5, 4, 3, 3, 4, 3, 3, 3, 4, 5, 4, 3, 4, 3, 3, 11, 3, 3, 5, 3, 3, 3, 13, 3, 3, 4, 5, 3, 5, 5, 3, 3, 3, 3, 4, 4, 4, 3, 4, 4, 3, 3, 6, 4, 3, 3, 5, 3, 3, 3, 5, 5, 4, 3, 3, 4, 4, 10, 10, 7, 4, 3, 3, 4, 9, 10, 3, 4, 3, 3, 11, 3, 14, 3, 4, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [21, 9, 31, 26, 19, 24, 35, 4, 23, 36, 25, 12, 15, 35, 12, 5, 22, 15, 13, 9, 19, 22, 33, 35, 20, 12, 4, 19, 21, 26, 36, 13, 28, 26, 35, 13, 34, 25, 12, 20, 26, 18, 26, 20, 13, 27, 12, 6, 19, 30, 12, 30, 18, 26, 17, 25, 13, 23, 3, 6, 5, 16, 18, 9, 26, 10, 9, 21, 2, 34, 20, 35, 27, 8, 32, 29, 6, 36, 3, 34, 5, 2, 22, 3, 21, 12, 10, 2, 11, 19, 21, 4, 36, 20, 10, 25, 30, 10, 32, 18]\n",
            "Hypergraph Dictionary:  {89: [0, 12, 19, 32, 37, 47, 68, 79, 103, 222, 224, 241, 352], 64: [0, 1, 6, 17, 24, 64, 79, 81, 97, 124, 233, 265, 269, 277, 285, 306], 80: [0, 3, 145, 360, 388], 53: [1, 38, 59, 60, 69, 96, 113, 120, 156, 177, 193, 199, 229, 259, 262, 267, 268, 287, 320, 336, 342, 364, 389], 16: [1, 22, 61, 79, 87, 91, 121, 123, 129, 155, 163, 201, 291, 333, 349, 359], 10: [1, 19, 27, 47, 49, 54, 92, 100, 156, 181, 204, 215, 267, 279, 300, 308, 325, 352, 355, 394], 23: [1, 15, 30, 62, 76, 92, 94, 96, 112, 128, 134, 135, 155, 181, 184, 201, 231, 315, 325, 352, 365, 372], 43: [1, 37, 79, 81, 94, 140, 161, 178, 206, 249, 255, 362, 391], 55: [2, 20, 27, 80, 99, 147, 165, 173, 197, 253, 256, 258, 267, 276, 311, 358, 383], 59: [2, 3, 37, 206], 79: [2, 13, 67, 80, 149, 158, 165, 169, 181, 200, 215, 225, 252, 265, 272, 289, 326, 330, 363, 371, 374, 375], 34: [3, 6, 17, 19, 42, 44, 68, 81, 92, 94, 129, 135, 144, 177, 184, 198, 244, 272, 282, 290, 304, 322, 331, 354, 361, 389], 37: [3, 13, 71, 85, 88, 94, 158, 213, 242, 250, 261, 312, 317, 355, 363], 95: [3, 44, 65, 80, 125, 140, 161, 197, 236, 241, 247, 276, 316, 359, 375, 397], 75: [4, 33, 37, 43, 52, 56, 66, 102, 126, 138, 139, 147, 158, 209, 319, 327, 329, 351], 6: [4, 6, 8, 11, 20, 62, 76, 86, 92, 99, 145, 160, 170, 175, 218, 246, 251, 272, 284, 305, 368], 9: [4, 11, 27, 42, 44, 48, 61, 80, 94, 116, 137, 141, 168, 182, 192, 207, 233, 284, 294, 297, 345, 353, 358, 366, 370, 377], 70: [4, 10, 16, 22, 31, 39, 131, 166, 186, 188, 198, 210, 372, 382], 30: [5, 8, 29, 31, 46, 55, 85, 141, 150, 172, 185, 202, 203, 225, 274, 279, 280, 281, 296, 306, 315, 329, 339], 51: [5, 24, 31, 32, 54, 71, 86, 92, 111, 154, 162, 186, 214, 232, 234, 237, 251, 293, 310, 341, 380, 381, 384], 66: [5, 23, 51, 175, 194, 203, 254, 304, 332], 71: [6, 37, 50, 58, 62, 73, 94, 104, 117, 190, 211, 226, 233, 243, 244, 270, 293, 302, 305, 314, 339, 347, 360, 378, 399], 18: [6, 10, 36, 37, 47, 116, 148, 150, 179, 370, 396], 82: [6, 9, 19, 26, 28, 35, 82, 107, 126, 131, 167, 185, 258, 260, 311, 334], 33: [6, 18, 22, 43, 60, 78, 86, 95, 115, 138, 152, 165, 208, 317, 326, 340, 382, 390], 69: [6, 18, 34, 48, 53, 70, 94, 117, 144, 154, 175, 195, 218, 224, 227, 240, 247, 271, 304, 305, 309, 327, 328, 336, 356, 376], 96: [6, 30, 31, 37, 45, 59, 64, 80, 84, 87, 123, 183, 194, 251, 335, 342, 345, 348, 353, 362, 369, 383, 386, 395], 7: [7, 48], 77: [7, 30, 68, 77, 81, 92, 108, 110, 223, 239, 249, 254, 280, 312, 316, 320, 354, 374, 375, 380], 98: [7, 38, 40, 44, 59, 72, 79, 86, 89, 110, 151, 196, 227, 253, 278, 327, 329, 336, 354], 13: [8, 26, 30, 80, 86, 118, 172, 178, 191, 208, 259, 265, 292, 295, 297, 298, 328, 338, 349, 367, 385, 388], 31: [8, 23, 37, 61, 83, 115, 187, 192, 257, 275, 344, 366], 74: [8, 12, 21, 60, 73, 76, 82, 127, 159, 166, 176, 179, 184, 210, 230, 235, 255, 262, 328, 331, 339, 359], 22: [9, 23, 26, 39, 40, 58, 69, 83, 99, 129, 136, 147, 234, 259, 289, 307, 326, 373, 376, 393], 12: [9, 36, 89, 95, 117, 160, 243, 278, 346], 48: [9, 16, 63, 80, 94, 101, 106, 114, 194, 196, 205, 218, 299], 93: [10, 49, 51, 65, 87, 93, 119, 236, 269, 277, 311, 364, 391, 399], 28: [11, 32, 37, 44, 104, 133, 146, 159, 223, 264, 279, 280, 308, 387], 91: [11, 18], 4: [11, 23, 40, 42, 57, 86, 93, 94, 112, 136, 183, 221, 227, 357], 54: [11, 103, 105, 148, 193, 200, 220, 284, 299, 319, 337, 362, 374], 36: [12, 21, 44, 47, 51, 73, 77, 87, 91, 99, 102, 107, 123, 189, 193, 211, 238, 278, 290, 322, 369, 391], 57: [13, 41, 153, 176, 220, 256, 295, 307, 309, 314, 334, 396], 39: [14, 29, 40, 49, 53, 87, 132, 192, 231, 324, 346, 373], 47: [14, 75, 119, 166, 197, 287], 29: [14, 28, 31, 51, 72, 83, 89, 90, 103, 113, 122, 134, 140, 216, 302, 313, 334, 366], 21: [15, 64, 70, 79, 108, 167, 170, 195, 323, 335, 363, 379, 380, 385], 2: [15, 17, 32, 52, 64, 81, 112, 128, 137, 189, 211, 255, 274, 282, 286, 318, 337, 347, 358, 368], 99: [16, 60, 87, 116, 128, 142, 212, 248, 294, 317, 395, 398], 20: [17, 26, 36, 46, 142, 229, 245, 268, 270, 298], 67: [17, 41, 46, 50, 56, 70, 74, 104, 105, 114, 152, 188, 217, 266, 287, 318, 360], 25: [20, 58, 81, 141, 157, 189, 199, 228, 242, 332, 373], 35: [21, 33, 44, 127, 182, 254, 271, 289, 294, 302, 365, 392], 88: [22, 79, 149, 173, 176, 195, 237], 63: [22, 200, 216, 235, 264, 273, 292, 343], 40: [24, 25, 34, 44, 79, 92, 101, 107, 118, 163, 170, 180, 219, 238, 321, 338, 356, 386, 394], 72: [25, 56, 74, 98, 106, 108, 109, 133, 157, 174, 190, 201, 205, 209, 232, 234, 245, 246, 268, 281, 283, 344, 377, 399], 3: [25, 29, 50, 56, 98, 105, 111, 130, 155, 163, 167, 237, 249, 252, 261, 286, 364, 368, 392, 395], 81: [28, 35], 45: [33, 61, 74, 75, 85, 122, 139, 159, 164, 169, 177, 180, 203, 205, 207, 253, 285, 288, 292, 372], 0: [34, 78, 79, 122, 162, 190, 219, 235, 273, 283, 309, 350, 371, 378, 398], 46: [34, 51, 86, 87, 94, 142, 191, 290], 85: [35, 94, 210, 266, 312, 340], 42: [37, 38, 41, 44, 82, 86, 139, 161, 164, 207, 209, 213, 222, 229, 230, 250, 269, 349, 350, 370], 97: [37, 67, 145, 174, 276, 307, 321], 94: [39, 124, 202, 226, 343, 367], 8: [40, 50, 65, 87, 94, 135, 143, 148, 228, 260, 288, 291, 295, 310, 316, 335, 382, 389], 50: [43, 75, 77, 100, 219, 236, 351], 32: [44, 45, 57, 72, 113, 153, 154, 172, 183, 204, 217, 228, 246, 263, 296, 299, 314, 324, 333, 337], 92: [44, 58, 69, 84, 92, 93, 97, 100, 115, 133, 150, 186, 248, 257, 260, 313, 315, 347, 365, 371, 387, 390, 393], 58: [44, 121], 86: [44, 92, 106, 118, 136, 162, 206, 282, 303], 41: [45, 91, 110, 208, 221, 223, 241, 344, 348, 379, 381], 84: [48, 63, 67, 72, 90, 92, 146, 187, 310, 319, 379, 392], 62: [48, 63, 98, 138, 174, 178, 220, 225, 239, 248, 277, 288, 330, 388], 17: [50, 88, 109, 125, 130, 214, 216, 238, 384, 390, 394], 78: [52, 168, 187], 49: [53, 66, 73, 82, 87, 90, 97, 124, 127, 134, 137, 143, 185, 221, 230, 256, 262, 263, 275, 281, 293, 318, 332, 348], 5: [54, 57, 80, 81, 120, 121, 131, 151, 240, 261, 306, 320, 330, 333, 345, 355], 68: [55, 264], 11: [55, 94, 114, 151, 257, 301, 353, 376, 393], 90: [57, 64, 80, 102, 173, 179, 180, 247, 283, 285, 298, 303, 322, 323, 341], 27: [64, 65, 92, 153, 188, 202, 215, 243, 244, 258, 271, 323, 325], 52: [66, 87, 95, 171, 214, 231, 286, 300, 338, 342, 384, 387, 397, 398], 65: [68, 89, 96, 196, 204, 252, 369, 377], 14: [68, 78, 80, 85, 94, 212, 321, 351, 386], 87: [71], 15: [72, 101, 263, 273], 44: [73, 74, 77, 199, 212, 226, 266, 297, 301, 357], 83: [78], 38: [79, 111, 120, 152, 169, 224, 331, 346, 357, 361, 383, 385], 24: [84, 96, 109, 119, 130, 144, 146, 171, 182, 191, 240, 270, 274, 296, 396], 61: [86, 99, 132, 149, 156, 239, 275, 340, 343, 361, 367, 378, 397], 1: [88, 132, 168, 245, 291, 303], 56: [125, 171, 213, 232, 350], 19: [126, 222, 250, 301, 324], 60: [143, 164, 381], 76: [157, 217, 313], 73: [160, 198, 242, 341], 26: [300, 308, 356]}\n",
            "{0: 'N', 1: 'N', 2: 'P', 3: 'N', 4: 'N', 5: 'N', 6: 'N', 7: 'N', 8: 'N', 9: 'N', 10: 'N', 11: 'N', 12: 'N', 13: 'N', 14: 'N', 15: 'N', 16: 'P', 17: 'N', 18: 'N', 19: 'N', 20: 'P', 21: 'P', 22: 'P', 23: 'N', 24: 'N', 25: 'N', 26: 'N', 27: 'N', 28: 'N', 29: 'N', 30: 'N', 31: 'N', 32: 'N', 33: 'N', 34: 'N', 35: 'N', 36: 'N', 37: 'N', 38: 'P', 39: 'N', 40: 'N', 41: 'N', 42: 'P', 43: 'N', 44: 'N', 45: 'N', 46: 'N', 47: 'N', 48: 'N', 49: 'N', 50: 'N', 51: 'N', 52: 'N', 53: 'N', 54: 'N', 55: 'N', 56: 'N', 57: 'N', 58: 'P', 59: 'N', 60: 'N', 61: 'N', 62: 'N', 63: 'P', 64: 'P', 65: 'N', 66: 'N', 67: 'P', 68: 'N', 69: 'N', 70: 'N', 71: 'N', 72: 'N', 73: 'N', 74: 'N', 75: 'N', 76: 'N', 77: 'N', 78: 'N', 79: 'N', 80: 'N', 81: 'N', 82: 'N', 83: 'N', 84: 'N', 85: 'P', 86: 'N', 87: 'N', 88: 'N', 89: 'N', 90: 'N', 91: 'N', 92: 'P', 93: 'N', 94: 'N', 95: 'N', 96: 'N', 97: 'N', 98: 'N', 99: 'N', 100: 'N', 101: 'N', 102: 'P', 103: 'N', 104: 'N', 105: 'N', 106: 'N', 107: 'N', 108: 'N', 109: 'N', 110: 'N', 111: 'N', 112: 'N', 113: 'N', 114: 'N', 115: 'N', 116: 'N', 117: 'N', 118: 'N', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'N', 124: 'N', 125: 'N', 126: 'N', 127: 'P', 128: 'N', 129: 'N', 130: 'N', 131: 'N', 132: 'N', 133: 'N', 134: 'N', 135: 'P', 136: 'N', 137: 'N', 138: 'N', 139: 'N', 140: 'N', 141: 'N', 142: 'N', 143: 'N', 144: 'N', 145: 'N', 146: 'N', 147: 'N', 148: 'N', 149: 'N', 150: 'N', 151: 'N', 152: 'P', 153: 'N', 154: 'N', 155: 'N', 156: 'N', 157: 'N', 158: 'N', 159: 'N', 160: 'N', 161: 'N', 162: 'N', 163: 'N', 164: 'N', 165: 'N', 166: 'P', 167: 'N', 168: 'N', 169: 'N', 170: 'N', 171: 'N', 172: 'N', 173: 'N', 174: 'N', 175: 'N', 176: 'N', 177: 'N', 178: 'N', 179: 'N', 180: 'N', 181: 'N', 182: 'N', 183: 'N', 184: 'N', 185: 'N', 186: 'N', 187: 'N', 188: 'N', 189: 'N', 190: 'N', 191: 'N', 192: 'N', 193: 'N', 194: 'N', 195: 'N', 196: 'N', 197: 'P', 198: 'N', 199: 'N', 200: 'N', 201: 'N', 202: 'N', 203: 'N', 204: 'N', 205: 'N', 206: 'N', 207: 'N', 208: 'N', 209: 'N', 210: 'N', 211: 'N', 212: 'N', 213: 'N', 214: 'N', 215: 'N', 216: 'N', 217: 'N', 218: 'N', 219: 'N', 220: 'N', 221: 'P', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'N', 227: 'N', 228: 'N', 229: 'N', 230: 'N', 231: 'N', 232: 'N', 233: 'N', 234: 'N', 235: 'N', 236: 'N', 237: 'N', 238: 'N', 239: 'P', 240: 'N', 241: 'N', 242: 'N', 243: 'N', 244: 'N', 245: 'N', 246: 'N', 247: 'N', 248: 'N', 249: 'N', 250: 'N', 251: 'P', 252: 'N', 253: 'N', 254: 'N', 255: 'N', 256: 'N', 257: 'N', 258: 'N', 259: 'N', 260: 'N', 261: 'N', 262: 'N', 263: 'N', 264: 'N', 265: 'N', 266: 'N', 267: 'N', 268: 'N', 269: 'N', 270: 'N', 271: 'N', 272: 'N', 273: 'N', 274: 'N', 275: 'N', 276: 'N', 277: 'N', 278: 'P', 279: 'N', 280: 'N', 281: 'N', 282: 'N', 283: 'N', 284: 'N', 285: 'N', 286: 'N', 287: 'N', 288: 'P', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'N', 294: 'N', 295: 'N', 296: 'N', 297: 'N', 298: 'N', 299: 'N', 300: 'N', 301: 'N', 302: 'N', 303: 'N', 304: 'P', 305: 'N', 306: 'N', 307: 'N', 308: 'N', 309: 'N', 310: 'N', 311: 'N', 312: 'N', 313: 'N', 314: 'P', 315: 'N', 316: 'P', 317: 'N', 318: 'N', 319: 'N', 320: 'N', 321: 'N', 322: 'N', 323: 'N', 324: 'N', 325: 'P', 326: 'N', 327: 'N', 328: 'N', 329: 'N', 330: 'N', 331: 'N', 332: 'N', 333: 'N', 334: 'N', 335: 'N', 336: 'N', 337: 'N', 338: 'N', 339: 'N', 340: 'P', 341: 'N', 342: 'N', 343: 'N', 344: 'N', 345: 'N', 346: 'N', 347: 'N', 348: 'N', 349: 'N', 350: 'N', 351: 'N', 352: 'N', 353: 'N', 354: 'N', 355: 'N', 356: 'N', 357: 'N', 358: 'P', 359: 'P', 360: 'N', 361: 'P', 362: 'N', 363: 'P', 364: 'N', 365: 'N', 366: 'N', 367: 'N', 368: 'N', 369: 'N', 370: 'N', 371: 'P', 372: 'N', 373: 'N', 374: 'P', 375: 'N', 376: 'N', 377: 'N', 378: 'N', 379: 'N', 380: 'P', 381: 'P', 382: 'N', 383: 'N', 384: 'N', 385: 'N', 386: 'N', 387: 'N', 388: 'P', 389: 'N', 390: 'P', 391: 'N', 392: 'N', 393: 'N', 394: 'N', 395: 'N', 396: 'N', 397: 'N', 398: 'P', 399: 'N'}\n",
            "Degree Sequence:  [6, 3, 3, 3, 5, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 4, 3, 6, 3, 3, 4, 3, 4, 4, 4, 3, 5, 4, 3, 5, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 3, 4, 4, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lam = 0.1\n",
        "alp = 1\n",
        "zeta_1 = 0.1\n",
        "zeta_2 = 0.05\n",
        "zeta_3 = 0.1\n",
        "zeta_4 = 0.05\n",
        "beta_PP = 0.025\n",
        "beta_NN = 0.5\n",
        "mu = 1\n",
        "n_sample = 20\n",
        "\n",
        "# Set the SN-IP and SP-IN disease spreading rates\n",
        "beta_NP_values = np.arange(0.05, 0.3, 0.05)\n",
        "beta_PN_values = np.arange(0.3, 0.5, 0.05)\n",
        "\n",
        "# Initialize the result array\n",
        "results_rho_C = np.zeros((len(beta_NP_values), len(beta_PN_values)))\n",
        "results_rho_P = np.zeros((len(beta_NP_values), len(beta_PN_values)))\n",
        "results_rho_R = np.zeros((len(beta_NP_values), len(beta_PN_values)))\n",
        "\n",
        "# Iterate over mu and lambda values\n",
        "for i, beta_NP in enumerate(beta_NP_values):\n",
        "  for j, beta_PN in enumerate(beta_PN_values):\n",
        "        avg_rho_C, avg_rho_P, avg_rho_R = ICE_model(inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample)\n",
        "        results_rho_C[i, j] = avg_rho_C\n",
        "        results_rho_P[i, j] = avg_rho_P\n",
        "        results_rho_R[i, j] = avg_rho_R\n",
        "        print(\"beta_NP:\", beta_NP,\"beta_PN:\", beta_PN, \"rho_C:\", avg_rho_C, \"rho_P:\", avg_rho_P, \"rho_R:\", avg_rho_R)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yC-RA0-ELqY",
        "outputId": "295daff5-a2d6-455a-d625-58b06c849cbd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corrected_frac 0.9775 recovered_frac 0.0025\n",
            "corrected_frac 0.9925 recovered_frac 0.8675\n",
            "corrected_frac 0.015 recovered_frac 0.005\n",
            "corrected_frac 0.01 recovered_frac 0.9275\n",
            "corrected_frac 0.005 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.955\n",
            "corrected_frac 0.0375 recovered_frac 0.935\n",
            "corrected_frac 0.99 recovered_frac 0.94\n",
            "corrected_frac 0.98 recovered_frac 0.635\n",
            "corrected_frac 0.9575 recovered_frac 0.005\n",
            "corrected_frac 0.95 recovered_frac 0.8625\n",
            "corrected_frac 0.0325 recovered_frac 0.91\n",
            "corrected_frac 0.02 recovered_frac 0.0025\n",
            "corrected_frac 0.985 recovered_frac 0.5975\n",
            "corrected_frac 0.99 recovered_frac 0.0075\n",
            "corrected_frac 1.0 recovered_frac 0.0025\n",
            "corrected_frac 0.99 recovered_frac 0.0025\n",
            "corrected_frac 0.9925 recovered_frac 0.9575\n",
            "corrected_frac 0.9925 recovered_frac 0.8625\n",
            "beta_NP: 0.05 beta_PN: 0.3 rho_C: 0.6797368421052631 rho_P: 0.00039473684210526315 rho_R: 0.49894736842105275\n",
            "corrected_frac 0.9975 recovered_frac 0.795\n",
            "corrected_frac 0.905 recovered_frac 0.0025\n",
            "corrected_frac 0.9925 recovered_frac 0.925\n",
            "corrected_frac 0.0125 recovered_frac 0.0025\n",
            "corrected_frac 0.9875 recovered_frac 0.95\n",
            "corrected_frac 0.9875 recovered_frac 0.965\n",
            "corrected_frac 0.0775 recovered_frac 0.9625\n",
            "corrected_frac 0.9925 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.795\n",
            "corrected_frac 0.0725 recovered_frac 0.0025\n",
            "corrected_frac 0.9925 recovered_frac 0.92\n",
            "corrected_frac 0.975 recovered_frac 0.9275\n",
            "corrected_frac 0.0425 recovered_frac 0.88\n",
            "corrected_frac 0.0475 recovered_frac 0.005\n",
            "corrected_frac 0.9875 recovered_frac 0.0025\n",
            "corrected_frac 0.1375 recovered_frac 0.895\n",
            "corrected_frac 0.97 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.8875\n",
            "beta_NP: 0.05 beta_PN: 0.35 rho_C: 0.67625 rho_P: 0.0002777777777777778 rho_R: 0.55125\n",
            "corrected_frac 0.0075 recovered_frac 0.79\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.0325 recovered_frac 0.8675\n",
            "corrected_frac 0.995 recovered_frac 0.005\n",
            "corrected_frac 0.02 recovered_frac 0.815\n",
            "corrected_frac 0.9725 recovered_frac 0.8875\n",
            "corrected_frac 0.99 recovered_frac 0.0025\n",
            "corrected_frac 0.995 recovered_frac 0.0025\n",
            "corrected_frac 0.97 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.865\n",
            "corrected_frac 0.985 recovered_frac 0.0025\n",
            "corrected_frac 0.8975 recovered_frac 0.885\n",
            "corrected_frac 0.0925 recovered_frac 0.025\n",
            "corrected_frac 0.0375 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.01\n",
            "corrected_frac 0.965 recovered_frac 0.01\n",
            "corrected_frac 0.99 recovered_frac 0.9225\n",
            "corrected_frac 0.0075 recovered_frac 0.0025\n",
            "corrected_frac 0.98 recovered_frac 0.005\n",
            "corrected_frac 0.9825 recovered_frac 0.0025\n",
            "beta_NP: 0.05 beta_PN: 0.39999999999999997 rho_C: 0.695625 rho_P: 0.0005 rho_R: 0.30537500000000006\n",
            "corrected_frac 0.99 recovered_frac 0.855\n",
            "corrected_frac 0.9375 recovered_frac 0.82\n",
            "corrected_frac 0.005 recovered_frac 0.02\n",
            "corrected_frac 0.795 recovered_frac 0.8175\n",
            "corrected_frac 0.985 recovered_frac 0.895\n",
            "corrected_frac 0.005 recovered_frac 0.8825\n",
            "corrected_frac 0.9775 recovered_frac 0.84\n",
            "corrected_frac 0.915 recovered_frac 0.01\n",
            "corrected_frac 0.9925 recovered_frac 0.9375\n",
            "corrected_frac 0.9975 recovered_frac 0.0075\n",
            "corrected_frac 0.995 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.9325\n",
            "corrected_frac 0.01 recovered_frac 0.855\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.9925 recovered_frac 0.0525\n",
            "corrected_frac 0.985 recovered_frac 0.855\n",
            "corrected_frac 0.9725 recovered_frac 0.0025\n",
            "corrected_frac 0.9925 recovered_frac 0.9\n",
            "corrected_frac 0.995 recovered_frac 0.9025\n",
            "corrected_frac 0.03 recovered_frac 0.0025\n",
            "beta_NP: 0.05 beta_PN: 0.44999999999999996 rho_C: 0.7783749999999998 rho_P: 0.0005 rho_R: 0.529625\n",
            "corrected_frac 0.95 recovered_frac 0.015\n",
            "corrected_frac 0.025 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.6875\n",
            "corrected_frac 0.145 recovered_frac 0.0025\n",
            "corrected_frac 0.96 recovered_frac 0.865\n",
            "corrected_frac 1.0 recovered_frac 0.8925\n",
            "corrected_frac 0.965 recovered_frac 0.87\n",
            "corrected_frac 0.9925 recovered_frac 0.9025\n",
            "corrected_frac 0.0475 recovered_frac 0.83\n",
            "corrected_frac 0.99 recovered_frac 0.905\n",
            "corrected_frac 0.99 recovered_frac 0.8975\n",
            "corrected_frac 0.035 recovered_frac 0.0025\n",
            "corrected_frac 1.0 recovered_frac 0.895\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.9475 recovered_frac 0.0125\n",
            "corrected_frac 0.03 recovered_frac 0.9075\n",
            "corrected_frac 0.025 recovered_frac 0.025\n",
            "corrected_frac 0.0375 recovered_frac 0.9\n",
            "corrected_frac 0.9825 recovered_frac 0.0025\n",
            "corrected_frac 0.99 recovered_frac 0.87\n",
            "beta_NP: 0.1 beta_PN: 0.3 rho_C: 0.655375 rho_P: 0.001875 rho_R: 0.524375\n",
            "corrected_frac 0.99 recovered_frac 0.8825\n",
            "corrected_frac 0.9675 recovered_frac 0.8875\n",
            "corrected_frac 0.095 recovered_frac 0.945\n",
            "corrected_frac 0.9925 recovered_frac 0.0075\n",
            "corrected_frac 0.1125 recovered_frac 0.0025\n",
            "corrected_frac 0.97 recovered_frac 0.915\n",
            "corrected_frac 0.0475 recovered_frac 0.0425\n",
            "corrected_frac 0.9825 recovered_frac 0.0025\n",
            "corrected_frac 0.9775 recovered_frac 0.8325\n",
            "corrected_frac 0.99 recovered_frac 0.955\n",
            "corrected_frac 0.9725 recovered_frac 0.8925\n",
            "corrected_frac 0.995 recovered_frac 0.0025\n",
            "corrected_frac 0.99 recovered_frac 0.9125\n",
            "corrected_frac 1.0 recovered_frac 0.8225\n",
            "corrected_frac 0.0575 recovered_frac 0.0025\n",
            "corrected_frac 0.0275 recovered_frac 0.0025\n",
            "corrected_frac 0.9825 recovered_frac 0.0025\n",
            "corrected_frac 0.0425 recovered_frac 0.0025\n",
            "corrected_frac 0.0375 recovered_frac 0.0375\n",
            "corrected_frac 0.9975 recovered_frac 0.005\n",
            "beta_NP: 0.1 beta_PN: 0.35 rho_C: 0.6613749999999999 rho_P: 0.001375 rho_R: 0.40774999999999995\n",
            "corrected_frac 0.9675 recovered_frac 0.93\n",
            "corrected_frac 0.045 recovered_frac 0.925\n",
            "corrected_frac 0.935 recovered_frac 0.0025\n",
            "corrected_frac 0.985 recovered_frac 0.885\n",
            "corrected_frac 0.9975 recovered_frac 0.8875\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.035 recovered_frac 0.965\n",
            "corrected_frac 0.0925 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.92\n",
            "corrected_frac 0.985 recovered_frac 0.0075\n",
            "corrected_frac 0.995 recovered_frac 0.855\n",
            "corrected_frac 0.9975 recovered_frac 0.915\n",
            "corrected_frac 0.985 recovered_frac 0.8075\n",
            "corrected_frac 0.9775 recovered_frac 0.005\n",
            "corrected_frac 0.9825 recovered_frac 0.005\n",
            "corrected_frac 0.9775 recovered_frac 0.8475\n",
            "corrected_frac 0.9775 recovered_frac 0.0025\n",
            "corrected_frac 0.9175 recovered_frac 0.0025\n",
            "corrected_frac 0.0125 recovered_frac 0.9325\n",
            "corrected_frac 0.995 recovered_frac 0.8825\n",
            "beta_NP: 0.1 beta_PN: 0.39999999999999997 rho_C: 0.79275 rho_P: 0.001 rho_R: 0.5391250000000001\n",
            "corrected_frac 0.965 recovered_frac 0.975\n",
            "corrected_frac 0.0375 recovered_frac 0.0025\n",
            "corrected_frac 0.01 recovered_frac 0.005\n",
            "corrected_frac 0.9975 recovered_frac 0.9275\n",
            "corrected_frac 0.975 recovered_frac 0.86\n",
            "corrected_frac 0.9775 recovered_frac 0.9375\n",
            "corrected_frac 0.99 recovered_frac 0.835\n",
            "corrected_frac 0.0225 recovered_frac 0.0025\n",
            "corrected_frac 0.9925 recovered_frac 0.0025\n",
            "corrected_frac 0.95 recovered_frac 0.925\n",
            "corrected_frac 0.995 recovered_frac 0.025\n",
            "corrected_frac 0.965 recovered_frac 0.9125\n",
            "corrected_frac 0.9975 recovered_frac 0.945\n",
            "corrected_frac 0.02 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.88\n",
            "corrected_frac 0.99 recovered_frac 0.9225\n",
            "corrected_frac 0.015 recovered_frac 0.0025\n",
            "corrected_frac 0.9875 recovered_frac 0.9125\n",
            "corrected_frac 0.985 recovered_frac 0.0025\n",
            "beta_NP: 0.1 beta_PN: 0.44999999999999996 rho_C: 0.7300000000000001 rho_P: 0.0011842105263157893 rho_R: 0.5303947368421053\n",
            "corrected_frac 0.9525 recovered_frac 0.0025\n",
            "corrected_frac 0.9425 recovered_frac 0.8975\n",
            "corrected_frac 0.98 recovered_frac 0.905\n",
            "corrected_frac 0.9925 recovered_frac 0.82\n",
            "corrected_frac 0.9875 recovered_frac 0.8525\n",
            "corrected_frac 0.9925 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.0225 recovered_frac 0.0025\n",
            "corrected_frac 0.0275 recovered_frac 0.925\n",
            "corrected_frac 0.1425 recovered_frac 0.9475\n",
            "corrected_frac 0.0175 recovered_frac 0.9425\n",
            "corrected_frac 0.055 recovered_frac 0.8525\n",
            "corrected_frac 0.98 recovered_frac 0.0025\n",
            "corrected_frac 0.99 recovered_frac 0.005\n",
            "corrected_frac 0.9975 recovered_frac 0.06\n",
            "corrected_frac 0.9875 recovered_frac 0.015\n",
            "corrected_frac 0.9875 recovered_frac 0.915\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "beta_NP: 0.15000000000000002 beta_PN: 0.3 rho_C: 0.7250000000000001 rho_P: 0.0011111111111111111 rho_R: 0.4529166666666666\n",
            "corrected_frac 1.0 recovered_frac 0.0025\n",
            "corrected_frac 0.975 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.995 recovered_frac 0.005\n",
            "corrected_frac 0.985 recovered_frac 0.0025\n",
            "corrected_frac 0.985 recovered_frac 0.7525\n",
            "corrected_frac 0.9875 recovered_frac 0.005\n",
            "corrected_frac 0.9825 recovered_frac 0.875\n",
            "corrected_frac 0.98 recovered_frac 0.0025\n",
            "corrected_frac 0.965 recovered_frac 0.01\n",
            "corrected_frac 0.0125 recovered_frac 0.0025\n",
            "corrected_frac 0.075 recovered_frac 0.0025\n",
            "corrected_frac 0.9925 recovered_frac 0.0025\n",
            "corrected_frac 0.03 recovered_frac 0.02\n",
            "corrected_frac 0.0175 recovered_frac 0.0025\n",
            "corrected_frac 1.0 recovered_frac 0.005\n",
            "corrected_frac 0.0125 recovered_frac 0.0025\n",
            "corrected_frac 0.0175 recovered_frac 0.96\n",
            "corrected_frac 0.995 recovered_frac 0.88\n",
            "beta_NP: 0.15000000000000002 beta_PN: 0.35 rho_C: 0.7001249999999999 rho_P: 0.001375 rho_R: 0.17699999999999996\n",
            "corrected_frac 0.9275 recovered_frac 0.9425\n",
            "corrected_frac 0.0425 recovered_frac 0.9075\n",
            "corrected_frac 0.99 recovered_frac 0.8175\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.975 recovered_frac 0.935\n",
            "corrected_frac 0.99 recovered_frac 0.8275\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.995 recovered_frac 0.0025\n",
            "corrected_frac 0.895 recovered_frac 0.9125\n",
            "corrected_frac 0.03 recovered_frac 0.805\n",
            "corrected_frac 0.045 recovered_frac 0.0025\n",
            "corrected_frac 0.985 recovered_frac 0.0025\n",
            "corrected_frac 0.99 recovered_frac 0.98\n",
            "corrected_frac 0.955 recovered_frac 0.8725\n",
            "corrected_frac 0.9875 recovered_frac 0.945\n",
            "corrected_frac 0.99 recovered_frac 0.0025\n",
            "corrected_frac 0.995 recovered_frac 0.8325\n",
            "corrected_frac 0.02 recovered_frac 0.905\n",
            "corrected_frac 0.035 recovered_frac 0.0025\n",
            "beta_NP: 0.15000000000000002 beta_PN: 0.39999999999999997 rho_C: 0.7285526315789475 rho_P: 0.0010526315789473684 rho_R: 0.5631578947368421\n",
            "corrected_frac 0.9925 recovered_frac 0.84\n",
            "corrected_frac 1.0 recovered_frac 0.915\n",
            "corrected_frac 0.985 recovered_frac 0.855\n",
            "corrected_frac 0.01 recovered_frac 0.91\n",
            "corrected_frac 0.99 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.895\n",
            "corrected_frac 0.96 recovered_frac 0.92\n",
            "corrected_frac 0.995 recovered_frac 0.005\n",
            "corrected_frac 0.9775 recovered_frac 0.8975\n",
            "corrected_frac 0.995 recovered_frac 0.915\n",
            "corrected_frac 0.5775 recovered_frac 0.87\n",
            "corrected_frac 0.9875 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.01\n",
            "corrected_frac 0.9875 recovered_frac 0.9075\n",
            "corrected_frac 0.72 recovered_frac 0.01\n",
            "corrected_frac 0.9775 recovered_frac 0.785\n",
            "corrected_frac 0.98 recovered_frac 0.0175\n",
            "corrected_frac 0.015 recovered_frac 0.0025\n",
            "beta_NP: 0.15000000000000002 beta_PN: 0.44999999999999996 rho_C: 0.8413888888888891 rho_P: 0.00125 rho_R: 0.5422222222222222\n",
            "corrected_frac 0.96 recovered_frac 0.8325\n",
            "corrected_frac 0.035 recovered_frac 0.0075\n",
            "corrected_frac 0.01 recovered_frac 0.0025\n",
            "corrected_frac 0.9825 recovered_frac 0.9175\n",
            "corrected_frac 0.075 recovered_frac 0.9225\n",
            "corrected_frac 0.9875 recovered_frac 0.985\n",
            "corrected_frac 0.965 recovered_frac 0.9475\n",
            "corrected_frac 0.97 recovered_frac 0.02\n",
            "corrected_frac 0.995 recovered_frac 0.9125\n",
            "corrected_frac 0.015 recovered_frac 0.0025\n",
            "corrected_frac 0.995 recovered_frac 0.8525\n",
            "corrected_frac 0.04 recovered_frac 0.87\n",
            "corrected_frac 0.9875 recovered_frac 0.0075\n",
            "corrected_frac 0.0725 recovered_frac 0.0025\n",
            "corrected_frac 0.9925 recovered_frac 0.0025\n",
            "corrected_frac 1.0 recovered_frac 0.0025\n",
            "corrected_frac 0.045 recovered_frac 0.0025\n",
            "corrected_frac 0.08 recovered_frac 0.9\n",
            "corrected_frac 0.0125 recovered_frac 0.945\n",
            "corrected_frac 0.0725 recovered_frac 0.8375\n",
            "beta_NP: 0.2 beta_PN: 0.3 rho_C: 0.5146249999999999 rho_P: 0.00075 rho_R: 0.4986250000000001\n",
            "corrected_frac 0.9925 recovered_frac 0.935\n",
            "corrected_frac 0.075 recovered_frac 0.9075\n",
            "corrected_frac 0.98 recovered_frac 0.005\n",
            "corrected_frac 0.985 recovered_frac 0.8775\n",
            "corrected_frac 0.9825 recovered_frac 0.885\n",
            "corrected_frac 1.0 recovered_frac 0.035\n",
            "corrected_frac 0.105 recovered_frac 0.0025\n",
            "corrected_frac 0.9975 recovered_frac 0.015\n",
            "corrected_frac 0.005 recovered_frac 0.795\n",
            "corrected_frac 0.97 recovered_frac 0.0025\n",
            "corrected_frac 0.99 recovered_frac 0.9175\n",
            "corrected_frac 0.035 recovered_frac 0.81\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.0225 recovered_frac 0.0025\n",
            "corrected_frac 0.975 recovered_frac 0.8675\n",
            "corrected_frac 0.9925 recovered_frac 0.02\n",
            "corrected_frac 0.985 recovered_frac 0.89\n",
            "corrected_frac 0.025 recovered_frac 0.0025\n",
            "beta_NP: 0.2 beta_PN: 0.35 rho_C: 0.6730555555555556 rho_P: 0.0008333333333333334 rho_R: 0.4429166666666667\n",
            "corrected_frac 0.995 recovered_frac 0.0025\n",
            "corrected_frac 0.965 recovered_frac 0.0025\n",
            "corrected_frac 0.0225 recovered_frac 0.005\n",
            "corrected_frac 0.9825 recovered_frac 0.905\n",
            "corrected_frac 0.995 recovered_frac 0.0125\n",
            "corrected_frac 0.9375 recovered_frac 0.9375\n",
            "corrected_frac 0.975 recovered_frac 0.875\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.985 recovered_frac 0.9275\n",
            "corrected_frac 0.995 recovered_frac 0.8375\n",
            "corrected_frac 0.97 recovered_frac 0.8375\n",
            "corrected_frac 0.0625 recovered_frac 0.8525\n",
            "corrected_frac 0.995 recovered_frac 0.005\n",
            "corrected_frac 0.9925 recovered_frac 0.88\n",
            "corrected_frac 0.9975 recovered_frac 0.02\n",
            "corrected_frac 0.99 recovered_frac 0.895\n",
            "corrected_frac 0.99 recovered_frac 0.88\n",
            "corrected_frac 0.99 recovered_frac 0.8425\n",
            "beta_NP: 0.2 beta_PN: 0.39999999999999997 rho_C: 0.8798611111111111 rho_P: 0.00041666666666666664 rho_R: 0.54\n",
            "corrected_frac 0.99 recovered_frac 0.8525\n",
            "corrected_frac 0.975 recovered_frac 0.0025\n",
            "corrected_frac 0.02 recovered_frac 0.965\n",
            "corrected_frac 0.995 recovered_frac 0.9475\n",
            "corrected_frac 0.9775 recovered_frac 0.965\n",
            "corrected_frac 0.9675 recovered_frac 0.67\n",
            "corrected_frac 1.0 recovered_frac 0.0025\n",
            "corrected_frac 0.9825 recovered_frac 0.0025\n",
            "corrected_frac 0.97 recovered_frac 0.915\n",
            "corrected_frac 0.965 recovered_frac 0.0025\n",
            "corrected_frac 0.9825 recovered_frac 0.005\n",
            "corrected_frac 0.9825 recovered_frac 0.905\n",
            "corrected_frac 0.9875 recovered_frac 0.925\n",
            "corrected_frac 0.99 recovered_frac 0.0025\n",
            "corrected_frac 0.9825 recovered_frac 0.9125\n",
            "corrected_frac 0.9675 recovered_frac 0.0025\n",
            "corrected_frac 0.9775 recovered_frac 0.0025\n",
            "corrected_frac 0.99 recovered_frac 0.9225\n",
            "corrected_frac 0.065 recovered_frac 0.9125\n",
            "beta_NP: 0.2 beta_PN: 0.44999999999999996 rho_C: 0.8825 rho_P: 0.0015789473684210526 rho_R: 0.5218421052631579\n",
            "corrected_frac 0.9975 recovered_frac 0.9375\n",
            "corrected_frac 0.99 recovered_frac 0.9525\n",
            "corrected_frac 0.8875 recovered_frac 0.8275\n",
            "corrected_frac 0.9925 recovered_frac 0.0025\n",
            "corrected_frac 0.9925 recovered_frac 0.8375\n",
            "corrected_frac 0.035 recovered_frac 0.9175\n",
            "corrected_frac 0.9975 recovered_frac 0.0025\n",
            "corrected_frac 0.995 recovered_frac 0.9525\n",
            "corrected_frac 0.99 recovered_frac 0.8325\n",
            "corrected_frac 0.9975 recovered_frac 0.01\n",
            "corrected_frac 0.9875 recovered_frac 0.0025\n",
            "corrected_frac 0.96 recovered_frac 0.0025\n",
            "corrected_frac 0.0125 recovered_frac 0.005\n",
            "corrected_frac 0.9875 recovered_frac 0.0025\n",
            "corrected_frac 1.0 recovered_frac 0.0075\n",
            "corrected_frac 1.0 recovered_frac 0.8175\n",
            "corrected_frac 0.9925 recovered_frac 0.875\n",
            "beta_NP: 0.25 beta_PN: 0.3 rho_C: 0.8714705882352942 rho_P: 0.0010294117647058822 rho_R: 0.4697058823529412\n",
            "corrected_frac 1.0 recovered_frac 0.895\n",
            "corrected_frac 0.01 recovered_frac 0.935\n",
            "corrected_frac 0.995 recovered_frac 0.015\n",
            "corrected_frac 0.99 recovered_frac 0.8575\n",
            "corrected_frac 0.995 recovered_frac 0.755\n",
            "corrected_frac 0.01 recovered_frac 0.8775\n",
            "corrected_frac 0.98 recovered_frac 0.025\n",
            "corrected_frac 0.9725 recovered_frac 0.005\n",
            "corrected_frac 0.015 recovered_frac 0.8475\n",
            "corrected_frac 0.055 recovered_frac 0.9375\n",
            "corrected_frac 0.05 recovered_frac 0.9375\n",
            "corrected_frac 0.055 recovered_frac 0.9475\n",
            "corrected_frac 0.9875 recovered_frac 0.975\n",
            "corrected_frac 0.1125 recovered_frac 0.01\n",
            "corrected_frac 0.995 recovered_frac 0.02\n",
            "corrected_frac 0.9975 recovered_frac 0.1575\n",
            "corrected_frac 0.98 recovered_frac 0.9475\n",
            "corrected_frac 0.9825 recovered_frac 0.86\n",
            "corrected_frac 0.9675 recovered_frac 0.0025\n",
            "beta_NP: 0.25 beta_PN: 0.35 rho_C: 0.6394736842105262 rho_P: 0.0011842105263157896 rho_R: 0.5793421052631578\n",
            "corrected_frac 0.01 recovered_frac 0.0025\n",
            "corrected_frac 0.99 recovered_frac 0.9075\n",
            "corrected_frac 0.9775 recovered_frac 0.0025\n",
            "corrected_frac 0.98 recovered_frac 0.0025\n",
            "corrected_frac 1.0 recovered_frac 0.92\n",
            "corrected_frac 0.9875 recovered_frac 0.0025\n",
            "corrected_frac 0.995 recovered_frac 0.935\n",
            "corrected_frac 0.99 recovered_frac 0.905\n",
            "corrected_frac 0.0275 recovered_frac 0.8625\n",
            "corrected_frac 0.9975 recovered_frac 0.925\n",
            "corrected_frac 0.9875 recovered_frac 0.915\n",
            "corrected_frac 0.9775 recovered_frac 0.9425\n",
            "corrected_frac 0.9975 recovered_frac 0.7875\n",
            "corrected_frac 0.995 recovered_frac 0.9\n",
            "corrected_frac 0.995 recovered_frac 0.92\n",
            "corrected_frac 0.9575 recovered_frac 0.0025\n",
            "corrected_frac 0.03 recovered_frac 0.735\n",
            "corrected_frac 0.98 recovered_frac 0.01\n",
            "corrected_frac 1.0 recovered_frac 0.0025\n",
            "beta_NP: 0.25 beta_PN: 0.39999999999999997 rho_C: 0.8355263157894737 rho_P: 0.0009210526315789475 rho_R: 0.5621052631578947\n",
            "corrected_frac 0.995 recovered_frac 0.8625\n",
            "corrected_frac 0.0325 recovered_frac 0.0025\n",
            "corrected_frac 0.985 recovered_frac 0.9325\n",
            "corrected_frac 0.9975 recovered_frac 0.8975\n",
            "corrected_frac 0.005 recovered_frac 0.8275\n",
            "corrected_frac 0.995 recovered_frac 0.9025\n",
            "corrected_frac 0.9925 recovered_frac 0.9725\n",
            "corrected_frac 0.0125 recovered_frac 0.0025\n",
            "corrected_frac 0.98 recovered_frac 0.0025\n",
            "corrected_frac 0.895 recovered_frac 0.0025\n",
            "corrected_frac 0.03 recovered_frac 0.8025\n",
            "corrected_frac 0.9675 recovered_frac 0.01\n",
            "corrected_frac 0.9875 recovered_frac 0.8325\n",
            "corrected_frac 0.98 recovered_frac 0.0025\n",
            "corrected_frac 1.0 recovered_frac 0.895\n",
            "corrected_frac 0.01 recovered_frac 0.8775\n",
            "corrected_frac 0.9775 recovered_frac 0.9575\n",
            "corrected_frac 0.01 recovered_frac 0.065\n",
            "corrected_frac 0.9825 recovered_frac 0.9375\n",
            "corrected_frac 0.99 recovered_frac 0.8825\n",
            "beta_NP: 0.25 beta_PN: 0.44999999999999996 rho_C: 0.69125 rho_P: 0.00075 rho_R: 0.583375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the heat map\n",
        "fig, ax = plt.subplots(figsize=(4, 3))\n",
        "heatmap = ax.imshow(results_rho_R, cmap='hot', interpolation='nearest')\n",
        "\n",
        "# Set the tick labels and show colorbar\n",
        "ax.set_xticks(np.arange(len(beta_PN_values)))\n",
        "ax.set_yticks(np.arange(len(beta_NP_values)))\n",
        "\n",
        "# Format the tick labels with two decimal places using string formatting\n",
        "beta_NP_formatter = ticker.StrMethodFormatter('{:.2f}'.format)\n",
        "beta_PN_formatter = ticker.StrMethodFormatter('{:.2f}'.format)\n",
        "ax.xaxis.set_major_formatter(beta_PN_formatter)\n",
        "ax.yaxis.set_major_formatter(beta_NP_formatter)\n",
        "ax.invert_yaxis()\n",
        "\n",
        "ax.set_xticklabels(['{:.2f}'.format(val) for val in beta_PN_values])\n",
        "ax.set_yticklabels(['{:.2f}'.format(val) for val in beta_NP_values])\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.colorbar(heatmap)\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel(r'$\\beta_{PN}$')\n",
        "ax.set_ylabel(r'$\\beta_{NP}$')\n",
        "ax.set_title('Average Recovered Density Heatmap')\n",
        "\n",
        "# Display the heat map\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "aWci2QNgOefS",
        "outputId": "f171deeb-bf79-4812-fb4d-4c1312d4a07c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lam = 0.2\n",
        "alp = 1\n",
        "zeta_1 = 0.1\n",
        "zeta_2 = 0.05\n",
        "zeta_3 = 0.1\n",
        "zeta_4 = 0.05\n",
        "beta_PP = 0.025\n",
        "beta_NN = 0.5\n",
        "mu = 1\n",
        "n_sample = 30\n",
        "\n",
        "# Set the SN-IP and SP-IN disease spreading rates\n",
        "beta_NP_values = np.arange(0.05, 0.3, 0.05)\n",
        "beta_PN_values = np.arange(0.3, 0.5, 0.05)\n",
        "\n",
        "# Initialize the result array\n",
        "results_rho_C = np.zeros((len(beta_NP_values), len(beta_PN_values)))\n",
        "results_rho_P = np.zeros((len(beta_NP_values), len(beta_PN_values)))\n",
        "results_rho_R = np.zeros((len(beta_NP_values), len(beta_PN_values)))\n",
        "\n",
        "# Iterate over mu and lambda values\n",
        "for i, beta_NP in enumerate(beta_NP_values):\n",
        "  for j, beta_PN in enumerate(beta_PN_values):\n",
        "        avg_rho_C, avg_rho_P, avg_rho_R = ICE_model(inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample)\n",
        "        results_rho_C[i, j] = avg_rho_C\n",
        "        results_rho_P[i, j] = avg_rho_P\n",
        "        results_rho_R[i, j] = avg_rho_R\n",
        "        print(\"beta_NP:\", beta_NP,\"beta_PN:\", beta_PN, \"rho_C:\", avg_rho_C, \"rho_P:\", avg_rho_P, \"rho_R:\", avg_rho_R)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlDmWiHrbmoJ",
        "outputId": "cb6f88d9-560d-4682-c28a-0528d3514a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corrected_frac 1.0 recovered_frac 0.9425\n",
            "corrected_frac 1.0 recovered_frac 0.79\n",
            "corrected_frac 0.9975 recovered_frac 0.865\n",
            "corrected_frac 1.0 recovered_frac 0.9125\n",
            "corrected_frac 1.0 recovered_frac 0.8575\n",
            "corrected_frac 0.995 recovered_frac 0.9375\n",
            "corrected_frac 1.0 recovered_frac 0.9225\n",
            "corrected_frac 1.0 recovered_frac 0.0025\n",
            "corrected_frac 1.0 recovered_frac 0.85\n",
            "corrected_frac 1.0 recovered_frac 0.91\n",
            "corrected_frac 1.0 recovered_frac 0.0025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the heat map\n",
        "fig, ax = plt.subplots(figsize=(4,3))\n",
        "heatmap = ax.imshow(results_rho_R, cmap='hot', interpolation='nearest')\n",
        "\n",
        "# Set the tick labels and show colorbar\n",
        "ax.set_xticks(np.arange(len(beta_PN_values)))\n",
        "ax.set_yticks(np.arange(len(beta_NP_values)))\n",
        "\n",
        "# Format the tick labels with two decimal places using string formatting\n",
        "beta_NP_formatter = ticker.StrMethodFormatter('{:.2f}'.format)\n",
        "beta_PN_formatter = ticker.StrMethodFormatter('{:.2f}'.format)\n",
        "ax.xaxis.set_major_formatter(beta_PN_formatter)\n",
        "ax.yaxis.set_major_formatter(beta_NP_formatter)\n",
        "ax.invert_yaxis()\n",
        "\n",
        "ax.set_xticklabels(['{:.2f}'.format(val) for val in beta_PN_values])\n",
        "ax.set_yticklabels(['{:.2f}'.format(val) for val in beta_NP_values])\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.colorbar(heatmap)\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel(r'$\\beta_{PN}$')\n",
        "ax.set_ylabel(r'$\\beta_{NP}$')\n",
        "ax.set_title('Average Recovered Density Heatmap')\n",
        "\n",
        "# Display the heat map\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GSexMsR6cEKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alp = 1\n",
        "zeta_1 = 0.05\n",
        "zeta_3 = 0.05\n",
        "zeta_4 = 0.05\n",
        "beta_PP = 0.025\n",
        "beta_NP = 0.05\n",
        "beta_PN = 0.2\n",
        "beta_NN = 0.4\n",
        "mu = 1\n",
        "n_sample = 100\n",
        "\n",
        "# Set the SN-IP and SP-IN disease spreading rates\n",
        "lam_values = np.arange(0.1, 0.4, 0.1)\n",
        "zeta_2_values = np.arange(0.05, 0.25, 0.05)\n",
        "\n",
        "# Initialize the result array\n",
        "results_rho_C = np.zeros((len(lam_values), len(zeta_2_values)))\n",
        "results_rho_R = np.zeros((len(lam_values), len(zeta_2_values)))\n",
        "\n",
        "# Iterate over mu and lambda values\n",
        "for i, lam in enumerate(lam_values):\n",
        "    for j, zeta_2 in enumerate(zeta_2_values):\n",
        "        avg_rho_C, avg_rho_P, avg_rho_R = ICE_model(inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample)\n",
        "        results_rho_C[i, j] = avg_rho_C\n",
        "        results_rho_R[i, j] = avg_rho_R\n",
        "        print(\"lam:\", lam,\"zeta_2:\", zeta_2, \"rho_C:\", avg_rho_C, \"rho_R:\", avg_rho_R)"
      ],
      "metadata": {
        "id": "UwrXpgbSe-OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the heat map\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "heatmap = ax.imshow(results_rho_R, cmap='hot', interpolation='nearest')\n",
        "\n",
        "# Set the tick labels and show colorbar\n",
        "ax.set_xticks(np.arange(len(zeta_2_values)))\n",
        "ax.set_yticks(np.arange(len(lam_values)))\n",
        "\n",
        "# Format the tick labels with two decimal places using string formatting\n",
        "zeta_2_formatter = ticker.StrMethodFormatter('{:.2f}'.format)\n",
        "lam_formatter = ticker.StrMethodFormatter('{:.2f}'.format)\n",
        "ax.xaxis.set_major_formatter(zeta_2_formatter)\n",
        "ax.yaxis.set_major_formatter(lam_formatter)\n",
        "ax.invert_yaxis()\n",
        "\n",
        "ax.set_xticklabels(['{:.2f}'.format(val) for val in zeta_2_values])\n",
        "ax.set_yticklabels(['{:.2f}'.format(val) for val in lam_values])\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.colorbar(heatmap)\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('$\\zeta_2$')\n",
        "ax.set_ylabel('$\\lambda$')\n",
        "ax.set_title('Average Recovered Density Heatmap')\n",
        "\n",
        "# Display the heat map\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kaexTn29gLy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alp = 1\n",
        "zeta_1 = 0.2\n",
        "zeta_3 = 0.2\n",
        "zeta_4 = 0.05\n",
        "beta_PP = 0.025\n",
        "beta_NP = 0.05\n",
        "beta_PN = 0.2\n",
        "beta_NN = 0.4\n",
        "mu = 1\n",
        "n_sample = 100\n",
        "\n",
        "# Set the SN-IP and SP-IN disease spreading rates\n",
        "lam_values = np.arange(0.1, 1.0, 0.2)\n",
        "zeta_2_values = np.arange(0.05, 0.3, 0.05)\n",
        "\n",
        "# Initialize the result array\n",
        "results_rho_C = np.zeros((len(lam_values), len(zeta_2_values)))\n",
        "results_rho_R = np.zeros((len(lam_values), len(zeta_2_values)))\n",
        "\n",
        "# Iterate over mu and lambda values\n",
        "for i, lam in enumerate(lam_values):\n",
        "    for j, zeta_2 in enumerate(zeta_2_values):\n",
        "        avg_rho_C, avg_rho_P, avg_rho_R = ICE_model(inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample)\n",
        "        results_rho_C[i, j] = avg_rho_C\n",
        "        results_rho_R[i, j] = avg_rho_R\n",
        "        print(\"lam:\", lam,\"zeta_2:\", zeta_2, \"rho_C:\", avg_rho_C, \"rho_R:\", avg_rho_R)"
      ],
      "metadata": {
        "id": "bG0OvA9GsBmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the heat map\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "heatmap = ax.imshow(results_rho_R, cmap='hot', interpolation='nearest')\n",
        "\n",
        "# Set the tick labels and show colorbar\n",
        "ax.set_xticks(np.arange(len(zeta_2_values)))\n",
        "ax.set_yticks(np.arange(len(lam_values)))\n",
        "\n",
        "# Format the tick labels with two decimal places using string formatting\n",
        "zeta_2_formatter = ticker.StrMethodFormatter('{:.2f}'.format)\n",
        "lam_formatter = ticker.StrMethodFormatter('{:.2f}'.format)\n",
        "ax.xaxis.set_major_formatter(zeta_2_formatter)\n",
        "ax.yaxis.set_major_formatter(lam_formatter)\n",
        "ax.invert_yaxis()\n",
        "\n",
        "ax.set_xticklabels(['{:.2f}'.format(val) for val in zeta_2_values])\n",
        "ax.set_yticklabels(['{:.2f}'.format(val) for val in lam_values])\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.colorbar(heatmap)\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('$\\zeta_2$')\n",
        "ax.set_ylabel('$\\lambda$')\n",
        "ax.set_title('Average Recovered Density Heatmap')\n",
        "\n",
        "# Display the heat map\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xsmHKr4l1Lse"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}